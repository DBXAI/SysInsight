{
  "param_name": "autovacuum_max_workers",
  "function_name": "RelationCacheInitializePhase3",
  "analysis": "1. Parameters influence database performance by controlling key functions:\n   - `autovacuum_max_workers` affects `RelationCacheInitializePhase3` through the [maximum backend connections setting], thereby impacting [cache initialization performance].\n   - Mechanism: The `autovacuum_max_workers` parameter directly participates in calculating `MaxBackends`, which controls the number of concurrent database connections allowed, including `AutovacuumLauncher`. Changes in this value can affect the expected resource allocation during the database initialization phase.\n   - Database performance impact: An increase in `MaxBackends` may lead to more time and resources required for loading and establishing relationship caches during the database initialization phase, potentially causing startup delays, especially when the system handles a large number of subsequent requests, leading to performance degradation.\n\n2. Based on the execution status of `RelationCacheInitializePhase3` and related function segments, provide optimization suggestions for `autovacuum_max_workers`:\n   - If other functions are involved, there is no need to monitor them; focus mainly on `RelationCacheInitializePhase3`.\n   - According to the flame graph sampling rate of `RelationCacheInitializePhase3`, if it is found that the initialization phase causes high CPU usage and significant delays due to relationship cache processing, it is recommended to reduce `autovacuum_max_workers`. This can reduce the cache initialization burden related to the maximum backend. If the flame graph clearly shows that too many threads cause cache processing blockage, reducing `autovacuum_max_workers` is needed to optimize startup efficiency. It is recommended to gradually adjust from a higher value downward to find the optimal balance point.",
  "code_snippets": "InitializeMaxBackends(void)\n{\n\tAssert(MaxBackends == 0);\n\n\t/* the extra unit accounts for the autovacuum launcher */\n\tMaxBackends = MaxConnections + autovacuum_max_workers + 1 +\n\t\tmax_worker_processes + max_wal_senders;\n\n\t/* internal error because the values were all checked previously */\n\tif (MaxBackends > MAX_BACKENDS)\n\t\telog(ERROR, \"too many backends configured\");\n}RelationCacheInitializePhase3(void)\n{\n\tHASH_SEQ_STATUS status;\n\tRelIdCacheEnt *idhentry;\n\tMemoryContext oldcxt;\n\tbool\t\tneedNewCacheFile = !criticalSharedRelcachesBuilt;\n\n\t/*\n\t * relation mapper needs initialized too\n\t */\n\tRelationMapInitializePhase3();\n\n\t/*\n\t * switch to cache memory context\n\t */\n\toldcxt = MemoryContextSwitchTo(CacheMemoryContext);\n\n\t/*\n\t * Try to load the local relcache cache file.  If unsuccessful, bootstrap\n\t * the cache with pre-made descriptors for the critical \"nailed-in\" system\n\t * catalogs.\n\t */\n\tif (IsBootstrapProcessingMode() ||\n\t\t!load_relcache_init_file(false))\n\t{\n\t\tneedNewCacheFile = true;\n\n\t\tformrdesc(\"pg_class\", RelationRelation_Rowtype_Id, false,\n\t\t\t\t  Natts_pg_class, Desc_pg_class);\n\t\tformrdesc(\"pg_attribute\", AttributeRelation_Rowtype_Id, false,\n\t\t\t\t  Natts_pg_attribute, Desc_pg_attribute);\n\t\tformrdesc(\"pg_proc\", ProcedureRelation_Rowtype_Id, false,\n\t\t\t\t  Natts_pg_proc, Desc_pg_proc);\n\t\tformrdesc(\"pg_type\", TypeRelation_Rowtype_Id, false,\n\t\t\t\t  Natts_pg_type, Desc_pg_type);\n\n#define NUM_CRITICAL_LOCAL_RELS 4\t/* fix if you change list above */\n\t}\n\n\tMemoryContextSwitchTo(oldcxt);\n\n\t/* In bootstrap mode, the faked-up formrdesc info is all we'll have */\n\tif (IsBootstrapProcessingMode())\n\t\treturn;\n\n\t/*\n\t * If we didn't get the critical system indexes loaded into relcache, do\n\t * so now.  These are critical because the catcache and/or opclass cache\n\t * depend on them for fetches done during relcache load.  Thus, we have an\n\t * infinite-recursion problem.  We can break the recursion by doing\n\t * heapscans instead of indexscans at certain key spots. To avoid hobbling\n\t * performance, we only want to do that until we have the critical indexes\n\t * loaded into relcache.  Thus, the flag criticalRelcachesBuilt is used to\n\t * decide whether to do heapscan or indexscan at the key spots, and we set\n\t * it true after we've loaded the critical indexes.\n\t *\n\t * The critical indexes are marked as \"nailed in cache\", partly to make it\n\t * easy for load_relcache_init_file to count them, but mainly because we\n\t * cannot flush and rebuild them once we've set criticalRelcachesBuilt to\n\t * true.  (NOTE: perhaps it would be possible to reload them by\n\t * temporarily setting criticalRelcachesBuilt to false again.  For now,\n\t * though, we just nail 'em in.)\n\t *\n\t * RewriteRelRulenameIndexId and TriggerRelidNameIndexId are not critical\n\t * in the same way as the others, because the critical catalogs don't\n\t * (currently) have any rules or triggers, and so these indexes can be\n\t * rebuilt without inducing recursion.  However they are used during\n\t * relcache load when a rel does have rules or triggers, so we choose to\n\t * nail them for performance reasons.\n\t */\n\tif (!criticalRelcachesBuilt)\n\t{\n\t\tload_critical_index(ClassOidIndexId,\n\t\t\t\t\t\t\tRelationRelationId);\n\t\tload_critical_index(AttributeRelidNumIndexId,\n\t\t\t\t\t\t\tAttributeRelationId);\n\t\tload_critical_index(IndexRelidIndexId,\n\t\t\t\t\t\t\tIndexRelationId);\n\t\tload_critical_index(OpclassOidIndexId,\n\t\t\t\t\t\t\tOperatorClassRelationId);\n\t\tload_critical_index(AccessMethodProcedureIndexId,\n\t\t\t\t\t\t\tAccessMethodProcedureRelationId);\n\t\tload_critical_index(RewriteRelRulenameIndexId,\n\t\t\t\t\t\t\tRewriteRelationId);\n\t\tload_critical_index(TriggerRelidNameIndexId,\n\t\t\t\t\t\t\tTriggerRelationId);\n\n#define NUM_CRITICAL_LOCAL_INDEXES\t7\t/* fix if you change list above */\n\n\t\tcriticalRelcachesBuilt = true;\n\t}\n\n\t/*\n\t * Process critical shared indexes too.\n\t *\n\t * DatabaseNameIndexId isn't critical for relcache loading, but rather for\n\t * initial lookup of MyDatabaseId, without which we'll never find any\n\t * non-shared catalogs at all.  Autovacuum calls InitPostgres with a\n\t * database OID, so it instead depends on DatabaseOidIndexId.  We also\n\t * need to nail up some indexes on pg_authid and pg_auth_members for use\n\t * during client authentication.  SharedSecLabelObjectIndexId isn't\n\t * critical for the core system, but authentication hooks might be\n\t * interested in it.\n\t */\n\tif (!criticalSharedRelcachesBuilt)\n\t{\n\t\tload_critical_index(DatabaseNameIndexId,\n\t\t\t\t\t\t\tDatabaseRelationId);\n\t\tload_critical_index(DatabaseOidIndexId,\n\t\t\t\t\t\t\tDatabaseRelationId);\n\t\tload_critical_index(AuthIdRolnameIndexId,\n\t\t\t\t\t\t\tAuthIdRelationId);\n\t\tload_critical_index(AuthIdOidIndexId,\n\t\t\t\t\t\t\tAuthIdRelationId);\n\t\tload_critical_index(AuthMemMemRoleIndexId,\n\t\t\t\t\t\t\tAuthMemRelationId);\n\t\tload_critical_index(SharedSecLabelObjectIndexId,\n\t\t\t\t\t\t\tSharedSecLabelRelationId);\n\n#define NUM_CRITICAL_SHARED_INDEXES 6\t/* fix if you change list above */\n\n\t\tcriticalSharedRelcachesBuilt = true;\n\t}\n\n\t/*\n\t * Now, scan all the relcache entries and update anything that might be\n\t * wrong in the results from formrdesc or the relcache cache file. If we\n\t * faked up relcache entries using formrdesc, then read the real pg_class\n\t * rows and replace the fake entries with them. Also, if any of the\n\t * relcache entries have rules, triggers, or security policies, load that\n\t * info the hard way since it isn't recorded in the cache file.\n\t *\n\t * Whenever we access the catalogs to read data, there is a possibility of\n\t * a shared-inval cache flush causing relcache entries to be removed.\n\t * Since hash_seq_search only guarantees to still work after the *current*\n\t * entry is removed, it's unsafe to continue the hashtable scan afterward.\n\t * We handle this by restarting the scan from scratch after each access.\n\t * This is theoretically O(N^2), but the number of entries that actually\n\t * need to be fixed is small enough that it doesn't matter.\n\t */\n\thash_seq_init(&status, RelationIdCache);\n\n\twhile ((idhentry = (RelIdCacheEnt *) hash_seq_search(&status)) != NULL)\n\t{\n\t\tRelation\trelation = idhentry->reldesc;\n\t\tbool\t\trestart = false;\n\n\t\t/*\n\t\t * Make sure *this* entry doesn't get flushed while we work with it.\n\t\t */\n\t\tRelationIncrementReferenceCount(relation);\n\n\t\t/*\n\t\t * If it's a faked-up entry, read the real pg_class tuple.\n\t\t */\n\t\tif (relation->rd_rel->relowner == InvalidOid)\n\t\t{\n\t\t\tHeapTuple\thtup;\n\t\t\tForm_pg_class relp;\n\n\t\t\thtup = SearchSysCache1(RELOID,\n\t\t\t\t\t\t\t\t   ObjectIdGetDatum(RelationGetRelid(relation)));\n\t\t\tif (!HeapTupleIsValid(htup))\n\t\t\t\telog(FATAL, \"cache lookup failed for relation %u\",\n\t\t\t\t\t RelationGetRelid(relation));\n\t\t\trelp = (Form_pg_class) GETSTRUCT(htup);\n\n\t\t\t/*\n\t\t\t * Copy tuple to relation->rd_rel. (See notes in\n\t\t\t * AllocateRelationDesc())\n\t\t\t */\n\t\t\tmemcpy((char *) relation->rd_rel, (char *) relp, CLASS_TUPLE_SIZE);\n\n\t\t\t/* Update rd_options while we have the tuple */\n\t\t\tif (relation->rd_options)\n\t\t\t\tpfree(relation->rd_options);\n\t\t\tRelationParseRelOptions(relation, htup);\n\n\t\t\t/*\n\t\t\t * Check the values in rd_att were set up correctly.  (We cannot\n\t\t\t * just copy them over now: formrdesc must have set up the rd_att\n\t\t\t * data correctly to start with, because it may already have been\n\t\t\t * copied into one or more catcache entries.)\n\t\t\t */\n\t\t\tAssert(relation->rd_att->tdtypeid == relp->reltype);\n\t\t\tAssert(relation->rd_att->tdtypmod == -1);\n\n\t\t\tReleaseSysCache(htup);\n\n\t\t\t/* relowner had better be OK now, else we'll loop forever */\n\t\t\tif (relation->rd_rel->relowner == InvalidOid)\n\t\t\t\telog(ERROR, \"invalid relowner in pg_class entry for \\\"%s\\\"\",\n\t\t\t\t\t RelationGetRelationName(relation));\n\n\t\t\trestart = true;\n\t\t}\n\n\t\t/*\n\t\t * Fix data that isn't saved in relcache cache file.\n\t\t *\n\t\t * relhasrules or relhastriggers could possibly be wrong or out of\n\t\t * date.  If we don't actually find any rules or triggers, clear the\n\t\t * local copy of the flag so that we don't get into an infinite loop\n\t\t * here.  We don't make any attempt to fix the pg_class entry, though.\n\t\t */\n\t\tif (relation->rd_rel->relhasrules && relation->rd_rules == NULL)\n\t\t{\n\t\t\tRelationBuildRuleLock(relation);\n\t\t\tif (relation->rd_rules == NULL)\n\t\t\t\trelation->rd_rel->relhasrules = false;\n\t\t\trestart = true;\n\t\t}\n\t\tif (relation->rd_rel->relhastriggers && relation->trigdesc == NULL)\n\t\t{\n\t\t\tRelationBuildTriggers(relation);\n\t\t\tif (relation->trigdesc == NULL)\n\t\t\t\trelation->rd_rel->relhastriggers = false;\n\t\t\trestart = true;\n\t\t}\n\n\t\t/*\n\t\t * Re-load the row security policies if the relation has them, since\n\t\t * they are not preserved in the cache.  Note that we can never NOT\n\t\t * have a policy while relrowsecurity is true,\n\t\t * RelationBuildRowSecurity will create a single default-deny policy\n\t\t * if there is no policy defined in pg_policy.\n\t\t */\n\t\tif (relation->rd_rel->relrowsecurity && relation->rd_rsdesc == NULL)\n\t\t{\n\t\t\tRelationBuildRowSecurity(relation);\n\n\t\t\tAssert(relation->rd_rsdesc != NULL);\n\t\t\trestart = true;\n\t\t}\n\n\t\t/* Reload tableam data if needed */\n\t\tif (relation->rd_tableam == NULL &&\n\t\t\t(RELKIND_HAS_TABLE_AM(relation->rd_rel->relkind) || relation->rd_rel->relkind == RELKIND_SEQUENCE))\n\t\t{\n\t\t\tRelationInitTableAccessMethod(relation);\n\t\t\tAssert(relation->rd_tableam != NULL);\n\n\t\t\trestart = true;\n\t\t}\n\n\t\t/* Release hold on the relation */\n\t\tRelationDecrementReferenceCount(relation);\n\n\t\t/* Now, restart the hashtable scan if needed */\n\t\tif (restart)\n\t\t{\n\t\t\thash_seq_term(&status);\n\t\t\thash_seq_init(&status, RelationIdCache);\n\t\t}\n\t}\n\n\t/*\n\t * Lastly, write out new relcache cache files if needed.  We don't bother\n\t * to distinguish cases where only one of the two needs an update.\n\t */\n\tif (needNewCacheFile)\n\t{\n\t\t/*\n\t\t * Force all the catcaches to finish initializing and thereby open the\n\t\t * catalogs and indexes they use.  This will preload the relcache with\n\t\t * entries for all the most important system catalogs and indexes, so\n\t\t * that the init files will be most useful for future backends.\n\t\t */\n\t\tInitCatalogCachePhase2();\n\n\t\t/* now write the files */\n\t\twrite_relcache_init_file(true);\n\t\twrite_relcache_init_file(false);\n\t}\n}",
  "timestamp": "2025-10-30T15:57:23.056981"
}