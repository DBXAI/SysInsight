{
  "param_name": "work_mem",
  "function_name": "hash_create",
  "analysis": "1. Parameters control the impact of key functions on database performance:\n    - `work_mem` affects `hash_create` through the memory configuration mechanism, thereby influencing the initialization and allocation of hash tables.\n    - Mechanism: `work_mem` specifies the maximum memory allowed for internal sorting or hash tables for a single operation, which affects the memory used for hash tables or directory structures in `hash_create`. Increasing the `work_mem` value will allow more data to be processed in memory in `hash_create` without spilling over to disk.\n    - Database performance impact: Higher `work_mem` can reduce disk I/O because larger hash tables can be established in memory, reducing disk write operations and improving query speed. However, excessively large `work_mem` may lead to excessive memory consumption, affecting the performance of other concurrent queries.\n\n2. Based on the execution status of `hash_create` and related function fragments, provide optimization suggestions for `work_mem`:\n    - If other functions are involved, indicate whether monitoring other functions besides `hash_create` is necessary: There are no other functions that need monitoring; `hash_create` is the primary evaluation target.\n    - How to recommend adjustments to `work_mem` (increase or decrease) based on the sampling rate of `hash_create`'s flame graph and the rationale:\n        - If the flame graph of `hash_create` shows frequent memory allocation failures or frequent disk I/O, it is recommended to increase `work_mem` so that the hash table can retain more data in memory.\n        - If the flame graph of `hash_create` shows excessive memory usage affecting other system functions or reducing system concurrency capabilities, it is recommended to adjust according to system resources and decrease `work_mem` to prevent excessive memory usage from causing performance bottlenecks.",
  "code_snippets": "hash_create(const char *tabname, long nelem, const HASHCTL *info, int flags)\n{\n\tHTAB\t   *hashp;\n\tHASHHDR    *hctl;\n\n\t/*\n\t * Hash tables now allocate space for key and data, but you have to say\n\t * how much space to allocate.\n\t */\n\tAssert(flags & HASH_ELEM);\n\tAssert(info->keysize > 0);\n\tAssert(info->entrysize >= info->keysize);\n\n\t/*\n\t * For shared hash tables, we have a local hash header (HTAB struct) that\n\t * we allocate in TopMemoryContext; all else is in shared memory.\n\t *\n\t * For non-shared hash tables, everything including the hash header is in\n\t * a memory context created specially for the hash table --- this makes\n\t * hash_destroy very simple.  The memory context is made a child of either\n\t * a context specified by the caller, or TopMemoryContext if nothing is\n\t * specified.\n\t */\n\tif (flags & HASH_SHARED_MEM)\n\t{\n\t\t/* Set up to allocate the hash header */\n\t\tCurrentDynaHashCxt = TopMemoryContext;\n\t}\n\telse\n\t{\n\t\t/* Create the hash table's private memory context */\n\t\tif (flags & HASH_CONTEXT)\n\t\t\tCurrentDynaHashCxt = info->hcxt;\n\t\telse\n\t\t\tCurrentDynaHashCxt = TopMemoryContext;\n\t\tCurrentDynaHashCxt = AllocSetContextCreate(CurrentDynaHashCxt,\n\t\t\t\t\t\t\t\t\t\t\t\t   \"dynahash\",\n\t\t\t\t\t\t\t\t\t\t\t\t   ALLOCSET_DEFAULT_SIZES);\n\t}\n\n\t/* Initialize the hash header, plus a copy of the table name */\n\thashp = (HTAB *) DynaHashAlloc(sizeof(HTAB) + strlen(tabname) + 1);\n\tMemSet(hashp, 0, sizeof(HTAB));\n\n\thashp->tabname = (char *) (hashp + 1);\n\tstrcpy(hashp->tabname, tabname);\n\n\t/* If we have a private context, label it with hashtable's name */\n\tif (!(flags & HASH_SHARED_MEM))\n\t\tMemoryContextSetIdentifier(CurrentDynaHashCxt, hashp->tabname);\n\n\t/*\n\t * Select the appropriate hash function (see comments at head of file).\n\t */\n\tif (flags & HASH_FUNCTION)\n\t{\n\t\tAssert(!(flags & (HASH_BLOBS | HASH_STRINGS)));\n\t\thashp->hash = info->hash;\n\t}\n\telse if (flags & HASH_BLOBS)\n\t{\n\t\tAssert(!(flags & HASH_STRINGS));\n\t\t/* We can optimize hashing for common key sizes */\n\t\tif (info->keysize == sizeof(uint32))\n\t\t\thashp->hash = uint32_hash;\n\t\telse\n\t\t\thashp->hash = tag_hash;\n\t}\n\telse\n\t{\n\t\t/*\n\t\t * string_hash used to be considered the default hash method, and in a\n\t\t * non-assert build it effectively still is.  But we now consider it\n\t\t * an assertion error to not say HASH_STRINGS explicitly.  To help\n\t\t * catch mistaken usage of HASH_STRINGS, we also insist on a\n\t\t * reasonably long string length: if the keysize is only 4 or 8 bytes,\n\t\t * it's almost certainly an integer or pointer not a string.\n\t\t */\n\t\tAssert(flags & HASH_STRINGS);\n\t\tAssert(info->keysize > 8);\n\n\t\thashp->hash = string_hash;\n\t}\n\n\t/*\n\t * If you don't specify a match function, it defaults to string_compare if\n\t * you used string_hash, and to memcmp otherwise.\n\t *\n\t * Note: explicitly specifying string_hash is deprecated, because this\n\t * might not work for callers in loadable modules on some platforms due to\n\t * referencing a trampoline instead of the string_hash function proper.\n\t * Specify HASH_STRINGS instead.\n\t */\n\tif (flags & HASH_COMPARE)\n\t\thashp->match = info->match;\n\telse if (hashp->hash == string_hash)\n\t\thashp->match = (HashCompareFunc) string_compare;\n\telse\n\t\thashp->match = memcmp;\n\n\t/*\n\t * Similarly, the key-copying function defaults to strlcpy or memcpy.\n\t */\n\tif (flags & HASH_KEYCOPY)\n\t\thashp->keycopy = info->keycopy;\n\telse if (hashp->hash == string_hash)\n\t{\n\t\t/*\n\t\t * The signature of keycopy is meant for memcpy(), which returns\n\t\t * void*, but strlcpy() returns size_t.  Since we never use the return\n\t\t * value of keycopy, and size_t is pretty much always the same size as\n\t\t * void *, this should be safe.  The extra cast in the middle is to\n\t\t * avoid warnings from -Wcast-function-type.\n\t\t */\n\t\thashp->keycopy = (HashCopyFunc) (pg_funcptr_t) strlcpy;\n\t}\n\telse\n\t\thashp->keycopy = memcpy;\n\n\t/* And select the entry allocation function, too. */\n\tif (flags & HASH_ALLOC)\n\t\thashp->alloc = info->alloc;\n\telse\n\t\thashp->alloc = DynaHashAlloc;\n\n\tif (flags & HASH_SHARED_MEM)\n\t{\n\t\t/*\n\t\t * ctl structure and directory are preallocated for shared memory\n\t\t * tables.  Note that HASH_DIRSIZE and HASH_ALLOC had better be set as\n\t\t * well.\n\t\t */\n\t\thashp->hctl = info->hctl;\n\t\thashp->dir = (HASHSEGMENT *) (((char *) info->hctl) + sizeof(HASHHDR));\n\t\thashp->hcxt = NULL;\n\t\thashp->isshared = true;\n\n\t\t/* hash table already exists, we're just attaching to it */\n\t\tif (flags & HASH_ATTACH)\n\t\t{\n\t\t\t/* make local copies of some heavily-used values */\n\t\t\thctl = hashp->hctl;\n\t\t\thashp->keysize = hctl->keysize;\n\t\t\thashp->ssize = hctl->ssize;\n\t\t\thashp->sshift = hctl->sshift;\n\n\t\t\treturn hashp;\n\t\t}\n\t}\n\telse\n\t{\n\t\t/* setup hash table defaults */\n\t\thashp->hctl = NULL;\n\t\thashp->dir = NULL;\n\t\thashp->hcxt = CurrentDynaHashCxt;\n\t\thashp->isshared = false;\n\t}\n\n\tif (!hashp->hctl)\n\t{\n\t\thashp->hctl = (HASHHDR *) hashp->alloc(sizeof(HASHHDR));\n\t\tif (!hashp->hctl)\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t errmsg(\"out of memory\")));\n\t}\n\n\thashp->frozen = false;\n\n\thdefault(hashp);\n\n\thctl = hashp->hctl;\n\n\tif (flags & HASH_PARTITION)\n\t{\n\t\t/* Doesn't make sense to partition a local hash table */\n\t\tAssert(flags & HASH_SHARED_MEM);\n\n\t\t/*\n\t\t * The number of partitions had better be a power of 2. Also, it must\n\t\t * be less than INT_MAX (see init_htab()), so call the int version of\n\t\t * next_pow2.\n\t\t */\n\t\tAssert(info->num_partitions == next_pow2_int(info->num_partitions));\n\n\t\thctl->num_partitions = info->num_partitions;\n\t}\n\n\tif (flags & HASH_SEGMENT)\n\t{\n\t\thctl->ssize = info->ssize;\n\t\thctl->sshift = my_log2(info->ssize);\n\t\t/* ssize had better be a power of 2 */\n\t\tAssert(hctl->ssize == (1L << hctl->sshift));\n\t}\n\n\t/*\n\t * SHM hash tables have fixed directory size passed by the caller.\n\t */\n\tif (flags & HASH_DIRSIZE)\n\t{\n\t\thctl->max_dsize = info->max_dsize;\n\t\thctl->dsize = info->dsize;\n\t}\n\n\t/* remember the entry sizes, too */\n\thctl->keysize = info->keysize;\n\thctl->entrysize = info->entrysize;\n\n\t/* make local copies of heavily-used constant fields */\n\thashp->keysize = hctl->keysize;\n\thashp->ssize = hctl->ssize;\n\thashp->sshift = hctl->sshift;\n\n\t/* Build the hash directory structure */\n\tif (!init_htab(hashp, nelem))\n\t\telog(ERROR, \"failed to initialize hash table \\\"%s\\\"\", hashp->tabname);\n\n\t/*\n\t * For a shared hash table, preallocate the requested number of elements.\n\t * This reduces problems with run-time out-of-shared-memory conditions.\n\t *\n\t * For a non-shared hash table, preallocate the requested number of\n\t * elements if it's less than our chosen nelem_alloc.  This avoids wasting\n\t * space if the caller correctly estimates a small table size.\n\t */\n\tif ((flags & HASH_SHARED_MEM) ||\n\t\tnelem < hctl->nelem_alloc)\n\t{\n\t\tint\t\t\ti,\n\t\t\t\t\tfreelist_partitions,\n\t\t\t\t\tnelem_alloc,\n\t\t\t\t\tnelem_alloc_first;\n\n\t\t/*\n\t\t * If hash table is partitioned, give each freelist an equal share of\n\t\t * the initial allocation.  Otherwise only freeList[0] is used.\n\t\t */\n\t\tif (IS_PARTITIONED(hashp->hctl))\n\t\t\tfreelist_partitions = NUM_FREELISTS;\n\t\telse\n\t\t\tfreelist_partitions = 1;\n\n\t\tnelem_alloc = nelem / freelist_partitions;\n\t\tif (nelem_alloc <= 0)\n\t\t\tnelem_alloc = 1;\n\n\t\t/*\n\t\t * Make sure we'll allocate all the requested elements; freeList[0]\n\t\t * gets the excess if the request isn't divisible by NUM_FREELISTS.\n\t\t */\n\t\tif (nelem_alloc * freelist_partitions < nelem)\n\t\t\tnelem_alloc_first =\n\t\t\t\tnelem - nelem_alloc * (freelist_partitions - 1);\n\t\telse\n\t\t\tnelem_alloc_first = nelem_alloc;\n\n\t\tfor (i = 0; i < freelist_partitions; i++)\n\t\t{\n\t\t\tint\t\t\ttemp = (i == 0) ? nelem_alloc_first : nelem_alloc;\n\n\t\t\tif (!element_alloc(hashp, temp, i))\n\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t errmsg(\"out of memory\")));\n\t\t}\n\t}\n\n\tif (flags & HASH_FIXED_SIZE)\n\t\thashp->isfixed = true;\n\treturn hashp;\n}",
  "timestamp": "2025-10-30T15:57:55.771272"
}