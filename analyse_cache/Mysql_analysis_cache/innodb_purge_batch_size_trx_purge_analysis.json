{
  "param_name": "innodb_purge_batch_size",
  "function_name": "trx_purge",
  "analysis": "1. Parameters influence database performance through controlling key functions:\n   - `innodb_purge_batch_size` affects `trx_purge` by adjusting the number of records to be purged in a batch, thereby impacting database performance.\n   - Mechanism: `innodb_purge_batch_size` defines the number of records to be processed in each purge operation. In the `trx_purge` function, the batch size determines the frequency of scheduling and executing task queues. The larger the value, the more records are processed in each purge, reducing the scheduling frequency of task queues.\n   - Database performance impact: Increasing `innodb_purge_batch_size` can enhance purge efficiency, especially in high-load database scenarios; however, a value too large may lead to increased lock waits and memory pressure. A smaller value may cause frequent task scheduling, affecting overall system performance and latency.\n\n2. Based on the execution status of `trx_purge` and related function fragments, provide optimization suggestions for `innodb_purge_batch_size`:\n   - If other functions are involved, besides monitoring `trx_purge`, it is also necessary to monitor the `trx_purge_attach_undo_recs` function, as it directly affects the specific implementation of purge batch processing.\n   - It is recommended to analyze data based on the sampling rate of flame graphs. If `trx_purge` and `trx_purge_attach_undo_recs` functions show high CPU usage or frequent waits, test increasing `innodb_purge_batch_size`. If this leads to increased lock waits or high memory consumption, consider lowering the value to achieve a balance between performance and resource usage. It is recommended to observe the impact through gradual adjustments and dynamically set an appropriate value.",
  "code_snippets": "ulint trx_purge(ulint n_purge_threads, /*!< in: number of purge tasks\n                                       to submit to the work queue */\n                ulint batch_size,      /*!< in: the maximum number of records\n                                       to purge in one batch */\n                bool truncate)         /*!< in: truncate history if true */\n{\n  que_thr_t *thr = nullptr;\n  ulint n_pages_handled;\n\n  ut_a(n_purge_threads > 0);\n\n  srv_dml_needed_delay = trx_purge_dml_delay();\n\n  /* The number of tasks submitted should be completed. */\n  ut_a(purge_sys->n_submitted == purge_sys->n_completed);\n\n  rw_lock_x_lock(&purge_sys->latch, UT_LOCATION_HERE);\n\n  purge_sys->view_active = false;\n\n  trx_sys->mvcc->clone_oldest_view(&purge_sys->view);\n\n  purge_sys->view_active = true;\n\n  rw_lock_x_unlock(&purge_sys->latch);\n\n#ifdef UNIV_DEBUG\n  if (srv_purge_view_update_only_debug) {\n    return (0);\n  }\n#endif /* UNIV_DEBUG */\n\n  /* Fetch the UNDO recs that need to be purged. */\n  n_pages_handled = trx_purge_attach_undo_recs(n_purge_threads, batch_size);\n\n  /* Do we do an asynchronous purge or not ? */\n  if (n_purge_threads > 1) {\n    /* Submit the tasks to the work queue. */\n    for (ulint i = 0; i < n_purge_threads - 1; ++i) {\n      thr = que_fork_scheduler_round_robin(purge_sys->query, thr);\n\n      ut_a(thr != nullptr);\n\n      srv_que_task_enqueue_low(thr);\n    }\n\n    thr = que_fork_scheduler_round_robin(purge_sys->query, thr);\n    ut_a(thr != nullptr);\n\n    purge_sys->n_submitted += n_purge_threads - 1;\n\n    goto run_synchronously;\n\n    /* Do it synchronously. */\n  } else {\n    thr = que_fork_scheduler_round_robin(purge_sys->query, nullptr);\n    ut_ad(thr);\n\n  run_synchronously:\n    ++purge_sys->n_submitted;\n\n    que_run_threads(thr);\n\n    purge_sys->n_completed.fetch_add(1);\n\n    if (n_purge_threads > 1) {\n      trx_purge_wait_for_workers_to_complete();\n    }\n  }\n\n  ut_a(purge_sys->n_submitted == purge_sys->n_completed);\n\n#ifdef UNIV_DEBUG\n  rw_lock_x_lock(&purge_sys->latch, UT_LOCATION_HERE);\n  if (purge_sys->limit.trx_no == 0) {\n    purge_sys->done = purge_sys->iter;\n  } else {\n    purge_sys->done = purge_sys->limit;\n  }\n  rw_lock_x_unlock(&purge_sys->latch);\n#endif /* UNIV_DEBUG */\n\n  /* The first page of LOBs are freed at the end of a purge batch because\n  multiple purge threads will access the same LOB as part of the purge\n  process.  Some purge threads will free only portion of the LOB related to\n  the partial update of the LOB.  But 1 of the purge thread will free the LOB\n  completely if it is not needed anymore (either because of full update or\n  because of deletion).  If the LOB is freed, and a purge thread attempts to\n  access the LOB, then it is a bug.  To avoid this, we delay the freeing of\n  the first page of LOB till the end of a purge batch.  */\n  for (thr = UT_LIST_GET_FIRST(purge_sys->query->thrs); thr != nullptr;\n       thr = UT_LIST_GET_NEXT(thrs, thr)) {\n    purge_node_t *node = static_cast<purge_node_t *>(thr->child);\n    node->free_lob_pages();\n  }\n\n  /* During upgrade, to know whether purge is empty,\n  we rely on purge history length. So truncate the\n  undo logs during upgrade to update purge history\n  length. */\n  if (truncate || srv_upgrade_old_undo_found) {\n    trx_purge_truncate();\n  }\n\n  MONITOR_INC_VALUE(MONITOR_PURGE_INVOKED, 1);\n  MONITOR_INC_VALUE(MONITOR_PURGE_N_PAGE_HANDLED, n_pages_handled);\n\n  return (n_pages_handled);\n}",
  "timestamp": "2025-10-30T15:56:01.486389"
}