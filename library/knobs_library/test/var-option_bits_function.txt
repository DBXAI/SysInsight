-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/thd_raii.h
Function: Disable_autocommit_guard::Disable_autocommit_guard
  explicit Disable_autocommit_guard(THD *thd)
      : m_thd(thd), m_save_option_bits(thd ? thd->variables.option_bits : 0) {
    if (m_thd) {
      /*
        We can't disable auto-commit if there is ongoing transaction as this
        might easily break statement/session transaction invariants.
      */
      assert(m_thd->get_transaction()->is_empty(Transaction_ctx::STMT) &&
             m_thd->get_transaction()->is_empty(Transaction_ctx::SESSION));

      m_thd->variables.option_bits &= ~OPTION_AUTOCOMMIT;
      m_thd->variables.option_bits |= OPTION_NOT_AUTOCOMMIT;
    }
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/thd_raii.h
Function: Disable_autocommit_guard::
    if (m_thd) {
      /*
        We can't disable auto-commit if there is ongoing transaction as this
        might easily break statement/session transaction invariants.
      */
      assert(m_thd->get_transaction()->is_empty(Transaction_ctx::STMT) &&
             m_thd->get_transaction()->is_empty(Transaction_ctx::SESSION));

      m_thd->variables.option_bits &= ~OPTION_AUTOCOMMIT;
      m_thd->variables.option_bits |= OPTION_NOT_AUTOCOMMIT;
    }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/thd_raii.h
Function: Disable_binlog_guard::Disable_binlog_guard
  explicit Disable_binlog_guard(THD *thd)
      : m_thd(thd),
        m_binlog_disabled(thd->variables.option_bits & OPTION_BIN_LOG) {
    thd->variables.option_bits &= ~OPTION_BIN_LOG;
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/thd_raii.h
Function: Disable_sql_log_bin_guard::
    if (m_thd) {
      /*
        We can't disable auto-commit if there is ongoing transaction as this
        might easily break statement/session transaction invariants.
      */
      assert(m_thd->get_transaction()->is_empty(Transaction_ctx::STMT) &&
             m_thd->get_transaction()->is_empty(Transaction_ctx::SESSION));

      m_thd->variables.option_bits &= ~OPTION_AUTOCOMMIT;
      m_thd->variables.option_bits |= OPTION_NOT_AUTOCOMMIT;
    }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/thd_raii.h
Function: Disable_binlog_guard::
    if (m_thd) {
      /*
        We can't disable auto-commit if there is ongoing transaction as this
        might easily break statement/session transaction invariants.
      */
      assert(m_thd->get_transaction()->is_empty(Transaction_ctx::STMT) &&
             m_thd->get_transaction()->is_empty(Transaction_ctx::SESSION));

      m_thd->variables.option_bits &= ~OPTION_AUTOCOMMIT;
      m_thd->variables.option_bits |= OPTION_NOT_AUTOCOMMIT;
    }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/ndb/plugin/ha_ndbcluster_binlog.cc
Function: Ndb_schema_event_handler::Lock_wait_timeout_guard::
  Copyright (c) 2006, 2023, Oracle and/or its affiliates.

   This program is free software; you can redistribute it and/or modify
   it under the terms of the GNU General Public License, version 2.0,
   as published by the Free Software Foundation.

   This program is also distributed with certain software (including
   but not limited to OpenSSL) that is licensed under separate terms,
   as designated in a particular file or component or in included license
   documentation.  The authors of MySQL hereby grant you an additional
   permission to link the program and your derivative works with the
   separately licensed software that they have included with MySQL.

   This program is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   GNU General Public License, version 2.0, for more details.

   You should have received a copy of the GNU General Public License
   along with this program; if not, write to the Free Software
   Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301  USA
*/

#include "storage/ndb/plugin/ha_ndbcluster_binlog.h"

#include <unordered_map>

#include "my_config.h"  // WORDS_BIGENDIAN
#include "my_dbug.h"
#include "my_thread.h"
#include "mysql/plugin.h"
#include "sql/auth/acl_change_notification.h"
#include "sql/binlog.h"
#include "sql/dd/types/abstract_table.h"  // dd::enum_table_type
#include "sql/dd/types/tablespace.h"      // dd::Tablespace
#include "sql/debug_sync.h"               // debug_sync_set_action, DEBUG_SYNC
#include "sql/derror.h"                   // ER_THD
#include "sql/mysqld.h"                   // opt_bin_log
#include "sql/mysqld_thd_manager.h"       // Global_THD_manager
#include "sql/protocol_classic.h"
#include "sql/rpl_injector.h"
#include "sql/sql_base.h"
#include "sql/sql_lex.h"
#include "sql/sql_rewrite.h"
#include "sql/sql_thd_internal_api.h"
#include "sql/thd_raii.h"
#include "sql/transaction.h"
#include "storage/ndb/include/ndbapi/NdbDictionary.hpp"
#include "storage/ndb/include/ndbapi/ndb_cluster_connection.hpp"
#include "storage/ndb/plugin/ha_ndbcluster_connection.h"
#include "storage/ndb/plugin/ndb_anyvalue.h"
#include "storage/ndb/plugin/ndb_apply_status_table.h"
#include "storage/ndb/plugin/ndb_binlog_client.h"
#include "storage/ndb/plugin/ndb_binlog_extra_row_info.h"
#include "storage/ndb/plugin/ndb_binlog_thread.h"
#include "storage/ndb/plugin/ndb_bitmap.h"
#include "storage/ndb/plugin/ndb_blobs_buffer.h"
#include "storage/ndb/plugin/ndb_conflict.h"
#include "storage/ndb/plugin/ndb_dd.h"
#include "storage/ndb/plugin/ndb_dd_client.h"
#include "storage/ndb/plugin/ndb_dd_disk_data.h"
#include "storage/ndb/plugin/ndb_dd_sync.h"  // Ndb_dd_sync
#include "storage/ndb/plugin/ndb_dd_table.h"
#include "storage/ndb/plugin/ndb_event_data.h"
#include "storage/ndb/plugin/ndb_global_schema_lock_guard.h"
#include "storage/ndb/plugin/ndb_index_stat_head_table.h"
#include "storage/ndb/plugin/ndb_index_stat_sample_table.h"
#include "storage/ndb/plugin/ndb_local_connection.h"
#include "storage/ndb/plugin/ndb_log.h"
#include "storage/ndb/plugin/ndb_mysql_services.h"
#include "storage/ndb/plugin/ndb_name_util.h"
#include "storage/ndb/plugin/ndb_ndbapi_errors.h"
#include "storage/ndb/plugin/ndb_ndbapi_util.h"
#include "storage/ndb/plugin/ndb_repl_tab.h"
#include "storage/ndb/plugin/ndb_require.h"
#include "storage/ndb/plugin/ndb_retry.h"
#include "storage/ndb/plugin/ndb_schema_dist.h"
#include "storage/ndb/plugin/ndb_schema_dist_table.h"
#include "storage/ndb/plugin/ndb_schema_object.h"
#include "storage/ndb/plugin/ndb_schema_result_table.h"
#include "storage/ndb/plugin/ndb_share.h"
#include "storage/ndb/plugin/ndb_sleep.h"
#include "storage/ndb/plugin/ndb_stored_grants.h"
#include "storage/ndb/plugin/ndb_table_guard.h"
#include "storage/ndb/plugin/ndb_table_map.h"
#include "storage/ndb/plugin/ndb_tdc.h"
#include "storage/ndb/plugin/ndb_thd.h"
#include "storage/ndb/plugin/ndb_thd_ndb.h"
#include "storage/ndb/plugin/ndb_upgrade_util.h"

typedef NdbDictionary::Event NDBEVENT;
typedef NdbDictionary::Table NDBTAB;

extern bool opt_ndb_log_orig;
extern bool opt_ndb_log_bin;
extern bool opt_ndb_log_empty_epochs;
extern bool opt_ndb_log_update_as_write;
extern bool opt_ndb_log_updated_only;
extern bool opt_ndb_log_update_minimal;
extern bool opt_ndb_log_binlog_index;
extern bool opt_ndb_log_apply_status;
extern bool opt_ndb_log_transaction_id;
extern bool opt_ndb_log_trx_compression;
extern uint opt_ndb_log_trx_compression_level_zstd;
extern bool opt_ndb_log_empty_update;
extern bool opt_ndb_clear_apply_status;
extern bool opt_ndb_log_fail_terminate;
extern bool opt_ndb_log_trans_dependency;
extern int opt_ndb_schema_dist_timeout;
extern ulong opt_ndb_schema_dist_lock_wait_timeout;
extern ulong opt_ndb_report_thresh_binlog_epoch_slip;
extern ulong opt_ndb_report_thresh_binlog_mem_usage;
extern ulonglong opt_ndb_eventbuffer_max_alloc;
extern uint opt_ndb_eventbuffer_free_percent;

void ndb_index_stat_restart();

extern Ndb_cluster_connection *g_ndb_cluster_connection;

/*
  Timeout for syncing schema events between
  mysql servers, and between mysql server and the binlog
*/
static const int DEFAULT_SYNC_TIMEOUT = 120;

/* Column numbers in the ndb_binlog_index table */
enum Ndb_binlog_index_cols {
  NBICOL_START_POS = 0,
  NBICOL_START_FILE = 1,
  NBICOL_EPOCH = 2,
  NBICOL_NUM_INSERTS = 3,
  NBICOL_NUM_UPDATES = 4,
  NBICOL_NUM_DELETES = 5,
  NBICOL_NUM_SCHEMAOPS = 6
  /* Following columns in schema 'v2' */
  ,
  NBICOL_ORIG_SERVERID = 7,
  NBICOL_ORIG_EPOCH = 8,
  NBICOL_GCI = 9
  /* Following columns in schema 'v3' */
  ,
  NBICOL_NEXT_POS = 10,
  NBICOL_NEXT_FILE = 11
};


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/ndb/plugin/ha_ndbcluster_binlog.cc
Function: Ndb_binlog_index_table_util::write_rows_impl
  static int write_rows_impl(THD *thd, ndb_binlog_index_row *row) {
    int error = 0;
    ndb_binlog_index_row *first = row;
    TABLE *ndb_binlog_index = nullptr;
    // Save previous option settings
    ulonglong option_bits = thd->variables.option_bits;

    /*
      Assume this function is not called with an error set in thd
      (but clear for safety in release version)
     */
    assert(!thd->is_error());
    thd->clear_error();

    /*
      Turn off binlogging to prevent the table changes to be written to
      the binary log.
    */
    Disable_binlog_guard binlog_guard(thd);

    if (open_binlog_index_table(thd, &ndb_binlog_index)) {
      if (thd->killed)
        DBUG_PRINT("error", ("Unable to lock table ndb_binlog_index, killed"));
      else
        ndb_log_error("Binlog: Unable to lock table ndb_binlog_index");
      error = -1;
      goto add_ndb_binlog_index_err;
    }

    // Set all columns to be written
    ndb_binlog_index->use_all_columns();

    // Turn off autocommit to do all writes in one transaction
    thd->variables.option_bits |= OPTION_NOT_AUTOCOMMIT;
    do {
      ulonglong epoch = 0, orig_epoch = 0;
      uint orig_server_id = 0;

      // Initialize ndb_binlog_index->record[0]
      empty_record(ndb_binlog_index);

      ndb_binlog_index->field[NBICOL_START_POS]->store(
          first->start_master_log_pos, true);
      ndb_binlog_index->field[NBICOL_START_FILE]->store(
          first->start_master_log_file,
          (uint)strlen(first->start_master_log_file), &my_charset_bin);
      ndb_binlog_index->field[NBICOL_EPOCH]->store(epoch = first->epoch, true);
      if (ndb_binlog_index->s->fields > NBICOL_ORIG_SERVERID) {
        /* Table has ORIG_SERVERID / ORIG_EPOCH columns.
         * Write rows with different ORIG_SERVERID / ORIG_EPOCH
         * separately
         */
        ndb_binlog_index->field[NBICOL_NUM_INSERTS]->store(row->n_inserts,
                                                           true);
        ndb_binlog_index->field[NBICOL_NUM_UPDATES]->store(row->n_updates,
                                                           true);
        ndb_binlog_index->field[NBICOL_NUM_DELETES]->store(row->n_deletes,
                                                           true);
        ndb_binlog_index->field[NBICOL_NUM_SCHEMAOPS]->store(row->n_schemaops,
                                                             true);
        ndb_binlog_index->field[NBICOL_ORIG_SERVERID]->store(
            orig_server_id = row->orig_server_id, true);
        ndb_binlog_index->field[NBICOL_ORIG_EPOCH]->store(
            orig_epoch = row->orig_epoch, true);
        ndb_binlog_index->field[NBICOL_GCI]->store(first->gci, true);

        if (ndb_binlog_index->s->fields > NBICOL_NEXT_POS) {
          /* Table has next log pos fields, fill them in */
          ndb_binlog_index->field[NBICOL_NEXT_POS]->store(
              first->next_master_log_pos, true);
          ndb_binlog_index->field[NBICOL_NEXT_FILE]->store(
              first->next_master_log_file,
              (uint)strlen(first->next_master_log_file), &my_charset_bin);
        }
        row = row->next;
      } else {
        /* Old schema : Table has no separate
         * ORIG_SERVERID / ORIG_EPOCH columns.
         * Merge operation counts and write one row
         */
        while ((row = row->next)) {
          first->n_inserts += row->n_inserts;
          first->n_updates += row->n_updates;
          first->n_deletes += row->n_deletes;
          first->n_schemaops += row->n_schemaops;
        }
        ndb_binlog_index->field[NBICOL_NUM_INSERTS]->store(
            (ulonglong)first->n_inserts, true);
        ndb_binlog_index->field[NBICOL_NUM_UPDATES]->store(
            (ulonglong)first->n_updates, true);
        ndb_binlog_index->field[NBICOL_NUM_DELETES]->store(
            (ulonglong)first->n_deletes, true);
        ndb_binlog_index->field[NBICOL_NUM_SCHEMAOPS]->store(
            (ulonglong)first->n_schemaops, true);
      }

      error = ndb_binlog_index->file->ha_write_row(ndb_binlog_index->record[0]);

      /* Fault injection to test logging */
      if (DBUG_EVALUATE_IF("ndb_injector_binlog_index_write_fail_random", true,
                           false)) {
        if ((((uint32)rand()) % 10) == 9) {
          ndb_log_error("Binlog: Injecting random write failure");
          error =
              ndb_binlog_index->file->ha_write_row(ndb_binlog_index->record[0]);
        }
      }

      if (error) {
        ndb_log_error(
            "Binlog: Failed writing to ndb_binlog_index for "
            "epoch %u/%u orig_server_id %u orig_epoch %u/%u "
            "with error %d.",
            uint(epoch >> 32), uint(epoch), orig_server_id,
            uint(orig_epoch >> 32), uint(orig_epoch), error);

        bool seen_error_row = false;
        ndb_binlog_index_row *cursor = first;
        do {
          char tmp[128];
          if (ndb_binlog_index->s->fields > NBICOL_ORIG_SERVERID)
            snprintf(tmp, sizeof(tmp), "%u/%u,%u,%u/%u", uint(epoch >> 32),
                     uint(epoch), uint(cursor->orig_server_id),
                     uint(cursor->orig_epoch >> 32), uint(cursor->orig_epoch));

          else
            snprintf(tmp, sizeof(tmp), "%u/%u", uint(epoch >> 32), uint(epoch));

          bool error_row = (row == (cursor->next));
          ndb_log_error(
              "Binlog: Writing row (%s) to ndb_binlog_index - %s", tmp,
              (error_row ? "ERROR" : (seen_error_row ? "Discarded" : "OK")));
          seen_error_row |= error_row;

        } while ((cursor = cursor->next));

        error = -1;
        goto add_ndb_binlog_index_err;
      }
    } while (row);

  add_ndb_binlog_index_err:
    /*
      Explicitly commit or rollback the writes.
      If we fail to commit we rollback.
      Note, trans_rollback_stmt() is defined to never fail.
    */
    thd->get_stmt_da()->set_overwrite_status(true);
    if (error) {
      // Error, rollback
      trans_rollback_stmt(thd);
    } else {
      assert(!thd->is_error());
      // Commit
      const bool failed = trans_commit_stmt(thd);
      if (failed || thd->transaction_rollback_request) {
        /*
          Transaction failed to commit or
          was rolled back internally by the engine
          print an error message in the log and return the
          error, which will cause replication to stop.
        */
        error = thd->get_stmt_da()->mysql_errno();
        ndb_log_error(
            "Binlog: Failed committing transaction to "
            "ndb_binlog_index with error %d.",
            error);
        trans_rollback_stmt(thd);
      }
    }

    thd->get_stmt_da()->set_overwrite_status(false);

    // Restore previous option settings
    thd->variables.option_bits = option_bits;

    // Close the tables this thread has opened
    close_thread_tables(thd);

    // Release MDL locks on the opened table
    thd->mdl_context.release_transactional_locks();

    return error;
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/ndb/plugin/ha_ndbcluster_binlog.cc
Function: Ndb_binlog_index_table_util::remove_rows_for_file
  static bool remove_rows_for_file(THD *thd, const char *filename) {
    Ndb_local_connection mysqld(thd);

    // Set isolation level to be independent from server settings
    thd->variables.transaction_isolation = ISO_REPEATABLE_READ;

    // Turn autocommit on, this will make delete_rows() commit
    thd->variables.option_bits &= ~OPTION_NOT_AUTOCOMMIT;

    // Ensure that file paths are escaped in a way that does not
    // interfere with path separator on Windows
    thd->variables.sql_mode |= MODE_NO_BACKSLASH_ESCAPES;

    // ignore "table does not exist" as it is a "consistent" behavior
    const bool ignore_no_such_table = true;
    std::string where;
    where.append("File='").append(filename).append("'");
    if (mysqld.delete_rows(DB_NAME, TABLE_NAME, ignore_no_such_table, where)) {
      // Failed
      return true;
    }
    return false;
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/server_component/mysql_system_variable_update_imp.cc
Function: prepare_thread_and_validate not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/server_component/mysql_system_variable_update_imp.cc
Function: prepare_thread_and_validate not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/ndb/plugin/ndb_dd_client.cc
Function: Ndb_dd_client::mdl_locks_acquire_exclusive
bool Ndb_dd_client::mdl_locks_acquire_exclusive(const char *schema_name,
                                                const char *table_name,
                                                bool custom_lock_wait,
                                                ulong lock_wait_timeout) {
  MDL_request_list mdl_requests;
  MDL_request schema_request;
  MDL_request mdl_request;
  MDL_request backup_lock_request;
  MDL_request grl_request;

  // If we cannot acquire protection against GRL, err out early.
  if (m_thd->global_read_lock.can_acquire_protection()) return false;

  MDL_REQUEST_INIT(&schema_request, MDL_key::SCHEMA, schema_name, "",
                   MDL_INTENTION_EXCLUSIVE, MDL_EXPLICIT);
  MDL_REQUEST_INIT(&mdl_request, MDL_key::TABLE, schema_name, table_name,
                   MDL_EXCLUSIVE, MDL_EXPLICIT);
  MDL_REQUEST_INIT(&backup_lock_request, MDL_key::BACKUP_LOCK, "", "",
                   MDL_INTENTION_EXCLUSIVE, MDL_EXPLICIT);
  MDL_REQUEST_INIT(&grl_request, MDL_key::GLOBAL, "", "",
                   MDL_INTENTION_EXCLUSIVE, MDL_EXPLICIT);

  mdl_requests.push_front(&schema_request);
  mdl_requests.push_front(&mdl_request);
  mdl_requests.push_front(&backup_lock_request);
  mdl_requests.push_front(&grl_request);

  if (!custom_lock_wait) {
    lock_wait_timeout = m_thd->variables.lock_wait_timeout;
  }

  if (!mdl_locks_acquire(mdl_requests, lock_wait_timeout)) {
    return false;
  }

  /*
    Now when we have protection against concurrent change of read_only
    option we can safely re-check its value.
  */
  if (check_readonly(m_thd, true)) return false;

  return true;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/ndb/plugin/ndb_dd_client.cc
Function: Ndb_dd_client::
   Copyright (c) 2017, 2023, Oracle and/or its affiliates.

   This program is free software; you can redistribute it and/or modify
   it under the terms of the GNU General Public License, version 2.0,
   as published by the Free Software Foundation.

   This program is also distributed with certain software (including
   but not limited to OpenSSL) that is licensed under separate terms,
   as designated in a particular file or component or in included license
   documentation.  The authors of MySQL hereby grant you an additional
   permission to link the program and your derivative works with the
   separately licensed software that they have included with MySQL.

   This program is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   GNU General Public License, version 2.0, for more details.

   You should have received a copy of the GNU General Public License
   along with this program; if not, write to the Free Software
   Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301  USA
*/

#include "storage/ndb/plugin/ndb_dd_client.h"

#include <assert.h>

#include <iostream>

#include "my_dbug.h"
#include "my_psi_config.h"         // HAVE_PSI_SP_INTERFACE
#include "sql/auth/auth_common.h"  // check_readonly()
#include "sql/dd/cache/dictionary_client.h"
#include "sql/dd/dd.h"
#include "sql/dd/dd_table.h"
#include "sql/dd/properties.h"
#include "sql/dd/types/schema.h"
#include "sql/dd/types/table.h"
#include "sql/query_options.h"  // OPTION_AUTOCOMMIT
#include "sql/sql_class.h"      // THD
#include "sql/sql_table.h"
#include "sql/sql_trigger.h"  // remove_all_triggers_from_perfschema
#include "sql/system_variables.h"
#include "sql/transaction.h"            // trans_*
#include "storage/ndb/plugin/ndb_dd.h"  // ndb_dd_fs_name_case
#include "storage/ndb/plugin/ndb_dd_disk_data.h"
#include "storage/ndb/plugin/ndb_dd_schema.h"
#include "storage/ndb/plugin/ndb_dd_sdi.h"
#include "storage/ndb/plugin/ndb_dd_table.h"
#include "storage/ndb/plugin/ndb_dd_upgrade_table.h"
#include "storage/ndb/plugin/ndb_fk_util.h"
#include "storage/ndb/plugin/ndb_log.h"
#include "storage/ndb/plugin/ndb_pfs_init.h"
#include "storage/ndb/plugin/ndb_schema_dist_table.h"
#include "storage/ndb/plugin/ndb_thd.h"

constexpr size_t NDB_DD_CLIENT_MEMROOT_BLOCK_SIZE = 1024;

Ndb_dd_client::Ndb_dd_client(THD *thd)
    : m_thd(thd),
      m_client(thd->dd_client()),
      m_save_mdl_locks(thd->mdl_context.mdl_savepoint()),
      m_dd_mem_root(key_memory_ndb_dd_client_mem_root,
                    NDB_DD_CLIENT_MEMROOT_BLOCK_SIZE),
      m_prev_mem_root(thd->mem_root) {
  DBUG_TRACE;
  disable_autocommit();

  // Create dictionary client auto releaser, stored as
  // opaque pointer in order to avoid including all of
  // Dictionary_client in the ndb_dd_client header file
  m_auto_releaser =
      (void *)new dd::cache::Dictionary_client::Auto_releaser(m_client);

  // Use dedicated MEM_ROOT while acessing DD
  thd->mem_root = &m_dd_mem_root;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/ndb/plugin/ndb_dd_client.cc
Function: Ndb_dd_client::disable_autocommit
void Ndb_dd_client::disable_autocommit() {
  /*
    Implementation details from which storage the DD uses leaks out
    and the user of these functions magically need to turn auto commit
    off.

    I.e as in sql_table.cc, execute_ddl_log_recovery()
     'Prevent InnoDB from automatically committing InnoDB transaction
      each time data-dictionary tables are closed after being updated.'
  */

  // Don't allow empty bits as zero is used as indicator
  // to restore the saved bits
  assert(m_thd->variables.option_bits);
  m_save_option_bits = m_thd->variables.option_bits;

  m_thd->variables.option_bits &= ~OPTION_AUTOCOMMIT;
  m_thd->variables.option_bits |= OPTION_NOT_AUTOCOMMIT;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/session_tracker.cc
Function: Transaction_state_tracker::add_trx_state
void Transaction_state_tracker::add_trx_state(THD *thd, uint add) {
  // We no longer test for m_enabled here as we now always track (just don't
  // always report to the client).
  if (thd->state_flags & Open_tables_state::BACKUPS_AVAIL) return;

  if (add == TX_EXPLICIT) {
    /*
      Always send chistics item (if tracked), always replace state.
    */
    tx_changed |= TX_CHG_CHISTICS;
    tx_curr_state = TX_EXPLICIT;
  }

  /*
    If we're not in an implicit or explicit transaction, but
    autocommit==0 and tables are accessed, we flag "implicit transaction."
  */
  else if (!(tx_curr_state & (TX_EXPLICIT | TX_IMPLICIT)) &&
           (thd->variables.option_bits & OPTION_NOT_AUTOCOMMIT) &&
           (add &
            (TX_READ_TRX | TX_READ_UNSAFE | TX_WRITE_TRX | TX_WRITE_UNSAFE)))
    tx_curr_state |= TX_IMPLICIT;

  /*
    Only flag state when in transaction or LOCK TABLES is added.
  */
  if ((tx_curr_state & (TX_EXPLICIT | TX_IMPLICIT)) ||
      (add & TX_LOCKED_TABLES) || (add == TX_STMT_DML))
    tx_curr_state |= add;

  update_change_flags(thd);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sp_head.cc
Function: sp_head::execute_function
bool sp_head::execute_function(THD *thd, Item **argp, uint argcount,
                               Field *return_value_fld) {
  ulonglong binlog_save_options = 0;
  bool need_binlog_call = false;
  uint arg_no;
  sp_rcontext *parent_sp_runtime_ctx = thd->sp_runtime_ctx;
  char buf[STRING_BUFFER_USUAL_SIZE];
  String binlog_buf(buf, sizeof(buf), &my_charset_bin);
  bool err_status = false;
  /*
    Prepare arena and memroot for objects which lifetime is whole
    duration of function call (sp_rcontext, it's tables and items,
    sp_cursor and Item_cache holders for case expressions).
    We can't use caller's arena/memroot for those objects because
    in this case some fixed amount of memory will be consumed for
    each function/trigger invocation and so statements which involve
    lot of them will hog memory.
    TODO: we should create sp_rcontext once per command and reuse
    it on subsequent executions of a function/trigger.
  */
  MEM_ROOT call_mem_root(key_memory_sp_head_call_root, MEM_ROOT_BLOCK_SIZE);
  Query_arena call_arena(&call_mem_root, Query_arena::STMT_INITIALIZED_FOR_SP);
  Query_arena backup_arena;

  DBUG_TRACE;
  DBUG_PRINT("info", ("function %s", m_name.str));

  // Resetting THD::where to its default value
  thd->where = THD::DEFAULT_WHERE;

  // Number of arguments has been checked during resolving
  assert(argcount == m_root_parsing_ctx->context_var_count());

  thd->swap_query_arena(call_arena, &backup_arena);

  sp_rcontext *func_runtime_ctx =
      sp_rcontext::create(thd, m_root_parsing_ctx, return_value_fld);

  if (!func_runtime_ctx) {
    thd->swap_query_arena(backup_arena, &call_arena);
    err_status = true;
    goto err_with_cleanup;
  }

  func_runtime_ctx->sp = this;

  /*
    We have to switch temporarily back to callers arena/memroot.
    Function arguments belong to the caller and so the may reference
    memory which they will allocate during calculation long after
    this function call will be finished (e.g. in Item::cleanup()).
  */
  thd->swap_query_arena(backup_arena, &call_arena);

  /*
    Pass arguments.

    Note, THD::sp_runtime_ctx must not be switched before the arguments are
    passed. Values are taken from the caller's runtime context and set to the
    runtime context of this function.
  */
  for (arg_no = 0; arg_no < argcount; arg_no++) {
    /* Arguments must be fixed in Item_func_sp::fix_fields */
    assert(argp[arg_no]->fixed);

    err_status = func_runtime_ctx->set_variable(thd, arg_no, &(argp[arg_no]));

    if (err_status) goto err_with_cleanup;
  }

  /*
    If row-based binlogging, we don't need to binlog the function's call, let
    each substatement be binlogged its way.
  */
  need_binlog_call = mysql_bin_log.is_open() &&
                     (thd->variables.option_bits & OPTION_BIN_LOG) &&
                     !thd->is_current_stmt_binlog_format_row();

  /*
    Remember the original arguments for unrolled replication of functions
    before they are changed by execution.

    Note, THD::sp_runtime_ctx must not be switched before the arguments are
    logged. Values are taken from the caller's runtime context.
  */
  if (need_binlog_call) {
    binlog_buf.length(0);
    binlog_buf.append(STRING_WITH_LEN("SELECT "));
    append_identifier(thd, &binlog_buf, m_db.str, m_db.length);
    binlog_buf.append('.');
    append_identifier(thd, &binlog_buf, m_name.str, m_name.length);
    binlog_buf.append('(');
    for (arg_no = 0; arg_no < argcount; arg_no++) {
      String str_value_holder;
      String *str_value;

      if (arg_no) binlog_buf.append(',');

      str_value = sp_get_item_value(thd, func_runtime_ctx->get_item(arg_no),
                                    &str_value_holder);

      if (str_value)
        binlog_buf.append(*str_value);
      else
        binlog_buf.append(STRING_WITH_LEN("NULL"));
    }
    binlog_buf.append(')');
  }

  thd->sp_runtime_ctx = func_runtime_ctx;

  Security_context *save_security_ctx;
  if (set_security_ctx(thd, &save_security_ctx)) {
    err_status = true;
    goto err_with_cleanup;
  }

  if (need_binlog_call) {
    query_id_t q;
    thd->user_var_events.clear();
    /*
      In case of artificially constructed events for function calls
      we have separate union for each such event and hence can't use
      query_id of real calling statement as the start of all these
      unions (this will break logic of replication of user-defined
      variables). So we use artificial value which is guaranteed to
      be greater than all query_id's of all statements belonging
      to previous events/unions.
      Possible alternative to this is logging of all function invocations
      as one select and not resetting THD::user_var_events before
      each invocation.
    */
    q = atomic_global_query_id;
    mysql_bin_log.start_union_events(thd, q + 1);
    binlog_save_options = thd->variables.option_bits;
    thd->variables.option_bits &= ~OPTION_BIN_LOG;
  }

  opt_trace_disable_if_no_stored_proc_func_access(thd, this);

  /*
    Switch to call arena/mem_root so objects like sp_cursor or
    Item_cache holders for case expressions can be allocated on it.

    TODO: In future we should associate call arena/mem_root with
          sp_rcontext and allocate all these objects (and sp_rcontext
          itself) on it directly rather than juggle with arenas.
  */
  thd->swap_query_arena(call_arena, &backup_arena);

#ifdef HAVE_PSI_SP_INTERFACE
  PSI_sp_locker_state psi_state;
  PSI_sp_locker *locker;

  locker = MYSQL_START_SP(&psi_state, m_sp_share);
#endif
  err_status = execute(thd, true);
#ifdef HAVE_PSI_SP_INTERFACE
  MYSQL_END_SP(locker);
#endif

  thd->swap_query_arena(backup_arena, &call_arena);

  if (need_binlog_call) {
    mysql_bin_log.stop_union_events(thd);
    thd->variables.option_bits = binlog_save_options;
    if (thd->binlog_evt_union.unioned_events) {
      int errcode = query_error_code(thd, thd->killed == THD::NOT_KILLED);
      Query_log_event qinfo(thd, binlog_buf.ptr(), binlog_buf.length(),
                            thd->binlog_evt_union.unioned_events_trans, false,
                            false, errcode);
      if (mysql_bin_log.write_event(&qinfo) &&
          thd->binlog_evt_union.unioned_events_trans) {
        push_warning(thd, Sql_condition::SL_WARNING, ER_UNKNOWN_ERROR,
                     "Invoked ROUTINE modified a transactional table but MySQL "
                     "failed to reflect this change in the binary log");
        err_status = true;
      }
      thd->user_var_events.clear();
      /* Forget those values, in case more function calls are binlogged: */
      thd->stmt_depends_on_first_successful_insert_id_in_prev_stmt = false;
      thd->auto_inc_intervals_in_cur_stmt_for_binlog.clear();
    }
  }

  if (!err_status) {
    /* We need result only in function but not in trigger */

    if (!thd->sp_runtime_ctx->is_return_value_set()) {
      my_error(ER_SP_NORETURNEND, MYF(0), m_name.str);
      err_status = true;
    }
  }

  m_security_ctx.restore_security_context(thd, save_security_ctx);

err_with_cleanup:
  ::destroy(func_runtime_ctx);
  call_arena.free_items();
  call_mem_root.Clear();
  thd->sp_runtime_ctx = parent_sp_runtime_ctx;

  /*
    If not inside a procedure and a function printing warning
    messages.
  */
  if (need_binlog_call && thd->sp_runtime_ctx == nullptr &&
      !thd->binlog_evt_union.do_union)
    thd->issue_unsafe_warnings();

  return err_status;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sp_head.cc
Function: sp_head::execute_procedure
bool sp_head::execute_procedure(THD *thd, mem_root_deque<Item *> *args) {
  bool err_status = false;
  uint params = m_root_parsing_ctx->context_var_count();
  /* Query start time may be reset in a multi-stmt SP; keep this for later. */
  ulonglong lock_usec_before_sp_exec;
  thd->push_lock_usec(lock_usec_before_sp_exec);
  sp_rcontext *parent_sp_runtime_ctx = thd->sp_runtime_ctx;
  sp_rcontext *sp_runtime_ctx_saved = thd->sp_runtime_ctx;
  bool save_enable_slow_log = false;
  bool save_log_general = false;

  DBUG_TRACE;
  DBUG_PRINT("info", ("procedure %s", m_name.str));

  // Argument count has been validated in prepare function.
  assert((args != nullptr ? args->size() : 0) == params);

  if (!parent_sp_runtime_ctx) {
    // Create a temporary old context. We need it to pass OUT-parameter values.
    parent_sp_runtime_ctx =
        sp_rcontext::create(thd, m_root_parsing_ctx, nullptr);

    if (!parent_sp_runtime_ctx) return true;

    parent_sp_runtime_ctx->sp = nullptr;
    thd->sp_runtime_ctx = parent_sp_runtime_ctx;

    /* set callers_arena to thd, for upper-level function to work */
    thd->sp_runtime_ctx->callers_arena = thd;
  }

  sp_rcontext *proc_runtime_ctx =
      sp_rcontext::create(thd, m_root_parsing_ctx, nullptr);

  if (!proc_runtime_ctx) {
    thd->sp_runtime_ctx = sp_runtime_ctx_saved;

    if (!sp_runtime_ctx_saved) ::destroy(parent_sp_runtime_ctx);

    return true;
  }

  proc_runtime_ctx->sp = this;

  if (params > 0) {
    auto it_args = args->begin();

    DBUG_PRINT("info", (" %.*s: eval args", (int)m_name.length, m_name.str));

    for (uint i = 0; i < params; ++i, ++it_args) {
      Item *arg_item = *it_args;
      if (!arg_item) break;

      sp_variable *spvar = m_root_parsing_ctx->find_variable(i);

      if (!spvar) continue;

      if (spvar->mode != sp_variable::MODE_IN) {
        Settable_routine_parameter *srp =
            arg_item->get_settable_routine_parameter();

        if (!srp) {
          my_error(ER_SP_NOT_VAR_ARG, MYF(0), i + 1, m_qname.str);
          err_status = true;
          break;
        }
      }

      if (spvar->mode == sp_variable::MODE_OUT) {
        Item_null *null_item = new Item_null();

        if (!null_item ||
            proc_runtime_ctx->set_variable(thd, i, (Item **)&null_item)) {
          err_status = true;
          break;
        }
      } else {
        if (proc_runtime_ctx->set_variable(thd, i, &*it_args)) {
          err_status = true;
          break;
        }
      }

      if (thd->variables.session_track_transaction_info > TX_TRACK_NONE) {
        TX_TRACKER_GET(tst);
        tst->add_trx_state_from_thd(thd);
      }
    }

    /*
      Okay, got values for all arguments. Close tables that might be used by
      arguments evaluation. If arguments evaluation required prelocking mode,
      we'll leave it here.
    */
    thd->lex->cleanup(true);

    if (!thd->in_sub_stmt) {
      thd->get_stmt_da()->set_overwrite_status(true);
      thd->is_error() ? trans_rollback_stmt(thd) : trans_commit_stmt(thd);
      thd->get_stmt_da()->set_overwrite_status(false);
    }

    thd_proc_info(thd, "closing tables");
    close_thread_tables(thd);
    thd_proc_info(thd, nullptr);

    if (!thd->in_sub_stmt) {
      if (thd->transaction_rollback_request) {
        trans_rollback_implicit(thd);
        thd->mdl_context.release_transactional_locks();
      } else if (!thd->in_multi_stmt_transaction_mode())
        thd->mdl_context.release_transactional_locks();
      else
        thd->mdl_context.release_statement_locks();
    }

    thd->rollback_item_tree_changes();

    DBUG_PRINT("info",
               (" %.*s: eval args done", (int)m_name.length, m_name.str));
  }
  if (!(m_flags & LOG_SLOW_STATEMENTS) && thd->enable_slow_log) {
    DBUG_PRINT("info", ("Disabling slow log for the execution"));
    save_enable_slow_log = true;
    thd->enable_slow_log = false;
  }
  if (!(m_flags & LOG_GENERAL_LOG) &&
      !(thd->variables.option_bits & OPTION_LOG_OFF)) {
    DBUG_PRINT("info", ("Disabling general log for the execution"));
    save_log_general = true;
    /* disable this bit */
    thd->variables.option_bits |= OPTION_LOG_OFF;
  }
  thd->sp_runtime_ctx = proc_runtime_ctx;

  Security_context *save_security_ctx = nullptr;
  if (!err_status) err_status = set_security_ctx(thd, &save_security_ctx);

  opt_trace_disable_if_no_stored_proc_func_access(thd, this);

#ifdef HAVE_PSI_SP_INTERFACE
  PSI_sp_locker_state psi_state;
  PSI_sp_locker *locker;

  locker = MYSQL_START_SP(&psi_state, m_sp_share);
#endif
  if (!err_status) err_status = execute(thd, true);
#ifdef HAVE_PSI_SP_INTERFACE
  MYSQL_END_SP(locker);
#endif

  if (save_log_general) thd->variables.option_bits &= ~OPTION_LOG_OFF;
  if (save_enable_slow_log) thd->enable_slow_log = true;
  /*
    In the case when we weren't able to employ reuse mechanism for
    OUT/INOUT parameters, we should reallocate memory. This
    allocation should be done on the arena which will live through
    all execution of calling routine.
  */
  thd->sp_runtime_ctx->callers_arena = parent_sp_runtime_ctx->callers_arena;

  if (!err_status && params > 0) {
    auto it_args = args->cbegin();

    /*
      Copy back all OUT or INOUT values to the previous frame, or
      set global user variables
    */
    for (uint i = 0; i < params; i++) {
      Item *arg_item = *it_args++;

      if (!arg_item) break;

      sp_variable *spvar = m_root_parsing_ctx->find_variable(i);

      if (spvar->mode == sp_variable::MODE_IN) continue;

      Settable_routine_parameter *srp =
          arg_item->get_settable_routine_parameter();

      assert(srp);

      if (srp->set_value(thd, parent_sp_runtime_ctx,
                         proc_runtime_ctx->get_item_addr(i))) {
        err_status = true;
        break;
      }

      Send_field *out_param_info = new (thd->mem_root) Send_field();
      proc_runtime_ctx->get_item(i)->make_field(out_param_info);
      out_param_info->db_name = m_db.str;
      out_param_info->table_name = m_name.str;
      out_param_info->org_table_name = m_name.str;
      out_param_info->col_name = spvar->name.str;
      out_param_info->org_col_name = spvar->name.str;

      srp->set_out_param_info(out_param_info);
    }
  }

  if (save_security_ctx)
    m_security_ctx.restore_security_context(thd, save_security_ctx);

  if (!sp_runtime_ctx_saved) ::destroy(parent_sp_runtime_ctx);

  ::destroy(proc_runtime_ctx);
  thd->sp_runtime_ctx = sp_runtime_ctx_saved;
  thd->pop_lock_usec(lock_usec_before_sp_exec);

  /*
    If not inside a procedure and a function printing warning
    messages.
  */
  bool need_binlog_call = mysql_bin_log.is_open() &&
                          (thd->variables.option_bits & OPTION_BIN_LOG) &&
                          !thd->is_current_stmt_binlog_format_row();
  if (need_binlog_call && thd->sp_runtime_ctx == nullptr &&
      !thd->binlog_evt_union.do_union)
    thd->issue_unsafe_warnings();

  return err_status;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.h
Function: THD::in_multi_stmt_transaction_mode
  inline bool in_multi_stmt_transaction_mode() const {
    return variables.option_bits & (OPTION_NOT_AUTOCOMMIT | OPTION_BEGIN);
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::is_secondary_storage_engine_eligible
bool THD::is_secondary_storage_engine_eligible() const {
  // STATEMENT based replication is enabled and the statement is CTAS or
  // INSERT INTO SELECT
  if (variables.binlog_format == BINLOG_FORMAT_STMT &&
      (lex->sql_command == SQLCOM_CREATE_TABLE ||
       lex->sql_command == SQLCOM_INSERT_SELECT))
    return false;
  // Secondary engines had been disabled in the session
  if (secondary_engine_optimization() ==
      Secondary_engine_optimization::PRIMARY_ONLY)
    return false;
  // The user has explicitly disabled secondary engines
  if (variables.use_secondary_engine == SECONDARY_ENGINE_OFF) return false;
  // LOCK TABLES mode is active
  if (locked_tables_mode != LTM_NONE) return false;
  // Multi-statement transaction mode is active and the statement is not a
  // CREATE TABLE AS SELECT (these are safe due to COMMIT being run before
  // and after the statement is executed)
  if ((in_multi_stmt_transaction_mode() &&
       lex->sql_command != SQLCOM_CREATE_TABLE))
    return false;
  //  It is a sub-statement of a stored procedure
  if (sp_runtime_ctx != nullptr) return false;
  return true;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Transaction_state::restore not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Transaction_state::restore not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Transaction_state::backup not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Transaction_state::backup not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Transaction_state::backup not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Transaction_state::restore not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Transaction_state::restore not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::Attachable_trx::Attachable_trx not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::init
void THD::init(void) {
  plugin_thdvar_init(this, m_enable_plugins);
  /*
    variables= global_system_variables above has reset
    variables.pseudo_thread_id to 0. We need to correct it here to
    avoid temporary tables replication failure.
  */
  variables.pseudo_thread_id = m_thread_id;

  /*
    NOTE: reset_connection command will reset the THD to its default state.
    All system variables whose scope is SESSION ONLY should be set to their
    default values here.
  */
  reset_first_successful_insert_id();
  user_time.tv_sec = user_time.tv_usec = 0;
  start_time.tv_sec = start_time.tv_usec = 0;
  set_time();
  auto_inc_intervals_forced.clear();
  {
    ulong tmp;
    tmp = sql_rnd_with_mutex();
    randominit(&rand,
               tmp + static_cast<ulong>(reinterpret_cast<uintptr_t>(&rand)),
               tmp + (ulong)::atomic_global_query_id);
  }

  server_status = SERVER_STATUS_AUTOCOMMIT;
  if (variables.sql_mode & MODE_NO_BACKSLASH_ESCAPES)
    server_status |= SERVER_STATUS_NO_BACKSLASH_ESCAPES;

  get_transaction()->reset_unsafe_rollback_flags(Transaction_ctx::SESSION);
  get_transaction()->reset_unsafe_rollback_flags(Transaction_ctx::STMT);
  open_options = ha_open_options;
  update_lock_default =
      (variables.low_priority_updates ? TL_WRITE_LOW_PRIORITY : TL_WRITE);
  insert_lock_default =
      (variables.low_priority_updates ? TL_WRITE_LOW_PRIORITY
                                      : TL_WRITE_CONCURRENT_INSERT);
  tx_isolation = (enum_tx_isolation)variables.transaction_isolation;
  tx_read_only = variables.transaction_read_only;
  tx_priority = 0;
  thd_tx_priority = 0;
  update_charset();
  reset_current_stmt_binlog_format_row();
  reset_binlog_local_stmt_filter();
  memset(&status_var, 0, sizeof(status_var));
  binlog_row_event_extra_data = nullptr;

  if (variables.sql_log_bin)
    variables.option_bits |= OPTION_BIN_LOG;
  else
    variables.option_bits &= ~OPTION_BIN_LOG;

#if defined(ENABLED_DEBUG_SYNC)
  /* Initialize the Debug Sync Facility. See debug_sync.cc. */
  debug_sync_init_thread(this);
#endif /* defined(ENABLED_DEBUG_SYNC) */

  /* Initialize session_tracker and create all tracker objects */
  session_tracker.init(this->charset());
  session_tracker.enable(this);

  owned_gtid.clear();
  owned_sid.clear();
  m_se_gtid_flags.reset();
  owned_gtid.dbug_print(nullptr, "set owned_gtid (clear) in THD::init");

  /*
    This will clear the writeset session history and re-set delegate state to
    INIT
  */
  rpl_thd_ctx.init();

  /*
    This variable is used to temporarily disable the password validation plugin
    when a RANDOM PASSWORD is generated during SET PASSWORD,CREATE USER or
    ALTER USER statements.
  */
  m_disable_password_validation = false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::copy_table_access_properties
void THD::copy_table_access_properties(THD *thd) {
  thread_stack = thd->thread_stack;
  variables.option_bits = thd->variables.option_bits & OPTION_BIN_LOG;
  skip_readonly_check = thd->skip_readonly_check;
  tx_isolation = thd->tx_isolation;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::raise_condition not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::raise_condition not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::raise_condition not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::raise_condition not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::raise_note
void THD::raise_note(uint sql_errno) {
  DBUG_TRACE;
  DBUG_PRINT("enter", ("code: %d", sql_errno));
  if (!(variables.option_bits & OPTION_SQL_NOTES)) return;
  const char *msg = ER_THD_NONCONST(this, sql_errno);
  (void)raise_condition(sql_errno, nullptr, Sql_condition::SL_NOTE, msg);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::raise_note_printf
void THD::raise_note_printf(uint sql_errno, ...) {
  va_list args;
  char ebuff[MYSQL_ERRMSG_SIZE];
  DBUG_TRACE;
  DBUG_PRINT("enter", ("code: %u", sql_errno));
  if (!(variables.option_bits & OPTION_SQL_NOTES)) return;
  const char *format = ER_THD_NONCONST(this, sql_errno);
  va_start(args, sql_errno);
  vsnprintf(ebuff, sizeof(ebuff), format, args);
  va_end(args);
  (void)raise_condition(sql_errno, nullptr, Sql_condition::SL_NOTE, ebuff);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::reset_sub_statement_state
void THD::reset_sub_statement_state(Sub_statement_state *backup,
                                    uint new_state) {
  backup->option_bits = variables.option_bits;
  backup->check_for_truncated_fields = check_for_truncated_fields;
  backup->in_sub_stmt = in_sub_stmt;
  backup->enable_slow_log = enable_slow_log;
  backup->current_found_rows = current_found_rows;
  backup->previous_found_rows = previous_found_rows;
  backup->examined_row_count = m_examined_row_count;
  backup->sent_row_count = m_sent_row_count;
  backup->num_truncated_fields = num_truncated_fields;
  backup->client_capabilities = m_protocol->get_client_capabilities();
  backup->savepoints = get_transaction()->m_savepoints;
  backup->first_successful_insert_id_in_prev_stmt =
      first_successful_insert_id_in_prev_stmt;
  backup->first_successful_insert_id_in_cur_stmt =
      first_successful_insert_id_in_cur_stmt;

  if ((!lex->requires_prelocking() || is_update_query(lex->sql_command)) &&
      !is_current_stmt_binlog_format_row()) {
    variables.option_bits &= ~OPTION_BIN_LOG;
  }

  if ((backup->option_bits & OPTION_BIN_LOG) &&
      is_update_query(lex->sql_command) && !is_current_stmt_binlog_format_row())
    mysql_bin_log.start_union_events(this, this->query_id);

  /* Disable result sets */
  if (is_classic_protocol())
    get_protocol_classic()->remove_client_capability(CLIENT_MULTI_RESULTS);
  in_sub_stmt |= new_state;
  m_examined_row_count = 0;
  m_sent_row_count = 0;
  num_truncated_fields = 0;
  get_transaction()->m_savepoints = nullptr;
  first_successful_insert_id_in_cur_stmt = 0;

  /* Reset savepoint on transaction write set */
  if (is_current_stmt_binlog_row_enabled_with_write_set_extraction()) {
    get_transaction()->get_transaction_write_set_ctx()->reset_savepoint_list();
  }
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::restore_sub_statement_state
void THD::restore_sub_statement_state(Sub_statement_state *backup) {
  DBUG_TRACE;

  /*
    To save resources we want to release savepoints which were created
    during execution of function or trigger before leaving their savepoint
    level. It is enough to release first savepoint set on this level since
    all later savepoints will be released automatically.
  */
  if (get_transaction()->m_savepoints) {
    SAVEPOINT *sv;
    for (sv = get_transaction()->m_savepoints; sv->prev; sv = sv->prev) {
    }
    /* ha_release_savepoint() never returns error. */
    (void)ha_release_savepoint(this, sv);
  }
  check_for_truncated_fields = backup->check_for_truncated_fields;
  get_transaction()->m_savepoints = backup->savepoints;
  variables.option_bits = backup->option_bits;
  in_sub_stmt = backup->in_sub_stmt;
  enable_slow_log = backup->enable_slow_log;
  first_successful_insert_id_in_prev_stmt =
      backup->first_successful_insert_id_in_prev_stmt;
  first_successful_insert_id_in_cur_stmt =
      backup->first_successful_insert_id_in_cur_stmt;
  current_found_rows = backup->current_found_rows;
  previous_found_rows = backup->previous_found_rows;
  set_sent_row_count(backup->sent_row_count);
  if (is_classic_protocol())
    get_protocol_classic()->set_client_capabilities(
        backup->client_capabilities);

  /*
    If we've left sub-statement mode, reset the fatal error flag.
    Otherwise keep the current value, to propagate it up the sub-statement
    stack.

    NOTE: is_fatal_sub_stmt_error can be set only if we've been in the
    sub-statement mode.
  */

  if (!in_sub_stmt) is_fatal_sub_stmt_error = false;

  if ((variables.option_bits & OPTION_BIN_LOG) &&
      is_update_query(lex->sql_command) && !is_current_stmt_binlog_format_row())
    mysql_bin_log.stop_union_events(this);

  /*
    The below assert mostly serves as reminder that optimization in
    DML_prelocking_strategy::handle_table() relies on the fact
    that stored function/trigger can't change FOREIGN_KEY_CHECKS
    value for the top-level statement which invokes them.
  */
  assert((variables.option_bits & OPTION_NO_FOREIGN_KEY_CHECKS) ==
         (backup->option_bits & OPTION_NO_FOREIGN_KEY_CHECKS));

  /*
    The following is added to the old values as we are interested in the
    total complexity of the query
  */
  inc_examined_row_count(backup->examined_row_count);
  num_truncated_fields += backup->num_truncated_fields;

  /* Restore savepoint on transaction write set */
  if (is_current_stmt_binlog_row_enabled_with_write_set_extraction()) {
    get_transaction()
        ->get_transaction_write_set_ctx()
        ->restore_savepoint_list();
  }
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_class.cc
Function: THD::is_current_stmt_binlog_disabled
bool THD::is_current_stmt_binlog_disabled() const {
  return (!(variables.option_bits & OPTION_BIN_LOG) ||
          !mysql_bin_log.is_open());
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: check_transaction_read_only
static bool check_transaction_read_only(sys_var *, THD *thd, set_var *var) {
  if (var->type == OPT_DEFAULT &&
      (thd->in_active_multi_stmt_transaction() || thd->in_sub_stmt)) {
    assert(thd->in_multi_stmt_transaction_mode() || thd->in_sub_stmt);
    my_error(ER_CANT_CHANGE_TX_CHARACTERISTICS, MYF(0));
    return true;
  }
  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: check_transaction_isolation
static bool check_transaction_isolation(sys_var *, THD *thd, set_var *var) {
  if (var->type == OPT_DEFAULT &&
      (thd->in_active_multi_stmt_transaction() || thd->in_sub_stmt)) {
    assert(thd->in_multi_stmt_transaction_mode() || thd->in_sub_stmt);
    my_error(ER_CANT_CHANGE_TX_CHARACTERISTICS, MYF(0));
    return true;
  }
  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: fix_sql_log_bin_after_update not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: fix_sql_log_bin_after_update not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: fix_sql_log_bin_after_update not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: fix_sql_log_bin_after_update not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: fix_sql_log_bin_after_update not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: fix_sql_log_bin_after_update not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: fix_sql_log_bin_after_update not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: fix_sql_log_bin_after_update not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: pre_autocommit
static bool pre_autocommit(sys_var *self, THD *thd, set_var *var) {
  if (!(self->is_global_persist(var->type)) &&
      (thd->variables.option_bits & OPTION_NOT_AUTOCOMMIT) &&
      var->save_result.ulonglong_value) {
    // Autocommit mode is about to be activated.
    if (trans_commit_stmt(thd) || trans_commit(thd)) return true;
  }
  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: fix_autocommit
static bool fix_autocommit(sys_var *self, THD *thd, enum_var_type type) {
  if (self->is_global_persist(type)) {
    if (global_system_variables.option_bits & OPTION_AUTOCOMMIT)
      global_system_variables.option_bits &= ~OPTION_NOT_AUTOCOMMIT;
    else
      global_system_variables.option_bits |= OPTION_NOT_AUTOCOMMIT;
    return false;
  }

  if (thd->variables.option_bits & OPTION_AUTOCOMMIT &&
      thd->variables.option_bits &
          OPTION_NOT_AUTOCOMMIT) {  // activating autocommit
    /*
      Don't close thread tables or release metadata locks: if we do so, we
      risk releasing locks/closing tables of expressions used to assign
      other variables, as in:
      set @var=my_stored_function1(), @@autocommit=1, @var2=(select max(a)
      from my_table), ...
      The locks will be released at statement end anyway, as SET
      statement that assigns autocommit is marked to commit
      transaction implicitly at the end (@sa stmt_causes_implicitcommit()).
    */
    thd->variables.option_bits &= ~(OPTION_BEGIN | OPTION_NOT_AUTOCOMMIT);
    thd->get_transaction()->reset_unsafe_rollback_flags(
        Transaction_ctx::SESSION);
    thd->server_status |= SERVER_STATUS_AUTOCOMMIT;
    return false;
  }

  if (!(thd->variables.option_bits & OPTION_AUTOCOMMIT) &&
      !(thd->variables.option_bits &
        OPTION_NOT_AUTOCOMMIT)) {  // disabling autocommit

    thd->get_transaction()->reset_unsafe_rollback_flags(
        Transaction_ctx::SESSION);
    thd->server_status &= ~SERVER_STATUS_AUTOCOMMIT;
    thd->variables.option_bits |= OPTION_NOT_AUTOCOMMIT;
    return false;
  }

  return false;  // autocommit value wasn't changed
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sys_vars.cc
Function: fix_max_join_size
static bool fix_max_join_size(sys_var *self, THD *thd, enum_var_type type) {
  System_variables *sv = (self->is_global_persist(type))
                             ? &global_system_variables
                             : &thd->variables;
  if (sv->max_join_size == HA_POS_ERROR)
    sv->option_bits |= OPTION_BIG_SELECTS;
  else
    sv->option_bits &= ~OPTION_BIG_SELECTS;
  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/handler.cc
Function: trans_register_ha
  This is done by invoking trans_register_ha() server call.
  Normally the engine registers itself whenever handler::external_lock()
  is called. trans_register_ha() can be invoked many times: if
  an engine is already registered, the call does nothing.
  In case autocommit is not set, the engine must register itself
  twice -- both in the statement list and in the normal transaction
  list.
  In which list to register is a parameter of trans_register_ha().

  Note, that although the registration interface in itself is
  fairly clear, the current usage practice often leads to undesired
  effects. E.g. since a call to trans_register_ha() in most engines
  is embedded into implementation of handler::external_lock(), some
  DDL statements start a transaction (at least from the server
  point of view) even though they are not expected to. E.g.
  CREATE TABLE does not start a transaction, since
  handler::external_lock() is never called during CREATE TABLE. But
  CREATE TABLE ... SELECT does, since handler::external_lock() is
  called for the table that is being selected from. This has no
  practical effects currently, but must be kept in mind
  nevertheless.

  Once an engine is registered, the server will do the rest
  of the work.

  During statement execution, whenever any of data-modifying
  PSEA API methods is used, e.g. handler::write_row() or
  handler::update_row(), the read-write flag is raised in the
  statement transaction for the involved engine.
  Currently All PSEA calls are "traced", and the data can not be
  changed in a way other than issuing a PSEA call. Important:
  unless this invariant is preserved the server will not know that
  a transaction in a given engine is read-write and will not
  involve the two-phase commit protocol!

  At the end of a statement, server call trans_commit_stmt is
  invoked. This call in turn invokes handlerton::prepare()
  for every involved engine. Prepare is followed by a call
  to handlerton::commit_one_phase() If a one-phase commit
  will suffice, handlerton::prepare() is not invoked and
  the server only calls handlerton::commit_one_phase().
  At statement commit, the statement-related read-write
  engine flag is propagated to the corresponding flag in the
  normal transaction.  When the commit is complete, the list
  of registered engines is cleared.

  Rollback is handled in a similar fashion.

  Additional notes on DDL and the normal transaction.
  ---------------------------------------------------

  DDLs and operations with non-transactional engines
  do not "register" in thd->transaction lists, and thus do not
  modify the transaction state. Besides, each DDL in
  MySQL is prefixed with an implicit normal transaction commit
  (a call to trans_commit_implicit()), and thus leaves nothing
  to modify.
  However, as it has been pointed out with CREATE TABLE .. SELECT,
  some DDL statements can start a *new* transaction.

  Behaviour of the server in this case is currently badly
  defined.
  DDL statements use a form of "semantic" logging
  to maintain atomicity: if CREATE TABLE .. SELECT failed,
  the newly created table is deleted.
  In addition, some DDL statements issue interim transaction
  commits: e.g. ALTER TABLE issues a commit after data is copied
  from the original table to the internal temporary table. Other
  statements, e.g. CREATE TABLE ... SELECT do not always commit
  after itself.
  And finally there is a group of DDL statements such as
  RENAME/DROP TABLE that doesn't start a new transaction
  and doesn't commit.

  This diversity makes it hard to say what will happen if
  by chance a stored function is invoked during a DDL --
  whether any modifications it makes will be committed or not
  is not clear. Fortunately, SQL grammar of few DDLs allows
  invocation of a stored function.

  A consistent behaviour is perhaps to always commit the normal
  transaction after all DDLs, just like the statement transaction
  is always committed at the end of all statements.
*/

/**
  Register a storage engine for a transaction.

  Every storage engine MUST call this function when it starts
  a transaction or a statement (that is it must be called both for the
  "beginning of transaction" and "beginning of statement").
  Only storage engines registered for the transaction/statement
  will know when to commit/rollback it.

  @note
    trans_register_ha is idempotent - storage engine may register many
    times per transaction.

*/
void trans_register_ha(THD *thd, bool all, handlerton *ht_arg,
                       const ulonglong *trxid [[maybe_unused]]) {
  Ha_trx_info *ha_info;
  Transaction_ctx *trn_ctx = thd->get_transaction();
  Transaction_ctx::enum_trx_scope trx_scope =
      all ? Transaction_ctx::SESSION : Transaction_ctx::STMT;

  DBUG_TRACE;
  DBUG_PRINT("enter", ("%s", all ? "all" : "stmt"));

  if (all) {
    /*
      Ensure no active backup engine data exists, unless the current
      transaction is from replication and in active xa state.
    */
    assert(
        thd->get_ha_data(ht_arg->slot)->ha_ptr_backup == nullptr ||
        (thd->get_transaction()->xid_state()->has_state(XID_STATE::XA_ACTIVE)));
    assert(thd->get_ha_data(ht_arg->slot)->ha_ptr_backup == nullptr ||
           (thd->is_binlog_applier() || thd->slave_thread));

    thd->server_status |= SERVER_STATUS_IN_TRANS;
    if (thd->tx_read_only)
      thd->server_status |= SERVER_STATUS_IN_TRANS_READONLY;
    DBUG_PRINT("info", ("setting SERVER_STATUS_IN_TRANS"));
  }

  ha_info = thd->get_ha_data(ht_arg->slot)->ha_info + (all ? 1 : 0);

  if (ha_info->is_started()) {
    assert(trn_ctx->ha_trx_info(trx_scope));
    return; /* already registered, return */
  }

  trn_ctx->register_ha(trx_scope, ha_info, ht_arg);
  trn_ctx->set_ha_trx_info(trx_scope, ha_info);

  if (ht_arg->prepare == nullptr) trn_ctx->set_no_2pc(trx_scope, true);

  trn_ctx->xid_state()->set_query_id(thd->query_id);
/*
        Register transaction start in performance schema if not done already.
        By doing this, we handle cases when the transaction is started
   implicitly in autocommit=0 mode, and cases when we are in normal autocommit=1
   mode and the executed statement is a single-statement transaction.

        Explicitly started transactions are handled in trans_begin().

        Do not register transactions in which binary log is the only
   participating transactional storage engine.
*/
#ifdef HAVE_PSI_TRANSACTION_INTERFACE
  if (thd->m_transaction_psi == nullptr && ht_arg->db_type != DB_TYPE_BINLOG &&
      !thd->is_attachable_transaction_active()) {
    const XID *xid = trn_ctx->xid_state()->get_xid();
    bool autocommit = !thd->in_multi_stmt_transaction_mode();
    thd->m_transaction_psi = MYSQL_START_TRANSACTION(
        &thd->m_transaction_state, xid, trxid, thd->tx_isolation,
        thd->tx_read_only, autocommit);
    DEBUG_SYNC(thd, "after_set_transaction_psi_before_set_transaction_gtid");
    gtid_set_performance_schema_values(thd);
  }
#endif
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/handler.cc
Function: is_ha_commit_low_invoking_commit_order
bool is_ha_commit_low_invoking_commit_order(THD *thd, bool all) {
  return (!thd->is_operating_substatement_implicitly &&
          !thd->is_operating_gtid_table_implicitly &&
          (thd->is_current_stmt_binlog_log_replica_updates_disabled() ||
           thd->is_low_level_commit_ordering_enabled()) &&
          ending_trans(thd, all));
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/handler.cc
Function: commit_owned_gtids not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/handler.cc
Function: commit_owned_gtids not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/handler.cc
Function: ha_commit_low
      call to ha_commit_low (OPT_BIN_LOG bit), but caches are disabled
      or empty (NDB). Please note that it is important to check
      opt_bin_log in is_current_stmt_binlog_log_replica_updates_disabled,
      because of statements such as ALTER TABLE OPTIMIZE PARTITION,
      where the last call to trans_commit_stmt in the
      mysql_inplace_alter_table (Implicit_substatement_guard disabled)
      is not the last call.
      Moreover, there are also cases in which binlog caches were
      emptied after thread entered the ordered_commit function in the
      MYSQL_BIN_LOG. Therefore, condition is checked in commit() function
      and the result is assigned to the is_low_level_commit_ordering_enabled
      flag introduced in the THD.

    - This function is usually called once per statement, with
      all=false.  We should not preserve the commit order when this
      function is called in that context.  Therefore, we have the
      condition ending_trans(thd, all).

    - Statements such as ANALYZE/OPTIMIZE/REPAIR TABLE will call
      ha_commit_low multiple times with all=true from within
      mysql_admin_table, mysql_recreate_table, and
      handle_histogram_command. After returning to
      mysql_execute_command, it will call ha_commit_low one last
      time.  It is only in this final call that we should preserve
      the commit order. Therefore, we set the flag
      thd->is_operating_substatement_implicitly while executing
      mysql_admin_table, mysql_recreate_table, and
      handle_histogram_command, clear it when returning from those
      functions, and check the flag here in ha_commit_low().

    - In all the above cases, we should make the current transaction
      fail early in case a previous transaction has rolled back.
      Therefore, we also invoke the commit order manager in case
      get_rollback_status returns true.

    Note: the calls to Commit_order_manager::wait/wait_and_finish() will be
          no-op for threads other than replication applier threads.
*/
bool is_ha_commit_low_invoking_commit_order(THD *thd, bool all) {
  return (!thd->is_operating_substatement_implicitly &&
          !thd->is_operating_gtid_table_implicitly &&
          (thd->is_current_stmt_binlog_log_replica_updates_disabled() ||
           thd->is_low_level_commit_ordering_enabled()) &&
          ending_trans(thd, all));
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/handler.cc
Function: check_table_binlog_row_based
static bool check_table_binlog_row_based(THD *thd, TABLE *table) {
  if (table->s->cached_row_logging_check == -1) {
    int const check(table->s->tmp_table == NO_TMP_TABLE &&
                    !table->no_replicate &&
                    binlog_filter->db_ok(table->s->db.str));
    table->s->cached_row_logging_check = check;
  }

  assert(table->s->cached_row_logging_check == 0 ||
         table->s->cached_row_logging_check == 1);

  return (thd->is_current_stmt_binlog_format_row() &&
          table->s->cached_row_logging_check &&
          (thd->variables.option_bits & OPTION_BIN_LOG) &&
          mysql_bin_log.is_open());
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: MYSQL_BIN_LOG::commit
      commit(thd, false) != TC_LOG::RESULT_SUCCESS) {
    ret = true;
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: ending_single_stmt_trans
bool ending_single_stmt_trans(THD *thd, const bool all) {
  return (!all && !thd->in_multi_stmt_transaction_mode());
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: ending_trans
bool ending_trans(THD *thd, const bool all) {
  return (all || ending_single_stmt_trans(thd, all));
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: MYSQL_BIN_LOG::rollback
int MYSQL_BIN_LOG::rollback(THD *thd, bool all) {
  int error = 0;
  bool stuff_logged = false;
  binlog_cache_mngr *cache_mngr = thd_get_cache_mngr(thd);
  bool is_empty = false;

  DBUG_TRACE;
  DBUG_PRINT("enter",
             ("all: %s, cache_mngr: 0x%llx, thd->is_error: %s", YESNO(all),
              (ulonglong)cache_mngr, YESNO(thd->is_error())));
  /*
    Defer XA-transaction rollback until its XA-rollback event is recorded.
    When we are executing a ROLLBACK TO SAVEPOINT, we
    should only clear the caches since this function is called as part
    of the engine rollback.
    In other cases we roll back the transaction in the engines early
    since this will release locks and allow other transactions to
    start executing.
  */
  if (is_xa_rollback(thd)) {
    auto xs = thd->get_transaction()->xid_state();

    assert(all || !xs->is_binlogged() ||
           (!xs->is_detached() && thd->is_error()));

    is_empty = !xs->is_binlogged();

    if ((error = this->write_xa_to_cache(thd)) != 0) goto end;

    cache_mngr = thd_get_cache_mngr(thd);
  } else if (thd->lex->sql_command != SQLCOM_ROLLBACK_TO_SAVEPOINT)
    if ((error = trx_coordinator::rollback_in_engines(thd, all))) goto end;

  /*
    If there is no cache manager, or if there is nothing in the
    caches, there are no caches to roll back, so we're trivially done
    unless XA-ROLLBACK that yet to run rollback_low().
  */
  if (cache_mngr == nullptr || cache_mngr->is_binlog_empty()) {
    goto end;
  }

  DBUG_PRINT("debug", ("all.cannot_safely_rollback(): %s, trx_cache_empty: %s",
                       YESNO(thd->get_transaction()->cannot_safely_rollback(
                           Transaction_ctx::SESSION)),
                       YESNO(cache_mngr->trx_cache.is_binlog_empty())));
  DBUG_PRINT("debug",
             ("stmt.cannot_safely_rollback(): %s, stmt_cache_empty: %s",
              YESNO(thd->get_transaction()->cannot_safely_rollback(
                  Transaction_ctx::STMT)),
              YESNO(cache_mngr->stmt_cache.is_binlog_empty())));

  /*
    If an incident event is set we do not flush the content of the statement
    cache because it may be corrupted.
  */
  if (cache_mngr->stmt_cache.has_incident()) {
    const char *err_msg =
        "The content of the statement cache is corrupted "
        "while writing a rollback record of the transaction "
        "to the binary log.";
    error = write_incident(thd, true /*need_lock_log=true*/, err_msg);
    cache_mngr->stmt_cache.reset();
  } else if (!cache_mngr->stmt_cache.is_binlog_empty()) {
    if (thd->lex->sql_command == SQLCOM_CREATE_TABLE &&
        !thd->lex->query_block->field_list_is_empty() && /* With select */
        !(thd->lex->create_info->options & HA_LEX_CREATE_TMP_TABLE) &&
        thd->is_current_stmt_binlog_format_row()) {
      /*
        In row based binlog format, we reset the binlog statement cache
        when rolling back a single statement 'CREATE...SELECT' transaction,
        since the 'CREATE TABLE' event was put in the binlog statement cache.
      */
      cache_mngr->stmt_cache.reset();
    } else {
      if ((error = cache_mngr->stmt_cache.finalize(thd))) goto end;
      stuff_logged = true;
    }
  }

  if (ending_trans(thd, all)) {
    if (trans_cannot_safely_rollback(thd)) {
      auto xs = thd->get_transaction()->xid_state();
      std::string query{"ROLLBACK"};

      if (is_xa_rollback(thd)) {
        /* this block is relevant only for not prepared yet and "local" xa trx
         */
        assert(
            thd->get_transaction()->xid_state()->has_state(XID_STATE::XA_IDLE));

        std::ostringstream oss;
        oss << "XA ROLLBACK " << *xs->get_xid() << std::flush;
        query = oss.str();
      }
      /*
        If the transaction is being rolled back and contains changes that
        cannot be rolled back, the trx-cache's content is flushed.
      */
      Query_log_event end_evt(thd, query.data(), query.length(), true, false,
                              true, 0, true);
      error = thd->lex->sql_command != SQLCOM_XA_ROLLBACK
                  ? cache_mngr->trx_cache.finalize(thd, &end_evt)
                  : cache_mngr->trx_cache.finalize(thd, &end_evt, xs);
      stuff_logged = true;
    } else {
      /*
        If the transaction is being rolled back and its changes can be
        rolled back, the trx-cache's content is truncated.
      */
      error = cache_mngr->trx_cache.truncate(thd, all);

      DBUG_EXECUTE_IF("ensure_binlog_cache_is_reset", {
        /* Assert that binlog cache is reset at rollback time. */
        assert(binlog_cache_is_reset);
        binlog_cache_is_reset = false;
      };);
    }
  } else {
    /*
      If a statement is being rolled back, it is necessary to know
      exactly why a statement may not be safely rolled back as in
      some specific situations the trx-cache can be truncated.

      If a temporary table is created or dropped, the trx-cache is not
      truncated. Note that if the stmt-cache is used, there is nothing
      to truncate in the trx-cache.

      If a non-transactional table is updated and the binlog format is
      statement, the trx-cache is not truncated. The trx-cache is used
      when the direct option is off and a transactional table has been
      updated before the current statement in the context of the
      current transaction. Note that if the stmt-cache is used there is
      nothing to truncate in the trx-cache.

      If other binlog formats are used, updates to non-transactional
      tables are written to the stmt-cache and trx-cache can be safely
      truncated, if necessary.
    */
    if (thd->get_transaction()->has_dropped_temp_table(Transaction_ctx::STMT) ||
        thd->get_transaction()->has_created_temp_table(Transaction_ctx::STMT) ||
        (thd->get_transaction()->has_modified_non_trans_table(
             Transaction_ctx::STMT) &&
         thd->variables.binlog_format == BINLOG_FORMAT_STMT)) {
      /*
        If the statement is being rolled back and dropped or created a
        temporary table or modified a non-transactional table and the
        statement-based replication is in use, the statement's changes
        in the trx-cache are preserved.
      */
      cache_mngr->trx_cache.set_prev_position(MY_OFF_T_UNDEF);
    } else {
      /*
        Otherwise, the statement's changes in the trx-cache are
        truncated.
      */
      error = cache_mngr->trx_cache.truncate(thd, all);
    }
  }
  if (stuff_logged) {
    Transaction_ctx *trn_ctx = thd->get_transaction();
    trn_ctx->store_commit_parent(
        m_dependency_tracker.get_max_committed_timestamp());
  }

  DBUG_PRINT("debug", ("error: %d", error));
  if (error == 0 && stuff_logged) {
    CONDITIONAL_SYNC_POINT_FOR_TIMESTAMP("before_invoke_before_commit_hook");
    if (RUN_HOOK(
            transaction, before_commit,
            (thd, all, thd_get_cache_mngr(thd)->get_trx_cache(),
             thd_get_cache_mngr(thd)->get_stmt_cache(),
             max<my_off_t>(max_binlog_cache_size, max_binlog_stmt_cache_size),
             false))) {
      // Reset the thread OK status before changing the outcome.
      if (thd->get_stmt_da()->is_ok())
        thd->get_stmt_da()->reset_diagnostics_area();
      my_error(ER_RUN_HOOK_ERROR, MYF(0), "before_commit");
      return RESULT_ABORTED;
    }
    // XA rollback is always accepted.
    assert(!thd->get_transaction()
                ->get_rpl_transaction_ctx()
                ->is_transaction_rollback());

    error = ordered_commit(thd, all, /* skip_commit */ true);

    // Inform hook listeners that a XA ROLLBACK did commit, that
    // is, did log a transaction to the binary log.
    if (!error && is_xa_rollback(thd))
      (void)RUN_HOOK(transaction, after_commit, (thd, all));
  }

  if (check_write_error(thd)) {
    /*
      We reach this point if the effect of a statement did not properly get into
      a cache and need to be rolled back.
    */
    error |= cache_mngr->trx_cache.truncate(thd, all);
  }

end:
  // The caches may be empty if an `XA ROLLBACK` was issued just after `XA
  // END`. In that case, the BCG will not be invoked and we need to
  // rollback in SEs and finalize GTID state.
  if (!error && !stuff_logged && is_xa_rollback(thd)) {
    error = trx_coordinator::rollback_in_engines(thd, all);
    if (!error && !thd->is_error()) {
      /*
        XA-rollback ignores the gtid_state, if the transaciton
        is empty.
      */
      if (is_empty && !thd->slave_thread) gtid_state->update_on_rollback(thd);
      /*
        XA-rollback commits the new gtid_state, if transaction
        is not empty.
      */
      else {
        gtid_state->update_on_commit(thd);
        /*
          Inform hook listeners that a XA ROLLBACK did commit, that
          is, did log a transaction to the binary log.
        */
        (void)RUN_HOOK(transaction, after_commit, (thd, all));
      }
    }
  }
  /*
    When a statement errors out on auto-commit mode it is rollback
    implicitly, so the same should happen to its GTID.
  */
  if (!thd->in_active_multi_stmt_transaction())
    gtid_state->update_on_rollback(thd);

  /*
    TODO: some errors are overwritten, which may cause problem,
    fix it later.
  */
  DBUG_PRINT("return", ("error: %d", error));
  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: binlog_trx_cache_data::truncate
  bool truncate(my_off_t offset) {
    assert(m_pipeline_head != nullptr);

    if (m_pipeline_head->truncate(offset)) return true;
    m_position = offset;
    return false;
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: MYSQL_BIN_LOG::ordered_commit
int MYSQL_BIN_LOG::ordered_commit(THD *thd, bool all, bool skip_commit) {
  DBUG_TRACE;
  int flush_error = 0, sync_error = 0;
  my_off_t total_bytes = 0;
  bool do_rotate = false;

  CONDITIONAL_SYNC_POINT_FOR_TIMESTAMP("before_assign_session_to_bgc_ticket");
  thd->rpl_thd_ctx.binlog_group_commit_ctx().assign_ticket();

  DBUG_EXECUTE_IF("syncpoint_before_wait_on_ticket_3",
                  binlog::Bgc_ticket_manager::instance().push_new_ticket(););
  DBUG_EXECUTE_IF("begin_new_bgc_ticket",
                  binlog::Bgc_ticket_manager::instance().push_new_ticket(););

  DBUG_EXECUTE_IF("crash_commit_before_log", DBUG_SUICIDE(););
  init_thd_variables(thd, all, skip_commit);
  DBUG_PRINT("enter", ("commit_pending: %s, commit_error: %d, thread_id: %u",
                       YESNO(thd->tx_commit_pending), thd->commit_error,
                       thd->thread_id()));

  DEBUG_SYNC(thd, "bgc_before_flush_stage");
  DBUG_EXECUTE_IF("ordered_commit_blocked", {
    const char act[] =
        "now signal signal.ordered_commit_waiting wait_for "
        "signal.ordered_commit_continue";
    assert(!debug_sync_set_action(current_thd, STRING_WITH_LEN(act)));
  });

  /*
    Stage #0: ensure slave threads commit order as they appear in the slave's
              relay log for transactions flushing to binary log.

    This will make thread wait until its turn to commit.
    Commit_order_manager maintains it own queue and its own order for the
    commit. So Stage#0 doesn't maintain separate StageID.
  */
  if (Commit_order_manager::wait_for_its_turn_before_flush_stage(thd) ||
      ending_trans(thd, all) ||
      Commit_order_manager::get_rollback_status(thd)) {
    if (Commit_order_manager::wait(thd)) {
      return thd->commit_error;
    }
  }

  /*
    Stage #1: flushing transactions to binary log

    While flushing, we allow new threads to enter and will process
    them in due time. Once the queue was empty, we cannot reap
    anything more since it is possible that a thread entered and
    appointed itself leader for the flush phase.
  */

  if (change_stage(thd, Commit_stage_manager::BINLOG_FLUSH_STAGE, thd, nullptr,
                   &LOCK_log)) {
    DBUG_PRINT("return", ("Thread ID: %u, commit_error: %d", thd->thread_id(),
                          thd->commit_error));
    return finish_commit(thd);
  }

  THD *wait_queue = nullptr, *final_queue = nullptr;
  mysql_mutex_t *leave_mutex_before_commit_stage = nullptr;
  my_off_t flush_end_pos = 0;
  bool update_binlog_end_pos_after_sync;
  if (unlikely(!is_open())) {
    final_queue = fetch_and_process_flush_stage_queue(true);
    leave_mutex_before_commit_stage = &LOCK_log;
    /*
      binary log is closed, flush stage and sync stage should be
      ignored. Binlog cache should be cleared, but instead of doing
      it here, do that work in 'finish_commit' function so that
      leader and followers thread caches will be cleared.
    */
    goto commit_stage;
  }
  DEBUG_SYNC(thd, "waiting_in_the_middle_of_flush_stage");
  flush_error =
      process_flush_stage_queue(&total_bytes, &do_rotate, &wait_queue);

  if (flush_error == 0 && total_bytes > 0)
    flush_error = flush_cache_to_file(&flush_end_pos);
  DBUG_EXECUTE_IF("crash_after_flush_binlog", DBUG_SUICIDE(););

  update_binlog_end_pos_after_sync = (get_sync_period() == 1);

  /*
    If the flush finished successfully, we can call the after_flush
    hook. Being invoked here, we have the guarantee that the hook is
    executed before the before/after_send_hooks on the dump thread
    preventing race conditions among these plug-ins.
  */
  if (flush_error == 0) {
    const char *file_name_ptr = log_file_name + dirname_length(log_file_name);
    assert(flush_end_pos != 0);
    if (RUN_HOOK(binlog_storage, after_flush,
                 (thd, file_name_ptr, flush_end_pos))) {
      LogErr(ERROR_LEVEL, ER_BINLOG_FAILED_TO_RUN_AFTER_FLUSH_HOOK);
      flush_error = ER_ERROR_ON_WRITE;
    }

    if (!update_binlog_end_pos_after_sync) update_binlog_end_pos();

    DBUG_EXECUTE_IF("crash_commit_after_log", DBUG_SUICIDE(););
  }

  if (flush_error) {
    /*
      Handle flush error (if any) after leader finishes it's flush stage.
    */
    handle_binlog_flush_or_sync_error(
        thd, false /* need_lock_log */,
        (thd->commit_error == THD::CE_FLUSH_GNO_EXHAUSTED_ERROR)
            ? ER_THD(thd, ER_GNO_EXHAUSTED)
            : nullptr);
  }

  DEBUG_SYNC(thd, "bgc_after_flush_stage_before_sync_stage");

  /*
    Stage #2: Syncing binary log file to disk
  */

  if (change_stage(thd, Commit_stage_manager::SYNC_STAGE, wait_queue, &LOCK_log,
                   &LOCK_sync)) {
    DBUG_PRINT("return", ("Thread ID: %u, commit_error: %d", thd->thread_id(),
                          thd->commit_error));
    return finish_commit(thd);
  }

  /*
    Shall introduce a delay only if it is going to do sync
    in this ongoing SYNC stage. The "+1" used below in the
    if condition is to count the ongoing sync stage.
    When sync_binlog=0 (where we never do sync in BGC group),
    it is considered as a special case and delay will be executed
    for every group just like how it is done when sync_binlog= 1.
  */
  if (!flush_error && (sync_counter + 1 >= get_sync_period()))
    Commit_stage_manager::get_instance().wait_count_or_timeout(
        opt_binlog_group_commit_sync_no_delay_count,
        opt_binlog_group_commit_sync_delay, Commit_stage_manager::SYNC_STAGE);

  final_queue = Commit_stage_manager::get_instance().fetch_queue_acquire_lock(
      Commit_stage_manager::SYNC_STAGE);

  if (flush_error == 0 && total_bytes > 0) {
    DEBUG_SYNC(thd, "before_sync_binlog_file");
    std::pair<bool, bool> result = sync_binlog_file(false);
    sync_error = result.first;
  }

  if (update_binlog_end_pos_after_sync && flush_error == 0 && sync_error == 0) {
    THD *tmp_thd = final_queue;
    const char *binlog_file = nullptr;
    my_off_t pos = 0;

    while (tmp_thd != nullptr) {
      if (tmp_thd->commit_error == THD::CE_NONE) {
        tmp_thd->get_trans_fixed_pos(&binlog_file, &pos);
      }
      tmp_thd = tmp_thd->next_to_commit;
    }

    if (binlog_file != nullptr && pos > 0) {
      update_binlog_end_pos(binlog_file, pos);
    }
  }

  DEBUG_SYNC(thd, "bgc_after_sync_stage_before_commit_stage");

  leave_mutex_before_commit_stage = &LOCK_sync;
  /*
    Stage #3: Commit all transactions in order.

    This stage is skipped if we do not need to order the commits and
    each thread have to execute the handlerton commit instead.

    However, since we are keeping the lock from the previous stage, we
    need to unlock it if we skip the stage.

    We must also step commit_clock before the ha_commit_low() is called
    either in ordered fashion (by the leader of this stage) or by the thread
    themselves.

    We are delaying the handling of sync error until
    all locks are released but we should not enter into
    commit stage if binlog_error_action is ABORT_SERVER.
  */
commit_stage:
  /* Clone needs binlog commit order. */
  if ((opt_binlog_order_commits || Clone_handler::need_commit_order()) &&
      (sync_error == 0 || binlog_error_action != ABORT_SERVER)) {
    if (change_stage(thd, Commit_stage_manager::COMMIT_STAGE, final_queue,
                     leave_mutex_before_commit_stage, &LOCK_commit)) {
      DBUG_PRINT("return", ("Thread ID: %u, commit_error: %d", thd->thread_id(),
                            thd->commit_error));
      return finish_commit(thd);
    }
    THD *commit_queue =
        Commit_stage_manager::get_instance().fetch_queue_acquire_lock(
            Commit_stage_manager::COMMIT_STAGE);
    DBUG_EXECUTE_IF("semi_sync_3-way_deadlock",
                    DEBUG_SYNC(thd, "before_process_commit_stage_queue"););

    if (flush_error == 0 && sync_error == 0)
      sync_error = call_after_sync_hook(commit_queue);

    /*
      process_commit_stage_queue will call update_on_commit or
      update_on_rollback for the GTID owned by each thd in the queue.

      This will be done this way to guarantee that GTIDs are added to
      gtid_executed in order, to avoid creating unnecessary temporary
      gaps and keep gtid_executed as a single interval at all times.

      If we allow each thread to call update_on_commit only when they
      are at finish_commit, the GTID order cannot be guaranteed and
      temporary gaps may appear in gtid_executed. When this happen,
      the server would have to add and remove intervals from the
      Gtid_set, and adding and removing intervals requires a mutex,
      which would reduce performance.
    */
    process_commit_stage_queue(thd, commit_queue);

    /**
     * After commit stage
     */
    if (change_stage(thd, Commit_stage_manager::AFTER_COMMIT_STAGE,
                     commit_queue, &LOCK_commit, &LOCK_after_commit)) {
      DBUG_PRINT("return", ("Thread ID: %u, commit_error: %d", thd->thread_id(),
                            thd->commit_error));
      return finish_commit(thd);
    }

    THD *after_commit_queue =
        Commit_stage_manager::get_instance().fetch_queue_acquire_lock(
            Commit_stage_manager::AFTER_COMMIT_STAGE);

    process_after_commit_stage_queue(thd, after_commit_queue);

    final_queue = after_commit_queue;
    mysql_mutex_unlock(&LOCK_after_commit);
  } else {
    if (leave_mutex_before_commit_stage)
      mysql_mutex_unlock(leave_mutex_before_commit_stage);
    if (flush_error == 0 && sync_error == 0)
      sync_error = call_after_sync_hook(final_queue);
  }

  /*
    Handle sync error after we release all locks in order to avoid deadlocks
  */
  if (sync_error)
    handle_binlog_flush_or_sync_error(thd, true /* need_lock_log */, nullptr);

  DEBUG_SYNC(thd, "before_signal_done");
  /* Commit done so signal all waiting threads */
  Commit_stage_manager::get_instance().signal_done(final_queue);
  DBUG_EXECUTE_IF("block_leader_after_delete", {
    const char action[] = "now SIGNAL leader_proceed";
    assert(!debug_sync_set_action(thd, STRING_WITH_LEN(action)));
  };);

  /*
    Finish the commit before executing a rotate, or run the risk of a
    deadlock. We don't need the return value here since it is in
    thd->commit_error, which is returned below.
  */
  (void)finish_commit(thd);
  DEBUG_SYNC(thd, "bgc_after_commit_stage_before_rotation");

  /*
    If we need to rotate, we do it without commit error.
    Otherwise the thd->commit_error will be possibly reset.
   */
  if (DBUG_EVALUATE_IF("force_rotate", 1, 0) ||
      (do_rotate && thd->commit_error == THD::CE_NONE &&
       !is_rotating_caused_by_incident)) {
    /*
      Do not force the rotate as several consecutive groups may
      request unnecessary rotations.

      NOTE: Run purge_logs wo/ holding LOCK_log because it does not
      need the mutex. Otherwise causes various deadlocks.
    */

    DEBUG_SYNC(thd, "ready_to_do_rotation");
    bool check_purge = false;
    mysql_mutex_lock(&LOCK_log);
    /*
      If rotate fails then depends on binlog_error_action variable
      appropriate action will be taken inside rotate call.
    */
    int error = rotate(false, &check_purge);
    mysql_mutex_unlock(&LOCK_log);

    if (error)
      thd->commit_error = THD::CE_COMMIT_ERROR;
    else if (check_purge)
      auto_purge();
  }
  /*
    flush or sync errors are handled above (using binlog_error_action).
    Hence treat only COMMIT_ERRORs as errors.
  */
  return thd->commit_error == THD::CE_COMMIT_ERROR;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: THD::decide_logging_format
int THD::decide_logging_format(Table_ref *tables) {
  DBUG_TRACE;
  DBUG_PRINT("info", ("query: %s", query().str));
  DBUG_PRINT("info", ("variables.binlog_format: %lu", variables.binlog_format));
  DBUG_PRINT("info", ("lex->get_stmt_unsafe_flags(): 0x%x",
                      lex->get_stmt_unsafe_flags()));

#if defined(ENABLED_DEBUG_SYNC)
  if (!is_attachable_ro_transaction_active())
    DEBUG_SYNC(this, "begin_decide_logging_format");
#endif

  reset_binlog_local_stmt_filter();

  /*
    We should not decide logging format if the binlog is closed or
    binlogging is off, or if the statement is filtered out from the
    binlog by filtering rules.
  */
  if (mysql_bin_log.is_open() && (variables.option_bits & OPTION_BIN_LOG) &&
      !(variables.binlog_format == BINLOG_FORMAT_STMT &&
        !binlog_filter->db_ok(m_db.str))) {
    /*
      Compute one bit field with the union of all the engine
      capabilities, and one with the intersection of all the engine
      capabilities.
    */
    handler::Table_flags flags_write_some_set = 0;
    handler::Table_flags flags_access_some_set = 0;
    handler::Table_flags flags_write_all_set =
        HA_BINLOG_ROW_CAPABLE | HA_BINLOG_STMT_CAPABLE;

    /*
       If different types of engines are about to be updated.
       For example: Innodb and Falcon; Innodb and MyIsam.
    */
    bool multi_write_engine = false;
    /*
       If different types of engines are about to be accessed
       and any of them is about to be updated. For example:
       Innodb and Falcon; Innodb and MyIsam.
    */
    bool multi_access_engine = false;
    /*
      Track if statement creates or drops a temporary table
      and log in ROW if it does.
*/
    bool is_create_drop_temp_table = false;
    /*
       Identifies if a table is changed.
    */
    bool is_write = false;
    /*
       A pointer to a previous table that was changed.
    */
    TABLE *prev_write_table = nullptr;
    /*
       A pointer to a previous table that was accessed.
    */
    TABLE *prev_access_table = nullptr;
    /*
      True if at least one table is transactional.
    */
    bool write_to_some_transactional_table = false;
    /*
      True if at least one table is non-transactional.
    */
    bool write_to_some_non_transactional_table = false;
    /*
       True if all non-transactional tables that has been updated
       are temporary.
    */
    bool write_all_non_transactional_are_tmp_tables = true;
    /**
      The number of tables used in the current statement,
      that should be replicated.
    */
    uint replicated_tables_count = 0;
    /**
      The number of tables written to in the current statement,
      that should not be replicated.
      A table should not be replicated when it is considered
      'local' to a MySQL instance.
      Currently, these tables are:
      - mysql.slow_log
      - mysql.general_log
      - mysql.slave_relay_log_info
      - mysql.slave_master_info
      - mysql.slave_worker_info
      - performance_schema.*
      - TODO: information_schema.*
      In practice, from this list, only performance_schema.* tables
      are written to by user queries.
    */
    uint non_replicated_tables_count = 0;
    /**
      Indicate whether we already reported a warning
      on modifying gtid_executed table.
    */
    int warned_gtid_executed_table = 0;
#ifndef NDEBUG
    {
      DBUG_PRINT("debug", ("prelocked_mode: %s",
                           get_locked_tables_mode_name(locked_tables_mode)));
    }
#endif

    if (variables.binlog_format != BINLOG_FORMAT_ROW && tables) {
      /*
        DML statements that modify a table with an auto_increment column based
        on rows selected from a table are unsafe as the order in which the rows
        are fetched from the select tables cannot be determined and may differ
        on master and slave.
       */
      if (has_write_table_with_auto_increment_and_query_block(tables))
        lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_WRITE_AUTOINC_SELECT);

      if (has_write_table_auto_increment_not_first_in_pk(tables))
        lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_AUTOINC_NOT_FIRST);

      /*
        A query that modifies autoinc column in sub-statement can make the
        master and slave inconsistent.
        We can solve these problems in mixed mode by switching to binlogging
        if at least one updated table is used by sub-statement
       */
      if (lex->requires_prelocking() &&
          has_write_table_with_auto_increment(lex->first_not_own_table()))
        lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_AUTOINC_COLUMNS);

      /*
        A query that modifies a table with a non-deterministic column default
        expression in a substatement, can make the master and the slave
        inconsistent. Switch to row logging in mixed mode, and raise a warning
        in statement mode.
      */
      if (lex->requires_prelocking() &&
          has_write_table_with_nondeterministic_default(
              lex->first_not_own_table()))
        lex->set_stmt_unsafe(
            LEX::BINLOG_STMT_UNSAFE_DEFAULT_EXPRESSION_IN_SUBSTATEMENT);

      /*
        A DML or DDL statement is unsafe if it reads a ACL table while
        modifying the table, because SE skips acquiring row locks.
        Therefore rows seen by DML or DDL may not have same effect on slave.

        We skip checking the same under lock tables mode, because we do
        not skip row locks on ACL table in this mode.
      */
      if (has_acl_table_read(this, tables)) {
        lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_ACL_TABLE_READ_IN_DML_DDL);
      }
    }

    /*
      Get the capabilities vector for all involved storage engines and
      mask out the flags for the binary log.
    */
    for (Table_ref *table = tables; table; table = table->next_global) {
      if (table->is_placeholder()) {
        /*
          Detect if this is a CREATE TEMPORARY or DROP of a
          temporary table. This will be used later in determining whether to
          log in ROW or STMT if MIXED replication is being used.
        */
        if (!is_create_drop_temp_table && !table->table &&
            ((lex->sql_command == SQLCOM_CREATE_TABLE &&
              (lex->create_info->options & HA_LEX_CREATE_TMP_TABLE)) ||
             ((lex->sql_command == SQLCOM_DROP_TABLE ||
               lex->sql_command == SQLCOM_TRUNCATE) &&
              find_temporary_table(this, table)))) {
          is_create_drop_temp_table = true;
        }
        continue;
      }
      handler::Table_flags const flags = table->table->file->ha_table_flags();

      DBUG_PRINT("info", ("table: %s; ha_table_flags: 0x%llx",
                          table->table_name, flags));

      if (table->table->no_replicate) {
        if (!warned_gtid_executed_table) {
          warned_gtid_executed_table =
              gtid_state->warn_or_err_on_modify_gtid_table(this, table);
          /*
            Do not allow users to modify the gtid_executed table
            explicitly by a XA transaction.
          */
          if (warned_gtid_executed_table == 2) return -1;
        }
        /*
          The statement uses a table that is not replicated.
          The following properties about the table:
          - persistent / transient
          - transactional / non transactional
          - temporary / permanent
          - read or write
          - multiple engines involved because of this table
          are not relevant, as this table is completely ignored.
          Because the statement uses a non replicated table,
          using STATEMENT format in the binlog is impossible.
          Either this statement will be discarded entirely,
          or it will be logged (possibly partially) in ROW format.
        */
        lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_SYSTEM_TABLE);

        if (table->lock_descriptor().type >= TL_WRITE_ALLOW_WRITE) {
          non_replicated_tables_count++;
          continue;
        }
      }

      replicated_tables_count++;

      bool trans = table->table->file->has_transactions();

      if (table->lock_descriptor().type >= TL_WRITE_ALLOW_WRITE) {
        write_to_some_transactional_table =
            write_to_some_transactional_table || trans;

        write_to_some_non_transactional_table =
            write_to_some_non_transactional_table || !trans;

        if (prev_write_table &&
            prev_write_table->file->ht != table->table->file->ht)
          multi_write_engine = true;

        if (table->table->s->tmp_table)
          lex->set_stmt_accessed_table(
              trans ? LEX::STMT_WRITES_TEMP_TRANS_TABLE
                    : LEX::STMT_WRITES_TEMP_NON_TRANS_TABLE);
        else
          lex->set_stmt_accessed_table(trans
                                           ? LEX::STMT_WRITES_TRANS_TABLE
                                           : LEX::STMT_WRITES_NON_TRANS_TABLE);

        /*
         Non-transactional updates are allowed when row binlog format is
         used and all non-transactional tables are temporary.
         Binlog format is checked on THD::is_dml_gtid_compatible() method.
        */
        if (!trans)
          write_all_non_transactional_are_tmp_tables =
              write_all_non_transactional_are_tmp_tables &&
              table->table->s->tmp_table;

        flags_write_all_set &= flags;
        flags_write_some_set |= flags;
        is_write = true;

        prev_write_table = table->table;

        /*
          It should be marked unsafe if a table which uses a fulltext parser
          plugin is modified. See also bug#48183.
        */
        if (!lex->is_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_FULLTEXT_PLUGIN)) {
          if (fulltext_unsafe_set(table->table->s))
            lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_FULLTEXT_PLUGIN);
        }
        /*
          INSERT...ON DUPLICATE KEY UPDATE on a table with more than one unique
          keys can be unsafe. Check for it if the flag is already not marked for
          the given statement.
        */
        if (!lex->is_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_INSERT_TWO_KEYS) &&
            lex->sql_command == SQLCOM_INSERT &&
            lex->duplicates == DUP_UPDATE) {
          uint keys = table->table->s->keys, i = 0, unique_keys = 0;
          for (KEY *keyinfo = table->table->s->key_info;
               i < keys && unique_keys <= 1; i++, keyinfo++) {
            if (keyinfo->flags & HA_NOSAME) unique_keys++;
          }
          if (unique_keys > 1)
            lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_INSERT_TWO_KEYS);
        }
      }
      if (lex->get_using_match()) {
        if (fulltext_unsafe_set(table->table->s))
          lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_FULLTEXT_PLUGIN);
      }

      flags_access_some_set |= flags;

      if (lex->sql_command != SQLCOM_CREATE_TABLE ||
          (lex->sql_command == SQLCOM_CREATE_TABLE &&
           ((lex->create_info->options & HA_LEX_CREATE_TMP_TABLE) ||
            (table->lock_descriptor().type < TL_WRITE_ALLOW_WRITE)))) {
        if (table->table->s->tmp_table)
          lex->set_stmt_accessed_table(
              trans ? LEX::STMT_READS_TEMP_TRANS_TABLE
                    : LEX::STMT_READS_TEMP_NON_TRANS_TABLE);
        else
          lex->set_stmt_accessed_table(trans ? LEX::STMT_READS_TRANS_TABLE
                                             : LEX::STMT_READS_NON_TRANS_TABLE);
      }

      if (prev_access_table &&
          prev_access_table->file->ht != table->table->file->ht)
        multi_access_engine = true;

      prev_access_table = table->table;
    }
    assert(!is_write || write_to_some_transactional_table ||
           write_to_some_non_transactional_table);
    /*
      write_all_non_transactional_are_tmp_tables may be true if any
      non-transactional table was not updated, so we fix its value here.
    */
    write_all_non_transactional_are_tmp_tables =
        write_all_non_transactional_are_tmp_tables &&
        write_to_some_non_transactional_table;

    DBUG_PRINT("info", ("flags_write_all_set: 0x%llx", flags_write_all_set));
    DBUG_PRINT("info", ("flags_write_some_set: 0x%llx", flags_write_some_set));
    DBUG_PRINT("info",
               ("flags_access_some_set: 0x%llx", flags_access_some_set));
    DBUG_PRINT("info", ("multi_write_engine: %d", multi_write_engine));
    DBUG_PRINT("info", ("multi_access_engine: %d", multi_access_engine));

    int error = 0;
    int unsafe_flags;

    /*
      With transactional data dictionary, CREATE TABLE runs as one statement
      in a multi-statement transaction internally. Revert this for the
      purposes of determining mixed statement safety.
    */
    const bool multi_stmt_trans = lex->sql_command != SQLCOM_CREATE_TABLE &&
                                  in_multi_stmt_transaction_mode();
    bool trans_table = trans_has_updated_trans_table(this);
    bool binlog_direct = variables.binlog_direct_non_trans_update;

    if (lex->is_mixed_stmt_unsafe(multi_stmt_trans, binlog_direct, trans_table,
                                  tx_isolation))
      lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_MIXED_STATEMENT);
    else if (multi_stmt_trans && trans_table && !binlog_direct &&
             lex->stmt_accessed_table(LEX::STMT_WRITES_NON_TRANS_TABLE))
      lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_NONTRANS_AFTER_TRANS);

    /*
      If more than one engine is involved in the statement and at
      least one is doing it's own logging (is *self-logging*), the
      statement cannot be logged atomically, so we generate an error
      rather than allowing the binlog to become corrupt.
    */
    if (multi_write_engine && (flags_write_some_set & HA_HAS_OWN_BINLOGGING))
      my_error((error = ER_BINLOG_MULTIPLE_ENGINES_AND_SELF_LOGGING_ENGINE),
               MYF(0));
    else if (multi_access_engine &&
             flags_access_some_set & HA_HAS_OWN_BINLOGGING)
      lex->set_stmt_unsafe(
          LEX::BINLOG_STMT_UNSAFE_MULTIPLE_ENGINES_AND_SELF_LOGGING_ENGINE);

    /* XA is unsafe for statements */
    if (is_write &&
        !get_transaction()->xid_state()->has_state(XID_STATE::XA_NOTR))
      lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_XA);

    DBUG_EXECUTE_IF("make_stmt_only_engines",
                    { flags_write_all_set = HA_BINLOG_STMT_CAPABLE; };);

    /* both statement-only and row-only engines involved */
    if ((flags_write_all_set &
         (HA_BINLOG_STMT_CAPABLE | HA_BINLOG_ROW_CAPABLE)) == 0) {
      /*
        1. Error: Binary logging impossible since both row-incapable
           engines and statement-incapable engines are involved
      */
      my_error((error = ER_BINLOG_ROW_ENGINE_AND_STMT_ENGINE), MYF(0));
    }
    /* statement-only engines involved */
    else if ((flags_write_all_set & HA_BINLOG_ROW_CAPABLE) == 0) {
      if (lex->is_stmt_row_injection()) {
        /*
          4. Error: Cannot execute row injection since table uses
             storage engine limited to statement-logging
        */
        my_error((error = ER_BINLOG_ROW_INJECTION_AND_STMT_ENGINE), MYF(0));
      } else if (variables.binlog_format == BINLOG_FORMAT_ROW &&
                 sqlcom_can_generate_row_events(this->lex->sql_command)) {
        /*
          2. Error: Cannot modify table that uses a storage engine
             limited to statement-logging when BINLOG_FORMAT = ROW
        */
        my_error((error = ER_BINLOG_ROW_MODE_AND_STMT_ENGINE), MYF(0));
      } else if (variables.binlog_format == BINLOG_FORMAT_MIXED &&
                 ((unsafe_flags = lex->get_stmt_unsafe_flags()) != 0)) {
        /*
          3. Error: Cannot execute statement: binlogging of unsafe
             statement is impossible when storage engine is limited to
             statement-logging and BINLOG_FORMAT = MIXED.
        */
        for (int unsafe_type = 0; unsafe_type < LEX::BINLOG_STMT_UNSAFE_COUNT;
             unsafe_type++)
          if (unsafe_flags & (1 << unsafe_type))
            my_error(
                (error = ER_BINLOG_UNSAFE_AND_STMT_ENGINE), MYF(0),
                ER_THD_NONCONST(current_thd,
                                LEX::binlog_stmt_unsafe_errcode[unsafe_type]));
      } else if (is_write &&
                 ((unsafe_flags = lex->get_stmt_unsafe_flags()) != 0)) {
        /*
          7. Warning: Unsafe statement logged as statement due to
             binlog_format = STATEMENT
        */
        binlog_unsafe_warning_flags |= unsafe_flags;
        DBUG_PRINT("info", ("Scheduling warning to be issued by "
                            "binlog_query: '%s'",
                            ER_THD(current_thd, ER_BINLOG_UNSAFE_STATEMENT)));
        DBUG_PRINT("info", ("binlog_unsafe_warning_flags: 0x%x",
                            binlog_unsafe_warning_flags));
      }
      /* log in statement format! */
    }
    /* no statement-only engines */
    else {
      /* binlog_format = STATEMENT */
      if (variables.binlog_format == BINLOG_FORMAT_STMT) {
        if (lex->is_stmt_row_injection()) {
          /*
            6. Error: Cannot execute row injection since
               BINLOG_FORMAT = STATEMENT
          */
          my_error((error = ER_BINLOG_ROW_INJECTION_AND_STMT_MODE), MYF(0));
        } else if ((flags_write_all_set & HA_BINLOG_STMT_CAPABLE) == 0 &&
                   sqlcom_can_generate_row_events(this->lex->sql_command)) {
          /*
            5. Error: Cannot modify table that uses a storage engine
               limited to row-logging when binlog_format = STATEMENT
          */
          my_error((error = ER_BINLOG_STMT_MODE_AND_ROW_ENGINE), MYF(0), "");
        } else if (is_write &&
                   (unsafe_flags = lex->get_stmt_unsafe_flags()) != 0) {
          /*
            7. Warning: Unsafe statement logged as statement due to
               binlog_format = STATEMENT
          */
          binlog_unsafe_warning_flags |= unsafe_flags;
          DBUG_PRINT("info", ("Scheduling warning to be issued by "
                              "binlog_query: '%s'",
                              ER_THD(current_thd, ER_BINLOG_UNSAFE_STATEMENT)));
          DBUG_PRINT("info", ("binlog_unsafe_warning_flags: 0x%x",
                              binlog_unsafe_warning_flags));
        }
        /* log in statement format! */
      }
      /* No statement-only engines and binlog_format != STATEMENT.
         I.e., nothing prevents us from row logging if needed. */
      else {
        if (lex->is_stmt_unsafe() || lex->is_stmt_row_injection() ||
            lex->is_stmt_unsafe_with_mixed_mode() ||
            (flags_write_all_set & HA_BINLOG_STMT_CAPABLE) == 0 ||
            lex->stmt_accessed_table(LEX::STMT_READS_TEMP_TRANS_TABLE) ||
            lex->stmt_accessed_table(LEX::STMT_READS_TEMP_NON_TRANS_TABLE) ||
            is_create_drop_temp_table) {
#ifndef NDEBUG
          int flags = lex->get_stmt_unsafe_flags();
          DBUG_PRINT("info", ("setting row format for unsafe statement"));
          for (int i = 0; i < Query_tables_list::BINLOG_STMT_UNSAFE_COUNT;
               i++) {
            if (flags & (1 << i))
              DBUG_PRINT(
                  "info",
                  ("unsafe reason: %s",
                   ER_THD_NONCONST(
                       current_thd,
                       Query_tables_list::binlog_stmt_unsafe_errcode[i])));
          }
          DBUG_PRINT("info",
                     ("is_row_injection=%d", lex->is_stmt_row_injection()));
          DBUG_PRINT("info", ("stmt_capable=%llu",
                              (flags_write_all_set & HA_BINLOG_STMT_CAPABLE)));
          DBUG_PRINT("info", ("lex->is_stmt_unsafe_with_mixed_mode = %d",
                              lex->is_stmt_unsafe_with_mixed_mode()));
#endif
          /* log in row format! */
          set_current_stmt_binlog_format_row_if_mixed();
        }
      }
    }

    if (non_replicated_tables_count > 0) {
      if ((replicated_tables_count == 0) || !is_write) {
        DBUG_PRINT("info",
                   ("decision: no logging, no replicated table affected"));
        set_binlog_local_stmt_filter();
      } else {
        if (!is_current_stmt_binlog_format_row()) {
          my_error((error = ER_BINLOG_STMT_MODE_AND_NO_REPL_TABLES), MYF(0));
        } else {
          clear_binlog_local_stmt_filter();
        }
      }
    } else {
      clear_binlog_local_stmt_filter();
    }

    if (!error &&
        !is_dml_gtid_compatible(write_to_some_transactional_table,
                                write_to_some_non_transactional_table,
                                write_all_non_transactional_are_tmp_tables))
      error = 1;

    if (error) {
      DBUG_PRINT("info", ("decision: no logging since an error was generated"));
      return -1;
    }

    if (is_write &&
        lex->sql_command != SQLCOM_END /* rows-event applying by slave */) {
      /*
        Master side of DML in the STMT format events parallelization.
        All involving table db:s are stored in a abc-ordered name list.
        In case the number of databases exceeds MAX_DBS_IN_EVENT_MTS maximum
        the list gathering breaks since it won't be sent to the slave.
      */
      for (Table_ref *table = tables; table; table = table->next_global) {
        if (table->is_placeholder()) continue;

        assert(table->table);

        if (table->table->s->is_referenced_by_foreign_key()) {
          /*
             FK-referenced dbs can't be gathered currently. The following
             event will be marked for sequential execution on slave.
          */
          binlog_accessed_db_names = nullptr;
          add_to_binlog_accessed_dbs("");
          break;
        }
        if (!is_current_stmt_binlog_format_row())
          add_to_binlog_accessed_dbs(table->db);
      }
    }
    DBUG_PRINT("info",
               ("decision: logging in %s format",
                is_current_stmt_binlog_format_row() ? "ROW" : "STATEMENT"));

    if (variables.binlog_format == BINLOG_FORMAT_ROW &&
        (lex->sql_command == SQLCOM_UPDATE ||
         lex->sql_command == SQLCOM_UPDATE_MULTI ||
         lex->sql_command == SQLCOM_DELETE ||
         lex->sql_command == SQLCOM_DELETE_MULTI)) {
      String table_names;
      /*
        Generate a warning for UPDATE/DELETE statements that modify a
        BLACKHOLE table, as row events are not logged in row format.
      */
      for (Table_ref *table = tables; table; table = table->next_global) {
        if (table->is_placeholder()) continue;
        if (table->table->file->ht->db_type == DB_TYPE_BLACKHOLE_DB &&
            table->lock_descriptor().type >= TL_WRITE_ALLOW_WRITE) {
          table_names.append(table->table_name);
          table_names.append(",");
        }
      }
      if (!table_names.is_empty()) {
        bool is_update = (lex->sql_command == SQLCOM_UPDATE ||
                          lex->sql_command == SQLCOM_UPDATE_MULTI);
        /*
          Replace the last ',' with '.' for table_names
        */
        table_names.replace(table_names.length() - 1, 1, ".", 1);
        push_warning_printf(
            this, Sql_condition::SL_WARNING, WARN_ON_BLOCKHOLE_IN_RBR,
            ER_THD(this, WARN_ON_BLOCKHOLE_IN_RBR),
            is_update ? "UPDATE" : "DELETE", table_names.c_ptr());
      }
    }
  } else {
    DBUG_PRINT(
        "info",
        ("decision: no logging since "
         "mysql_bin_log.is_open() = %d "
         "and (options & OPTION_BIN_LOG) = 0x%llx "
         "and binlog_format = %lu "
         "and binlog_filter->db_ok(db) = %d",
         mysql_bin_log.is_open(), (variables.option_bits & OPTION_BIN_LOG),
         variables.binlog_format, binlog_filter->db_ok(m_db.str)));

    for (Table_ref *table = tables; table; table = table->next_global) {
      if (!table->is_placeholder() && table->table->no_replicate &&
          gtid_state->warn_or_err_on_modify_gtid_table(this, table))
        break;
    }
  }

#if defined(ENABLED_DEBUG_SYNC)
  if (!is_attachable_ro_transaction_active())
    DEBUG_SYNC(this, "end_decide_logging_format");
#endif

  return 0;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: THD::is_ddl_gtid_compatible
bool THD::is_ddl_gtid_compatible() {
  DBUG_TRACE;

  bool is_binlog_open{mysql_bin_log.is_open()};
  bool is_binlog_enabled_for_session{(variables.option_bits & OPTION_BIN_LOG) !=
                                     0};
  DBUG_PRINT("info", ("is_binlog_open:%d is_binlog_enabled_for_session:%d",
                      is_binlog_open, is_binlog_enabled_for_session));
  // If we are not going to log, then no problem, we can execute any
  // statement.
  if (!is_binlog_open || !is_binlog_enabled_for_session) return true;

  bool is_create_table{lex->sql_command == SQLCOM_CREATE_TABLE};
  bool is_create_temporary_table{false};
  bool is_create_table_select{false};
  bool is_create_table_atomic{false};
  if (is_create_table) {
    // Check this conditionally, since create_info and/or query_block
    // may be uninitialized if sql_command!=SQLCOM_CREATE_TABLE.
    is_create_temporary_table =
        (lex->create_info->options & HA_LEX_CREATE_TMP_TABLE);
    if (!is_create_temporary_table)
      is_create_table_select = !lex->query_block->field_list_is_empty();
    is_create_table_atomic =
        get_default_handlerton(this, lex->create_info->db_type)->flags &
        HTON_SUPPORTS_ATOMIC_DDL;
  }

  bool is_drop_table{lex->sql_command == SQLCOM_DROP_TABLE};
  bool is_drop_temporary_table{false};
  if (is_drop_table) is_drop_temporary_table = lex->drop_temporary;

  bool is_in_transaction{in_multi_stmt_transaction_mode()};

  bool is_in_sub_statement{in_sub_stmt != 0};

  bool is_binlog_format_statement{variables.binlog_format ==
                                  BINLOG_FORMAT_STMT};

  DBUG_PRINT("info", ("is_create_table:%d is_create_temporary_table:%d "
                      "is_create_table_select:%d is_create_table_atomic:%d "
                      "is_drop_table:%d is_drop_temporary_table:%d "
                      "is_in_transaction:%d is_in_sub_statement:%d "
                      "is_binlog_format_statement:%d",
                      is_create_table, is_create_temporary_table,
                      is_create_table_select, is_create_table_atomic,
                      is_drop_table, is_drop_temporary_table, is_in_transaction,
                      is_in_sub_statement, is_binlog_format_statement));

  if (is_create_table_select && !is_create_temporary_table &&
      !is_create_table_atomic) {
    /*
      CREATE ... SELECT (without TEMPORARY) for engines not supporting
      atomic DDL is unsafe because if binlog_format=row it will be
      logged as a CREATE TABLE followed by row events, re-executed
      non-atomically as two transactions, and then written to the
      slave's binary log as two separate transactions with the same
      GTID.
    */
    return handle_gtid_consistency_violation(
        this, ER_GTID_UNSAFE_CREATE_SELECT,
        ER_RPL_GTID_UNSAFE_STMT_CREATE_SELECT);
  }

  if ((is_create_temporary_table || is_drop_temporary_table) &&
      is_binlog_format_statement &&
      (is_in_transaction || is_in_sub_statement)) {
    /*
      When @@session.binlog_format=statement,
      [CREATE|DROP] TEMPORARY TABLE is unsafe to execute inside a
      transaction or Procedure, because the [CREATE|DROP] statement on
      the temporary table will be executed and written into binary log
      with a GTID even if the transaction or Procedure is rolled back.
    */
    return handle_gtid_consistency_violation(
        this, ER_CLIENT_GTID_UNSAFE_CREATE_DROP_TEMP_TABLE_IN_TRX_IN_SBR,
        ER_SERVER_GTID_UNSAFE_CREATE_DROP_TEMP_TABLE_IN_TRX_IN_SBR);
  }

  return true;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: binlog_start_trans_and_stmt
static int binlog_start_trans_and_stmt(THD *thd, Log_event *start_event) {
  DBUG_TRACE;

  /*
    Initialize the cache manager if this was not done yet.
  */
  if (thd->binlog_setup_trx_data()) return 1;

  /*
    Retrieve the appropriated cache.
  */
  bool is_transactional = start_event->is_using_trans_cache();
  binlog_cache_mngr *cache_mngr = thd_get_cache_mngr(thd);
  binlog_cache_data *cache_data =
      cache_mngr->get_binlog_cache_data(is_transactional);

  /*
    If the event is requesting immediate logging, there is no need to go
    further down and set savepoint and register callbacks.
  */
  if (start_event->is_using_immediate_logging()) return 0;

  register_binlog_handler(thd, thd->in_multi_stmt_transaction_mode());

  /* Transactional DDL is logged traditionally without BEGIN. */
  if (is_atomic_ddl_event(start_event)) return 0;

  /*
    If the cache is empty log "BEGIN" at the beginning of every transaction.
    Here, a transaction is either a BEGIN..COMMIT/ROLLBACK block or a single
    statement in autocommit mode.
  */
  if (cache_data->is_binlog_empty()) {
    static const char begin[] = "BEGIN";
    const char *query = nullptr;
    char buf[XID::ser_buf_size];
    char xa_start[sizeof("XA START") + 1 + sizeof(buf)];
    XID_STATE *xs = thd->get_transaction()->xid_state();
    int qlen = sizeof(begin) - 1;

    if (is_transactional && xs->has_state(XID_STATE::XA_ACTIVE)) {
      /*
        XA-prepare logging case.
      */
      qlen = sprintf(xa_start, "XA START %s", xs->get_xid()->serialize(buf));
      query = xa_start;
    } else {
      /*
        Regular transaction case.
      */
      query = begin;
    }

    Query_log_event qinfo(thd, query, qlen, is_transactional, false, true, 0,
                          true);
    if (cache_data->write_event(&qinfo)) return 1;
  }

  return 0;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: MYSQL_BIN_LOG::write_xa_to_cache
int MYSQL_BIN_LOG::write_xa_to_cache(THD *thd) {
  assert(thd->lex->sql_command == SQLCOM_XA_COMMIT ||
         thd->lex->sql_command == SQLCOM_XA_ROLLBACK);

  if (get_xa_opt(thd) == XA_ONE_PHASE) return 0;

  auto xid_state = thd->get_transaction()->xid_state();
  if (!xid_state->is_binlogged())
    return 0;  // nothing was really logged at prepare

  if (thd->is_error() && DBUG_EVALUATE_IF("simulate_xa_rm_error", 0, 1))
    return 0;  // don't binlog if there are some errors.

  auto xid_to_write = xid_state->get_xid();
  assert(xid_to_write != nullptr);
  assert(!xid_to_write->is_null() ||
         !(thd->variables.option_bits & OPTION_BIN_LOG));

  std::ostringstream oss;
  oss << "XA "
      << (thd->lex->sql_command == SQLCOM_XA_COMMIT ? "COMMIT" : "ROLLBACK")
      << " " << *xid_to_write << std::flush;
  auto query = oss.str();
  Query_log_event qinfo(thd, query.data(), query.length(), false, true, true, 0,
                        false);
  return this->write_event(&qinfo);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: MYSQL_BIN_LOG::write_event
int binlog_cache_data::write_event(Log_event *ev) {
  DBUG_TRACE;

  if (ev != nullptr) {
    DBUG_EXECUTE_IF("simulate_disk_full_at_flush_pending",
                    { DBUG_SET("+d,simulate_file_write_error"); });

    if (binary_event_serialize(ev, &m_cache)) {
      DBUG_EXECUTE_IF("simulate_disk_full_at_flush_pending", {
        DBUG_SET("-d,simulate_file_write_error");
        DBUG_SET("-d,simulate_disk_full_at_flush_pending");
        /*
           after +d,simulate_file_write_error the local cache
           is in unsane state. Since -d,simulate_file_write_error
           revokes the first simulation do_write_cache()
           can't be run without facing an assert.
           So it's blocked with the following 2nd simulation:
        */
        DBUG_SET("+d,simulate_do_write_cache_failure");
      });
      return 1;
    }
    if (ev->get_type_code() == binary_log::XID_EVENT ||
        ev->get_type_code() == binary_log::XA_PREPARE_LOG_EVENT)
      flags.with_xid = true;
    if (ev->is_using_immediate_logging()) flags.immediate = true;
    /* DDL gets marked as xid-requiring at its caching. */
    if (is_atomic_ddl_event(ev)) flags.with_xid = true;
    /* With respect to the event type being written */
    if (ev->is_sbr_logging_format()) flags.with_sbr = true;
    if (ev->is_rbr_logging_format()) flags.with_rbr = true;
    /* With respect to empty transactions */
    if (ev->starts_group()) flags.with_start = true;
    if (ev->ends_group()) flags.with_end = true;
    if (!ev->starts_group() && !ev->ends_group()) flags.with_content = true;
    m_event_counter++;
    DBUG_PRINT("debug",
               ("event_counter= %lu", static_cast<ulong>(m_event_counter)));
  }
  return 0;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: MYSQL_BIN_LOG::is_current_stmt_binlog_enabled_and_caches_empty
bool MYSQL_BIN_LOG::is_current_stmt_binlog_enabled_and_caches_empty(
    const THD *thd) const {
  DBUG_TRACE;
  if (!(thd->variables.option_bits & OPTION_BIN_LOG) ||
      !mysql_bin_log.is_open()) {
    // thd_get_cache_mngr requires binlog to option to be enabled
    return false;
  }
  binlog_cache_mngr *const cache_mngr = thd_get_cache_mngr(thd);
  if (cache_mngr == nullptr) {
    return true;
  }
  return cache_mngr->is_binlog_empty();
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: THD::binlog_query
int THD::binlog_query(THD::enum_binlog_query_type qtype, const char *query_arg,
                      size_t query_len, bool is_trans, bool direct,
                      bool suppress_use, int errcode) {
  DBUG_TRACE;
  DBUG_PRINT("enter",
             ("qtype: %s  query: '%s'", show_query_type(qtype), query_arg));
  assert(query_arg && mysql_bin_log.is_open());

  if (get_binlog_local_stmt_filter() == BINLOG_FILTER_SET) {
    /*
      The current statement is to be ignored, and not written to
      the binlog. Do not call issue_unsafe_warnings().
    */
    return 0;
  }

  /*
    If we are not in prelocked mode, mysql_unlock_tables() will be
    called after this binlog_query(), so we have to flush the pending
    rows event with the STMT_END_F set to unlock all tables at the
    slave side as well.

    If we are in prelocked mode, the flushing will be done inside the
    top-most close_thread_tables().
  */
  if (this->locked_tables_mode <= LTM_LOCK_TABLES)
    if (int error = binlog_flush_pending_rows_event(true, is_trans))
      return error;

  /*
    Warnings for unsafe statements logged in statement format are
    printed in three places instead of in decide_logging_format().
    This is because the warnings should be printed only if the statement
    is actually logged. When executing decide_logging_format(), we cannot
    know for sure if the statement will be logged:

    1 - sp_head::execute_procedure which prints out warnings for calls to
    stored procedures.

    2 - sp_head::execute_function which prints out warnings for calls
    involving functions.

    3 - THD::binlog_query (here) which prints warning for top level
    statements not covered by the two cases above: i.e., if not inside a
    procedure and a function.

    Besides, we should not try to print these warnings if it is not
    possible to write statements to the binary log as it happens when
    the execution is inside a function, or generally speaking, when
    the variables.option_bits & OPTION_BIN_LOG is false.
  */
  if ((variables.option_bits & OPTION_BIN_LOG) && sp_runtime_ctx == nullptr &&
      !binlog_evt_union.do_union)
    issue_unsafe_warnings();

  switch (qtype) {
      /*
        ROW_QUERY_TYPE means that the statement may be logged either in
        row format or in statement format.  If
        current_stmt_binlog_format is row, it means that the
        statement has already been logged in row format and hence shall
        not be logged again.
      */
    case THD::ROW_QUERY_TYPE:
      DBUG_PRINT("debug", ("is_current_stmt_binlog_format_row: %d",
                           is_current_stmt_binlog_format_row()));
      if (is_current_stmt_binlog_format_row()) return 0;
      [[fallthrough]];

      /*
        STMT_QUERY_TYPE means that the query must be logged in statement
        format; it cannot be logged in row format.  This is typically
        used by DDL statements.  It is an error to use this query type
        if current_stmt_binlog_format_row is row.

        @todo Currently there are places that call this method with
        STMT_QUERY_TYPE and current_stmt_binlog_format is row.  Fix those
        places and add assert to ensure correct behavior. /Sven
      */
    case THD::STMT_QUERY_TYPE:
      /*
        The MYSQL_BIN_LOG::write() function will set the STMT_END_F flag and
        flush the pending rows event if necessary.
      */
      {
        Query_log_event qinfo(this, query_arg, query_len, is_trans, direct,
                              suppress_use, errcode);
        /*
          Binlog table maps will be irrelevant after a Query_log_event
          (they are just removed on the slave side) so after the query
          log event is written to the binary log, we pretend that no
          table maps were written.
         */
        int error = mysql_bin_log.write_event(&qinfo);
        binlog_table_maps = 0;
        return error;
      }
      break;

    case THD::QUERY_TYPE_COUNT:
    default:
      assert(0 <= qtype && qtype < QUERY_TYPE_COUNT);
  }
  return 0;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/binlog.cc
Function: THD::is_dml_gtid_compatible
         Binlog format is checked on THD::is_dml_gtid_compatible() method.
        */
        if (!trans)
          write_all_non_transactional_are_tmp_tables =
              write_all_non_transactional_are_tmp_tables &&
              table->table->s->tmp_table;

        flags_write_all_set &= flags;
        flags_write_some_set |= flags;
        is_write = true;

        prev_write_table = table->table;

        /*
          It should be marked unsafe if a table which uses a fulltext parser
          plugin is modified. See also bug#48183.
        */
        if (!lex->is_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_FULLTEXT_PLUGIN)) {
          if (fulltext_unsafe_set(table->table->s))
            lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_FULLTEXT_PLUGIN);
        }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Query_log_event::Query_log_event
Query_log_event::Query_log_event()
    : binary_log::Query_event(),
      Log_event(header(), footer()),
      data_buf(nullptr) {}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Query_log_event::do_shall_skip not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Query_log_event::do_shall_skip not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Query_log_event::do_shall_skip not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Query_log_event::do_shall_skip not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Query_log_event::do_shall_skip not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Query_log_event::do_shall_skip not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Query_log_event::do_shall_skip not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Query_log_event::do_shall_skip not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Query_log_event::do_apply_event
  Query_log_event::do_apply_event()
*/
int Query_log_event::do_apply_event(Relay_log_info const *rli) {
  return do_apply_event(rli, query, q_len);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Xid_apply_log_event::do_shall_skip not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Xid_apply_log_event::do_shall_skip not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Xid_apply_log_event::do_shall_skip not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Xid_apply_log_event::do_shall_skip not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Rows_log_event::do_apply_event
  Query_log_event::do_apply_event()
*/
int Query_log_event::do_apply_event(Relay_log_info const *rli) {
  return do_apply_event(rli, query, q_len);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Stop_log_event::do_update_pos
int Log_event::do_update_pos(Relay_log_info *rli) {
  int error = 0;
  assert(!rli->belongs_to_client());

  if (rli) error = rli->stmt_done(common_header->log_pos);
  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log_event.cc
Function: Rows_log_event::Rows_log_event
      Rows_log_event(buf, description_event),
      binary_log::Write_rows_event(buf, description_event) {
  assert(header()->type_code == m_type);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_replica.cc
Function: is_autocommit_off_and_infotables
static bool is_autocommit_off_and_infotables(THD *thd) {
  DBUG_TRACE;
  return (thd && thd->in_multi_stmt_transaction_mode() &&
          (opt_mi_repository_id == INFO_REPOSITORY_TABLE ||
           opt_rli_repository_id == INFO_REPOSITORY_TABLE))
             ? true
             : false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_replica.cc
Function: set_slave_thread_options
void set_slave_thread_options(THD *thd) {
  DBUG_TRACE;
  /*
     It's nonsense to constrain the slave threads with max_join_size; if a
     query succeeded on master, we HAVE to execute it. So set
     OPTION_BIG_SELECTS. Setting max_join_size to HA_POS_ERROR is not enough
     (and it's not needed if we have OPTION_BIG_SELECTS) because an INSERT
     SELECT examining more than 4 billion rows would still fail (yes, because
     when max_join_size is 4G, OPTION_BIG_SELECTS is automatically set, but
     only for client threads.
  */
  ulonglong options = thd->variables.option_bits | OPTION_BIG_SELECTS;
  if (opt_log_replica_updates)
    options |= OPTION_BIN_LOG;
  else
    options &= ~OPTION_BIN_LOG;
  thd->variables.option_bits = options;
  thd->variables.completion_type = 0;

  /* Do not track GTIDs for slave threads to avoid performance issues. */
  thd->variables.session_track_gtids = SESSION_TRACK_GTIDS_OFF;
  thd->rpl_thd_ctx.session_gtids_ctx()
      .update_tracking_activeness_from_session_variable(thd);

  /*
    Set autocommit= 1 when info tables are used and autocommit == 0 to
    avoid trigger asserts on mysql_execute_command(THD *thd) caused by
    info tables updates which do not commit, like Rotate, Stop and
    skipped events handling.
  */
  if ((thd->variables.option_bits & OPTION_NOT_AUTOCOMMIT) &&
      (opt_mi_repository_id == INFO_REPOSITORY_TABLE ||
       opt_rli_repository_id == INFO_REPOSITORY_TABLE)) {
    thd->variables.option_bits |= OPTION_AUTOCOMMIT;
    thd->variables.option_bits &= ~OPTION_NOT_AUTOCOMMIT;
    thd->server_status |= SERVER_STATUS_AUTOCOMMIT;
  }

  /*
    Set thread InnoDB high priority.
  */
  DBUG_EXECUTE_IF("dbug_set_high_prio_sql_thread", {
    if (thd->system_thread == SYSTEM_THREAD_SLAVE_SQL ||
        thd->system_thread == SYSTEM_THREAD_SLAVE_WORKER)
      thd->thd_tx_priority = 1;
  });
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sp_instr.cc
Function: sp_lex_instr::execute_expression
bool sp_lex_instr::execute_expression(THD *thd, uint *nextp) {
  auto execute_guard = create_scope_guard([&]() {
    m_lex->cleanup(true);
    if (thd->in_sub_stmt == 0) {
      thd->get_stmt_da()->set_overwrite_status(true);
      thd->is_error() ? trans_rollback_stmt(thd) : trans_commit_stmt(thd);
      thd->get_stmt_da()->set_overwrite_status(false);
    }
    thd_proc_info(thd, "closing tables");
    close_thread_tables(thd);
    thd_proc_info(thd, nullptr);

    if (thd->in_sub_stmt == 0) {
      if (thd->transaction_rollback_request) {
        trans_rollback_implicit(thd);
        thd->mdl_context.release_transactional_locks();
      } else if (!thd->in_multi_stmt_transaction_mode()) {
        thd->mdl_context.release_transactional_locks();
      } else {
        thd->mdl_context.release_statement_locks();
      }
    }
  });

  /*
    Check privileges for tables in expression, open and lock those tables,
    bind data to expression so that it is ready for execution.

    Notice that temporary tables must be opened before privilege checking.
    This is because a session has all privileges for any temporary table that
    it has created, however a table must be opened in order to identify it as
    a temporary table.
  */
  if (m_lex->query_tables != nullptr) {
    if (open_temporary_tables(thd, m_lex->query_tables)) {
      return true;
    }
    if (check_table_access(thd, SELECT_ACL, m_lex->query_tables, false,
                           UINT_MAX, false)) {
      return true;
    }
  }
  if (open_and_lock_tables(thd, m_lex->query_tables, 0)) {
    return true;
  }

  if (m_arena.get_state() != Query_arena::STMT_INITIALIZED_FOR_SP) {
    m_lex->restore_cmd_properties();
    bind_fields(m_arena.item_list());
  }
  /*
    Trace the expression. This is not an SQL statement, but pretend it is
    a SELECT query expression.
  */
  Opt_trace_start ots(thd, m_lex->query_tables, SQLCOM_SELECT, &m_lex->var_list,
                      nullptr, 0, this, thd->variables.character_set_client);
  const Opt_trace_object trace_command(&thd->opt_trace);
  const Opt_trace_array trace_command_steps(&thd->opt_trace, "steps");

  if (exec_core(thd, nextp)) {
    return true;
  }

  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sp_instr.cc
Function: sp_instr_stmt::execute
bool sp_instr_stmt::execute(THD *thd, uint *nextp) {
  bool need_subst = false;
  bool rc = false;

  DBUG_PRINT("info", ("query: '%.*s'", (int)m_query.length, m_query.str));

  thd->set_query_for_display(m_query.str, m_query.length);

  const LEX_CSTRING query_backup = thd->query();

#if defined(ENABLED_PROFILING)
  /* This SP-instr is profilable and will be captured. */
  thd->profiling->set_query_source(m_query.str, m_query.length);
#endif

  /*
    If we can't set thd->query_string at all, we give up on this statement.
  */
  if (alloc_query(thd, m_query.str, m_query.length)) return true;

  /*
    Check whether we actually need a substitution of SP variables with
    NAME_CONST(...) (using subst_spvars()).
    If both of the following apply, we won't need to substitute:

    - general log is off

    - binary logging is off

    - if the query generates row events in binlog row format mode
    (DDLs are always written in statement format irrespective of binlog_format
    and they can have SP variables in it. For example, 'ALTER EVENT' is allowed
    inside a procedure and can contain SP variables in it. Those too need to be
    substituted with NAME_CONST(...))

    query_name_consts is used elsewhere in a special case concerning
    CREATE TABLE, but we do not need to do anything about that here.

    The slow query log is another special case: we won't know whether a
    query qualifies for the slow query log until after it's been
    executed. We assume that most queries are not slow, so we do not
    pre-emptively substitute just for the slow query log. If a query
    ends up being slow after all and we haven't done the substitution
    already for any of the above (general log etc.), we'll do the
    substitution immediately before writing to the log.
  */

  need_subst = !((thd->variables.option_bits & OPTION_LOG_OFF) &&
                 (!(thd->variables.option_bits & OPTION_BIN_LOG) ||
                  !mysql_bin_log.is_open() ||
                  (thd->is_current_stmt_binlog_format_row() &&
                   sqlcom_can_generate_row_events(m_lex->sql_command))));

  /*
    If we need to do a substitution but can't (OOM), give up.
  */

  if (need_subst && subst_spvars(thd, this, m_query)) return true;

  if (unlikely((thd->variables.option_bits & OPTION_LOG_OFF) == 0))
    query_logger.general_log_write(thd, COM_QUERY, thd->query().str,
                                   thd->query().length);

  rc = validate_lex_and_execute_core(thd, nextp, false);

  if (thd->get_stmt_da()->is_eof()) {
    /* Finalize server status flags after executing a statement. */
    thd->update_slow_query_status();

    thd->send_statement_status();
  }

  if (!rc && unlikely(log_slow_applicable(thd))) {
    /*
      We actually need to write the slow log. Check whether we already
      called subst_spvars() above, otherwise, do it now.  In the highly
      unlikely event of subst_spvars() failing (OOM), we'll try to log
      the unmodified statement instead.
    */
    if (!need_subst) rc = subst_spvars(thd, this, m_query);
    /*
      We currently do not support --log-slow-extra for this case,
      and therefore pass in a null-pointer instead of a pointer to
      state at the beginning of execution.
    */
    log_slow_do(thd);
  }

  /*
    With the current setup, a subst_spvars() and a mysql_rewrite_query()
    (rewriting passwords etc.) will not both happen to a query.
    If this ever changes, we give the engineer pause here so they will
    double-check whether the potential conflict they created is a
    problem.
  */
  assert((thd->query_name_consts == 0) ||
         (thd->rewritten_query().length() == 0));

  thd->set_query(query_backup);
  thd->query_name_consts = 0;

  return rc || thd->is_error();
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_base.cc
Function: DML_prelocking_strategy::handle_table
bool DML_prelocking_strategy::handle_table(THD *thd,
                                           Query_tables_list *prelocking_ctx,
                                           Table_ref *table_list,
                                           bool *need_prelocking) {
  /* We rely on a caller to check that table is going to be changed. */
  assert(table_list->lock_descriptor().type >= TL_WRITE_ALLOW_WRITE);

  if (table_list->trg_event_map) {
    if (table_list->table->triggers) {
      *need_prelocking = true;

      if (table_list->table->triggers->add_tables_and_routines_for_triggers(
              thd, prelocking_ctx, table_list))
        return true;
    }

    /*
      When FOREIGN_KEY_CHECKS is 0 we are not going to do any foreign key checks
      so we don't need to add child and parent tables to the prelocking list.

      However, since trigger or stored function might change this variable for
      their duration (it is, actually, advisable to do so in some scenarios),
      we can apply this optimization only to tables which are directly used by
      the top-level statement.

      While processing LOCK TABLES, we must disregard F_K_C too, since the
      prelocking set will be used while in LTM mode, and F_K_C may be turned
      on later, after the set has been established.
    */
    if ((!(thd->variables.option_bits & OPTION_NO_FOREIGN_KEY_CHECKS) ||
         prelocking_ctx->sql_command == SQLCOM_LOCK_TABLES ||
         table_list->prelocking_placeholder) &&
        !(table_list->table->s->tmp_table)) {
      bool is_insert =
          (table_list->trg_event_map &
           static_cast<uint8>(1 << static_cast<int>(TRG_EVENT_INSERT)));
      bool is_update =
          (table_list->trg_event_map &
           static_cast<uint8>(1 << static_cast<int>(TRG_EVENT_UPDATE)));
      bool is_delete =
          (table_list->trg_event_map &
           static_cast<uint8>(1 << static_cast<int>(TRG_EVENT_DELETE)));

      process_table_fks(thd, prelocking_ctx, table_list->table->s, is_insert,
                        is_update, is_delete, table_list->belong_to_view,
                        need_prelocking);
    }
  }
  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_base.cc
Function: close_temporary_tables
bool close_temporary_tables(THD *thd) {
  DBUG_TRACE;
  TABLE *table;
  TABLE *next = nullptr;
  TABLE *prev_table;
  /* Assume thd->variables.option_bits has OPTION_QUOTE_SHOW_CREATE */
  bool was_quote_show = true;
  bool error = false;
  int slave_closed_temp_tables = 0;

  if (!thd->temporary_tables) return false;

  assert(!thd->slave_thread ||
         thd->system_thread != SYSTEM_THREAD_SLAVE_WORKER);

  /*
    Ensure we don't have open HANDLERs for tables we are about to close.
    This is necessary when close_temporary_tables() is called as part
    of execution of BINLOG statement (e.g. for format description event).
  */
  mysql_ha_rm_temporary_tables(thd);
  if (!mysql_bin_log.is_open()) {
    TABLE *tmp_next;
    for (TABLE *t = thd->temporary_tables; t; t = tmp_next) {
      tmp_next = t->next;
      mysql_lock_remove(thd, thd->lock, t);
      /*
        We should not meet temporary tables created by ALTER TABLE here.
        It is responsibility of ALTER statement to close them. Otherwise
        it might be necessary to remove them from DD as well.
      */
      assert(t->s->tmp_table_def);
      close_temporary(thd, t, true, true);
      slave_closed_temp_tables++;
    }

    thd->temporary_tables = nullptr;
    if (thd->slave_thread) {
      atomic_replica_open_temp_tables -= slave_closed_temp_tables;
      thd->rli_slave->get_c_rli()->atomic_channel_open_temp_tables -=
          slave_closed_temp_tables;
    }

    return false;
  }

  /*
    We are about to generate DROP TEMPORARY TABLE statements for all
    the left out temporary tables. If GTID_NEXT is set (e.g. if user
    did SET GTID_NEXT just before disconnecting the client), we must
    ensure that it will be able to generate GTIDs for the statements
    with this server's UUID. Therefore we set gtid_next to
    AUTOMATIC_GTID.
  */
  gtid_state->update_on_rollback(thd);
  thd->variables.gtid_next.set_automatic();

  /*
    We must separate transactional temp tables and
    non-transactional temp tables in two distinct DROP statements
    to avoid the splitting if a slave server reads from this binlog.
  */

  /* Better add "if exists", in case a RESET MASTER has been done */
  const char stub[] = "DROP /*!40005 TEMPORARY */ TABLE IF EXISTS ";
  uint stub_len = sizeof(stub) - 1;
  char buf_trans[256], buf_non_trans[256];
  String s_query_trans =
      String(buf_trans, sizeof(buf_trans), system_charset_info);
  String s_query_non_trans =
      String(buf_non_trans, sizeof(buf_non_trans), system_charset_info);
  bool found_user_tables = false;
  bool found_trans_table = false;
  bool found_non_trans_table = false;

  memcpy(buf_trans, stub, stub_len);
  memcpy(buf_non_trans, stub, stub_len);

  /*
    Insertion sort of temp tables by pseudo_thread_id to build ordered list
    of sublists of equal pseudo_thread_id
  */

  for (prev_table = thd->temporary_tables, table = prev_table->next; table;
       prev_table = table, table = table->next) {
    TABLE *prev_sorted /* same as for prev_table */, *sorted;
    /*
      We should not meet temporary tables created by ALTER TABLE here.
      It is responsibility of ALTER statement to close them. Otherwise
      it might be necessary to remove them from DD as well.
    */
    assert(table->s->tmp_table_def);
    if (is_user_table(table)) {
      if (!found_user_tables) found_user_tables = true;
      for (prev_sorted = nullptr, sorted = thd->temporary_tables;
           sorted != table; prev_sorted = sorted, sorted = sorted->next) {
        if (!is_user_table(sorted) || tmpkeyval(sorted) > tmpkeyval(table)) {
          /* move into the sorted part of the list from the unsorted */
          prev_table->next = table->next;
          table->next = sorted;
          if (prev_sorted) {
            prev_sorted->next = table;
          } else {
            thd->temporary_tables = table;
          }
          table = prev_table;
          break;
        }
      }
    }
  }

  /* We always quote db,table names though it is slight overkill */
  if (found_user_tables && !(was_quote_show = (thd->variables.option_bits &
                                               OPTION_QUOTE_SHOW_CREATE))) {
    thd->variables.option_bits |= OPTION_QUOTE_SHOW_CREATE;
  }

  /*
    Make LEX consistent with DROP TEMPORARY TABLES statement which we
    are going to log. This is important for the binary logging code.
  */
  LEX *lex = thd->lex;
  enum_sql_command sav_sql_command = lex->sql_command;
  bool sav_drop_temp = lex->drop_temporary;
  lex->sql_command = SQLCOM_DROP_TABLE;
  lex->drop_temporary = true;

  /* scan sorted tmps to generate sequence of DROP */
  for (table = thd->temporary_tables; table; table = next) {
    if (is_user_table(table) && table->should_binlog_drop_if_temp()) {
      bool save_thread_specific_used = thd->thread_specific_used;
      my_thread_id save_pseudo_thread_id = thd->variables.pseudo_thread_id;
      /* Set pseudo_thread_id to be that of the processed table */
      thd->variables.pseudo_thread_id = tmpkeyval(table);
      String db;
      db.append(table->s->db.str);
      /* Loop forward through all tables that belong to a common database
         within the sublist of common pseudo_thread_id to create single
         DROP query
      */
      for (s_query_trans.length(stub_len), s_query_non_trans.length(stub_len),
           found_trans_table = false, found_non_trans_table = false;
           table && is_user_table(table) &&
           tmpkeyval(table) == thd->variables.pseudo_thread_id &&
           table->s->db.length == db.length() &&
           strcmp(table->s->db.str, db.ptr()) == 0;
           table = next) {
        /* Separate transactional from non-transactional temp tables */
        if (table->should_binlog_drop_if_temp()) {
          /* Separate transactional from non-transactional temp tables */
          if (table->s->tmp_table == TRANSACTIONAL_TMP_TABLE) {
            found_trans_table = true;
            /*
              We are going to add ` around the table names and possible more
              due to special characters
            */
            append_identifier(thd, &s_query_trans, table->s->table_name.str,
                              strlen(table->s->table_name.str));
            s_query_trans.append(',');
          } else if (table->s->tmp_table == NON_TRANSACTIONAL_TMP_TABLE) {
            found_non_trans_table = true;
            /*
              We are going to add ` around the table names and possible more
              due to special characters
            */
            append_identifier(thd, &s_query_non_trans, table->s->table_name.str,
                              strlen(table->s->table_name.str));
            s_query_non_trans.append(',');
          }
        }

        next = table->next;
        mysql_lock_remove(thd, thd->lock, table);
        close_temporary(thd, table, true, true);
        slave_closed_temp_tables++;
      }
      thd->clear_error();
      const CHARSET_INFO *cs_save = thd->variables.character_set_client;
      thd->variables.character_set_client = system_charset_info;
      thd->thread_specific_used = true;

      if (found_trans_table) {
        Query_log_event qinfo(thd, s_query_trans.ptr(),
                              s_query_trans.length() - 1, false, true, false,
                              0);
        qinfo.db = db.ptr();
        qinfo.db_len = db.length();
        thd->variables.character_set_client = cs_save;

        thd->get_stmt_da()->set_overwrite_status(true);
        if ((error = (mysql_bin_log.write_event(&qinfo) ||
                      mysql_bin_log.commit(thd, true) || error))) {
          /*
            If we're here following THD::cleanup, thence the connection
            has been closed already. So lets print a message to the
            error log instead of pushing yet another error into the
            Diagnostics_area.

            Also, we keep the error flag so that we propagate the error
            up in the stack. This way, if we're the SQL thread we notice
            that close_temporary_tables failed. (Actually, the SQL
            thread only calls close_temporary_tables while applying old
            Start_log_event_v3 events.)
          */
          LogErr(ERROR_LEVEL, ER_BINLOG_FAILED_TO_WRITE_DROP_FOR_TEMP_TABLES);
        }
        thd->get_stmt_da()->set_overwrite_status(false);
      }

      if (found_non_trans_table) {
        Query_log_event qinfo(thd, s_query_non_trans.ptr(),
                              s_query_non_trans.length() - 1, false, true,
                              false, 0);
        qinfo.db = db.ptr();
        qinfo.db_len = db.length();
        thd->variables.character_set_client = cs_save;

        thd->get_stmt_da()->set_overwrite_status(true);
        if ((error = (mysql_bin_log.write_event(&qinfo) ||
                      mysql_bin_log.commit(thd, true) || error))) {
          /*
            If we're here following THD::cleanup, thence the connection
            has been closed already. So lets print a message to the
            error log instead of pushing yet another error into the
            Diagnostics_area.

            Also, we keep the error flag so that we propagate the error
            up in the stack. This way, if we're the SQL thread we notice
            that close_temporary_tables failed. (Actually, the SQL
            thread only calls close_temporary_tables while applying old
            Start_log_event_v3 events.)
          */
          LogErr(ERROR_LEVEL, ER_BINLOG_FAILED_TO_WRITE_DROP_FOR_TEMP_TABLES);
        }
        thd->get_stmt_da()->set_overwrite_status(false);
      }

      thd->variables.pseudo_thread_id = save_pseudo_thread_id;
      thd->thread_specific_used = save_thread_specific_used;
    } else {
      next = table->next;
      /*
        This is for those cases when we have acquired lock but drop temporary
        table will not be logged.
      */
      mysql_lock_remove(thd, thd->lock, table);
      close_temporary(thd, table, true, true);
      slave_closed_temp_tables++;
    }
  }
  lex->drop_temporary = sav_drop_temp;
  lex->sql_command = sav_sql_command;

  if (!was_quote_show)
    thd->variables.option_bits &=
        ~OPTION_QUOTE_SHOW_CREATE; /* restore option */

  thd->temporary_tables = nullptr;
  if (thd->slave_thread) {
    atomic_replica_open_temp_tables -= slave_closed_temp_tables;
    thd->rli_slave->get_c_rli()->atomic_channel_open_temp_tables -=
        slave_closed_temp_tables;
  }

  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_cursor.cc
Function: Query_result_materialize::prepare
  bool prepare(THD *thd, const mem_root_deque<Item *> &list,
               Query_expression *u) override;
  bool start_execution(THD *thd) override;
  bool send_result_set_metadata(THD *thd, const mem_root_deque<Item *> &list,
                                uint flags) override;
  void cleanup() override { m_result->cleanup(); }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_handler.cc
Function: prepare_transaction_context not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_handler.cc
Function: prepare_transaction_context not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_handler.cc
Function: prepare_transaction_context not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_handler.cc
Function: prepare_transaction_context not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_handler.cc
Function: prepare_transaction_context not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_handler.cc
Function: prepare_transaction_context not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_group_replication.cc
Function: get_server_startup_prerequirements
void get_server_startup_prerequirements(Trans_context_info &requirements) {
  requirements.binlog_enabled = opt_bin_log;
  requirements.binlog_format = global_system_variables.binlog_format;
  requirements.binlog_checksum_options = binlog_checksum_options;
  requirements.gtid_mode = global_gtid_mode.get();
  requirements.log_replica_updates = opt_log_replica_updates;
  requirements.transaction_write_set_extraction =
      global_system_variables.transaction_write_set_extraction;
  requirements.mi_repository_type = opt_mi_repository_id;
  requirements.rli_repository_type = opt_rli_repository_id;
  requirements.parallel_applier_type = mts_parallel_option;
  requirements.parallel_applier_workers = opt_mts_replica_parallel_workers;
  requirements.parallel_applier_preserve_commit_order =
      opt_replica_preserve_commit_order;
  requirements.lower_case_table_names = lower_case_table_names;
  requirements.default_table_encryption =
      global_system_variables.default_table_encryption;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_lex.cc
Function: Query_block::make_active_options
void Query_block::make_active_options(ulonglong added_options,
                                      ulonglong removed_options) {
  m_active_options =
      (m_base_options | added_options | parent_lex->statement_options() |
       parent_lex->thd->variables.option_bits) &
      ~removed_options;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_lex.h
Function: Query_block::set_base_options
  void set_base_options(ulonglong options_arg) {
    DBUG_EXECUTE_IF("no_const_tables", options_arg |= OPTION_NO_CONST_TABLES;);

    // Make sure we do not overwrite options by accident
    assert(m_base_options == 0 && m_active_options == 0);
    m_base_options = options_arg;
    m_active_options = options_arg;
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_optimizer.cc
Function: warn_index_not_applicable not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_optimizer.cc
Function: warn_index_not_applicable not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_optimizer.cc
Function: warn_index_not_applicable not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_optimizer.cc
Function: warn_index_not_applicable not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_parse.cc
Function: check_secondary_engine_statement not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_parse.cc
Function: check_secondary_engine_statement not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_parse.cc
Function: check_secondary_engine_statement not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_parse.cc
Function: check_secondary_engine_statement not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_parse.cc
Function: check_secondary_engine_statement not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_parse.cc
Function: check_secondary_engine_statement not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_parse.cc
Function: check_secondary_engine_statement not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_parse.cc
Function: check_secondary_engine_statement not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_parse.cc
Function: check_secondary_engine_statement not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_parse.cc
Function: mysql_execute_command
    KILL QUERY may come after cleanup in mysql_execute_command(). Next query
    execution is interrupted due to this. So resetting THD::killed here.

    THD::killed value can not be KILL_TIMEOUT here as timer used for statement
    max execution time is disarmed in the cleanup stage of
    mysql_execute_command. KILL CONNECTION should terminate the connection.
    Hence resetting THD::killed only for KILL QUERY case here.
  */
  if (thd->killed == THD::KILL_QUERY) thd->killed = THD::NOT_KILLED;
  thd->set_time();
  if (is_time_t_valid_for_timestamp(thd->query_start_in_secs()) == false) {
    /*
      If the time has gone past end of epoch we need to shutdown the server. But
      there is possibility of getting invalid time value on some platforms.
      For example, gettimeofday() might return incorrect value on solaris
      platform. Hence validating the current time with 5 iterations before
      initiating the normal server shutdown process because of time getting
      past 2038.
    */
    const int max_tries = 5;
    LogErr(WARNING_LEVEL, ER_CONFIRMING_THE_FUTURE, max_tries);

    int tries = 0;
    while (++tries <= max_tries) {
      thd->set_time();
      if (is_time_t_valid_for_timestamp(thd->query_start_in_secs()) == true) {
        LogErr(WARNING_LEVEL, ER_BACK_IN_TIME, tries);
        break;
      }
      LogErr(WARNING_LEVEL, ER_FUTURE_DATE, tries);
    }
    if (tries > max_tries) {
      /*
        If the time has got past epoch, we need to shut this server down.
        We do this by making sure every command is a shutdown and we
        have enough privileges to shut the server down

        TODO: remove this when we have full 64 bit my_time_t support
      */
      LogErr(ERROR_LEVEL, ER_UNSUPPORTED_DATE);
      ulong master_access = thd->security_context()->master_access();
      thd->security_context()->set_master_access(master_access | SHUTDOWN_ACL);
      error = true;
      kill_mysql();
    }
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_view.cc
Function: mysql_create_view
bool mysql_create_view(THD *thd, Table_ref *views, enum_view_create_mode mode) {
  LEX *lex = thd->lex;
  bool link_to_local;
  /* first table in list is target VIEW name => cut off it */
  Table_ref *view = lex->unlink_first_table(&link_to_local);
  Table_ref *tables = lex->query_tables;
  Table_ref *tbl;
  Query_block *const query_block = lex->query_block;
  Query_block *sl;
  Query_expression *const unit = lex->unit;
  bool res = false;
  bool exists = false;
  DBUG_TRACE;
  dd::cache::Dictionary_client::Auto_releaser releaser(thd->dd_client());

  /* This is ensured in the parser. */
  assert(!lex->result && !lex->param_list.elements);

  /*
    We can't allow taking exclusive meta-data locks of unlocked view under
    LOCK TABLES since this might lead to deadlock. Since at the moment we
    can't really lock view with LOCK TABLES we simply prohibit creation/
    alteration of views under LOCK TABLES.
  */

  if (thd->locked_tables_mode) {
    my_error(ER_LOCK_OR_ACTIVE_TRANSACTION, MYF(0));
    res = true;
    goto err;
  }

  if (create_view_precheck(thd, tables, view, mode)) {
    res = true;
    goto err;
  }

  lex->link_first_table_back(view, link_to_local);
  view->open_type = OT_BASE_ONLY;

  /*
    No pre-opening of temporary tables is possible since must
    wait until Table_ref::open_type is set. So we have to open
    them here instead.
  */
  if (open_temporary_tables(thd, lex->query_tables)) {
    view = lex->unlink_first_table(&link_to_local);
    res = true;
    goto err;
  }

  /* Not required to lock any tables. */
  if (open_tables_for_query(thd, lex->query_tables, 0)) {
    view = lex->unlink_first_table(&link_to_local);
    res = true;
    goto err;
  }

  view = lex->unlink_first_table(&link_to_local);

  /*
    Checking the existence of the database in which the view is to be created.
    Errors will be reported in dd::schema_exists().
  */
  if (dd::schema_exists(thd, view->db, &exists)) {
    res = true;
    goto err;
  } else if (!exists) {
    my_error(ER_BAD_DB_ERROR, MYF(0), view->db);
    res = true;
    goto err;
  }

  if (mode == enum_view_create_mode::VIEW_ALTER &&
      fill_defined_view_parts(thd, view)) {
    res = true;
    goto err;
  }

  sp_cache_invalidate();

  if (!lex->definer) {
    /*
      DEFINER-clause is missing; we have to create default definer in
      persistent arena to be PS/SP friendly.
      If this is an ALTER VIEW then the current user should be set as
      the definer.
    */
    Prepared_stmt_arena_holder ps_arena_holder(thd);

    lex->definer = create_default_definer(thd);

    if (!lex->definer) goto err;
  }

  /*
    check definer of view:
      - same as current user
      - current user has SUPER_ACL or SET_USER_ID
  */
  if (lex->definer &&
      (strcmp(lex->definer->user.str,
              thd->security_context()->priv_user().str) != 0 ||
       my_strcasecmp(system_charset_info, lex->definer->host.str,
                     thd->security_context()->priv_host().str) != 0)) {
    Security_context *sctx = thd->security_context();
    if (!(sctx->check_access(SUPER_ACL) ||
          sctx->has_global_grant(STRING_WITH_LEN("SET_USER_ID")).first)) {
      my_error(ER_SPECIFIC_ACCESS_DENIED_ERROR, MYF(0), "SUPER or SET_USER_ID");
      res = true;
      goto err;
    } else if (sctx->can_operate_with({lex->definer}, consts::system_user,
                                      true)) {
      res = true;
      goto err;
    } else {
      if (!is_acl_user(thd, lex->definer->host.str, lex->definer->user.str)) {
        push_warning_printf(thd, Sql_condition::SL_NOTE, ER_NO_SUCH_USER,
                            ER_THD(thd, ER_NO_SUCH_USER),
                            lex->definer->user.str, lex->definer->host.str);
      }
    }
  }

  /*
    check that tables are not temporary  and this VIEW do not used in query
    (it is possible with ALTERing VIEW).
    open_and_lock_tables can change the value of tables,
    e.g. it may happen if before the function call tables was equal to 0.
  */
  for (tbl = lex->query_tables; tbl; tbl = tbl->next_global) {
    /* is this table view and the same view which we creates now? */
    if (tbl->is_view() && strcmp(tbl->db, view->db) == 0 &&
        strcmp(tbl->table_name, view->table_name) == 0) {
      my_error(ER_NO_SUCH_TABLE, MYF(0), tbl->db, tbl->table_name);
      res = true;
      goto err;
    }

    /*
      tbl->table can be NULL when tbl is a placeholder for a view
      that is indirectly referenced via a stored function from the
      view being created. We don't check these indirectly
      referenced views in CREATE VIEW so they don't have table
      object.
    */
    if (tbl->table) {
      /*
        is this table temporary and is not a derived table, a view, a recursive
        reference, a table function or a schema table?
      */
      if (tbl->table->s->tmp_table != NO_TMP_TABLE && !tbl->is_placeholder()) {
        my_error(ER_VIEW_SELECT_TMPTABLE, MYF(0), tbl->alias);
        res = true;
        goto err;
      }
    }
  }

  /* prepare select to resolve all fields */
  lex->context_analysis_only |= CONTEXT_ANALYSIS_ONLY_VIEW;
  if (!unit->is_prepared()) {
    Prepared_stmt_arena_holder ps_arena_holder(thd);
    /*
      @todo - the following code is duplicated in mysql_test_create_view.
              ensure that we have a single preparation function for create view.
    */
    if (unit->prepare(thd, nullptr, nullptr, 0, 0)) {
      /*
        some errors from prepare are reported to user, if is not then
        it will be checked after err: label
      */
      res = true;
      goto err;
    }
    /* Check if the auto generated column names are conforming. */
    make_valid_column_names(lex);

    /*
      Only column names of the first query block should be checked for
      duplication; any further UNION-ed part isn't used for determining
      names of the view's columns.
    */
    if (check_duplicate_names(view->derived_column_names(), query_block->fields,
                              true)) {
      res = true;
      goto err;
    }

    /*
      Make sure the view doesn't have so many columns that we hit the
      64k header limit if the view is materialized as a MyISAM table.
    */
    if (query_block->fields.size() > MAX_FIELDS) {
      my_error(ER_TOO_MANY_FIELDS, MYF(0));
      res = true;
      goto err;
    }
  } else {
    lex->restore_cmd_properties();
    bind_fields(thd->stmt_arena->item_list());
  }

  /*
    Compare/check grants on view with grants of underlying tables
  */
  if (view->is_internal())
    view->set_privileges(SELECT_ACL);
  else
    fill_effective_table_privileges(thd, &view->grant, view->db,
                                    view->get_table_name());

  /*
    Make sure that the current user does not have more column-level privileges
    on the newly created view than he/she does on the underlying
    tables. E.g. it must not be so that the user has UPDATE privileges on a
    view column of he/she doesn't have it on the underlying table's
    corresponding column. In that case, return an error for CREATE VIEW.
   */
  {
    Item *report_item = nullptr;
    /*
       This will hold the intersection of the privileges on all columns in the
       view.
     */
    uint final_priv = VIEW_ANY_ACL;

    for (sl = query_block; sl; sl = sl->next_query_block()) {
      assert(view->db); /* Must be set in the parser */
      for (Item *item : sl->visible_fields()) {
        Item_field *fld = item->field_for_view_update();
        uint priv = (get_column_grant(thd, &view->grant, view->db,
                                      view->table_name, item->item_name.ptr()) &
                     VIEW_ANY_ACL);

        if (fld && !fld->field->table->s->tmp_table) {
          final_priv &= fld->have_privileges;

          if (~fld->have_privileges & priv) report_item = item;
        }
      }
    }

    if (!final_priv && report_item) {
      my_error(ER_COLUMNACCESS_DENIED_ERROR, MYF(0), "create view",
               thd->security_context()->priv_user().str,
               thd->security_context()->priv_host().str,
               report_item->item_name.ptr(), view->table_name);
      res = true;
      goto err;
    }
  }

  if ((res = mysql_register_view(thd, view, mode))) goto err_with_rollback;

  /*
    View TABLE_SHARE must be removed from the table definition cache in order
    to make ALTER VIEW work properly. Otherwise, we would not be able to
    detect meta-data changes after ALTER VIEW.
  */
  tdc_remove_table(thd, TDC_RT_REMOVE_ALL, view->db, view->table_name, false);

  // Update metadata of views referencing "view".
  {
    Uncommitted_tables_guard uncommited_tables(thd);
    uncommited_tables.add_table(view);
    if ((res = update_referencing_views_metadata(thd, view, false,
                                                 &uncommited_tables)))
      goto err_with_rollback;
  }

  // Binlog CREATE/ALTER/CREATE OR REPLACE event.
  if (mysql_bin_log.is_open() &&
      (thd->variables.option_bits & OPTION_BIN_LOG)) {
    String buff;
    const LEX_CSTRING command[3] = {{STRING_WITH_LEN("CREATE ")},
                                    {STRING_WITH_LEN("ALTER ")},
                                    {STRING_WITH_LEN("CREATE OR REPLACE ")}};

    buff.append(command[static_cast<int>(thd->lex->create_view_mode)].str,
                command[static_cast<int>(thd->lex->create_view_mode)].length);
    view_store_options(thd, views, &buff);
    buff.append(STRING_WITH_LEN("VIEW "));
    /* Test if user supplied a db (ie: we did not use thd->db) */
    if (views->db && views->db[0] &&
        (thd->db().str == nullptr || strcmp(views->db, thd->db().str))) {
      append_identifier(thd, &buff, views->db, views->db_length);
      buff.append('.');
    }
    append_identifier(thd, &buff, views->table_name, views->table_name_length);
    if (view->derived_column_names()) {
      int i = 0;
      for (auto name : *view->derived_column_names()) {
        buff.append(i++ ? ", " : "(");
        append_identifier(thd, &buff, name.str, name.length);
      }
      buff.append(')');
    }
    buff.append(STRING_WITH_LEN(" AS "));
    buff.append(views->source.str, views->source.length);

    int errcode = query_error_code(thd, true);
    thd->add_to_binlog_accessed_dbs(views->db);
    if ((res = thd->binlog_query(THD::STMT_QUERY_TYPE, buff.ptr(),
                                 buff.length(), true, false, false, errcode)))
      goto err_with_rollback;
  }

  // Commit changes to the data-dictionary and binary log.
  res = DBUG_EVALUATE_IF("simulate_create_view_failure", true, false) ||
        trans_commit_stmt(thd) || trans_commit(thd);
  if (res) goto err_with_rollback;

  my_ok(thd);
  lex->link_first_table_back(view, link_to_local);
  return false;

err_with_rollback:
  DBUG_EXECUTE_IF("simulate_create_view_failure",
                  my_error(ER_UNKNOWN_ERROR, MYF(0)););

  trans_rollback_stmt(thd);
  /*
    Full rollback in case we have THD::transaction_rollback_request
    and to synchronize DD state in cache and on disk (as statement
    rollback doesn't clear DD cache of modified uncommitted objects).
  */
  trans_rollback(thd);

err:
  THD_STAGE_INFO(thd, stage_end);
  lex->link_first_table_back(view, link_to_local);
  unit->cleanup(true);

  return res || thd->is_error();
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_partition.cc
Function: add_name_string
static int add_name_string(File fptr, const char *name) {
  int err;
  THD *thd = current_thd;
  ulonglong save_options = thd->variables.option_bits;
  thd->variables.option_bits &= ~OPTION_QUOTE_SHOW_CREATE;
  err = add_ident_string(fptr, name);
  thd->variables.option_bits = save_options;
  return err;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_partition.cc
Function: append_field_list
static bool append_field_list(THD *thd, String *str, List<char> field_list) {
  uint i, num_fields;

  List_iterator<char> part_it(field_list);
  num_fields = field_list.elements;
  i = 0;
  ulonglong save_options = thd->variables.option_bits;
  thd->variables.option_bits &= ~OPTION_QUOTE_SHOW_CREATE;
  while (i < num_fields) {
    const char *field_str = part_it++;
    append_identifier(thd, str, field_str, strlen(field_str));
    if (i != (num_fields - 1)) {
      if (str->append(',')) {
        thd->variables.option_bits = save_options;
        return true;
      }
    }
    i++;
  }
  thd->variables.option_bits = save_options;
  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_planner.cc
Function: calculate_condition_filter
float calculate_condition_filter(const JOIN_TAB *const tab,
                                 const Key_use *const keyuse,
                                 table_map used_tables, double fanout,
                                 bool is_join_buffering, bool write_to_trace,
                                 Opt_trace_object &parent_trace) {
  /*
    Because calculating condition filtering has a cost, it should only
    be done if the filter is meaningful. It is meaningful if the query
    is an EXPLAIN, if a max_join_size has been specified, or if the
    filter may influence the QEP.

    Note that this means that EXPLAIN FOR CONNECTION will typically
    not find a calculated filtering value for the last table in a QEP
    (i.e., it will be 1.0).

    Calculate condition filter if
    1)  Condition filtering is enabled, and
    2a) Condition filtering is about to be calculated for a scan that
        might do join buffering. Rationale: When a table is scanned
        and joined with rows in a buffer, constant predicates are
        evaluated on rows in the joined table. Only rows that pass the
        constant predicates are attempted joined with the prefix rows
        in the buffer. The filtering effect is the estimate of how
        many rows pass the constant predicate evaluation.
    2b) 'tab' is not the last table that will be added to the plan.
        Rationale: filtering only reduces the number of rows sent to
        the next step in the join ordering and therefore has no effect
        on the last table in the join order, or
    2c) 'tab' is in a subselect. Rationale: for subqueries, view/table
        materializations, the filtering effect is needed to
        estimate the number of rows in the potentially materialized
        subquery, or
    2d) 'tab' is in a query_block with a semijoin nest. Rationale: the
        cost of some of the duplicate elimination strategies depends
        on the size of the output, or
    2e) The query has either an order by or group by clause and a limit clause.
        Rationale: some of the limit optimizations take the filtering effect
        on the last table into account.
    2f) Statement is EXPLAIN
    2g) max_join_size is in effect.

    Note: Even in the case of a single table query, the filtering
    effect may effect the QEP because the cost of sorting fewer rows
    is lower. This is currently ignored since single table
    optimization performance is so important.
  */
  const THD *thd = tab->join()->thd;
  TABLE *const table = tab->table();
  const table_map remaining_tables =
      ~used_tables & ~tab->table_ref->map() & tab->join()->all_table_map;
  if (!(thd->optimizer_switch_flag(
            OPTIMIZER_SWITCH_COND_FANOUT_FILTER) &&  // 1)
        (is_join_buffering ||                        // 2a
         remaining_tables != 0 ||                    // 2b
         tab->join()
                 ->query_block->master_query_expression()
                 ->outer_query_block() != nullptr ||     // 2c
         !tab->join()->query_block->sj_nests.empty() ||  // 2d
         ((!tab->join()->order.empty() || !tab->join()->group_list.empty()) &&
          tab->join()->query_expression()->select_limit_cnt !=
              HA_POS_ERROR) ||                                      // 2e
         thd->lex->is_explain() ||                                  // 2f
         !Overlaps(thd->variables.option_bits, OPTION_BIG_SELECTS)  // 2g
         )))
    return COND_FILTER_ALLPASS;

  // No filtering is calculated if we expect less than one row to be fetched
  if (fanout < 1.0 || tab->found_records < 1.0 || tab->records() < 1.0)
    return COND_FILTER_ALLPASS;

  /*
    cond_set has the column bit set for each column involved in a
    predicate. If no bits are set, there are no predicates on this
    table.
  */
  if (bitmap_is_clear_all(&table->cond_set)) return COND_FILTER_ALLPASS;

  /*
    Use TABLE::tmp_set to keep track of fields that should not
    contribute to filtering effect.
    First, verify it's not used.
  */
  assert(bitmap_is_clear_all(&table->tmp_set));

  float filter = COND_FILTER_ALLPASS;

  Opt_trace_context *const trace = &tab->join()->thd->opt_trace;

  Opt_trace_disable_I_S disable_trace(trace, !write_to_trace);
  Opt_trace_array filtering_effect_trace(trace, "filtering_effect");

  /*
    If ref/range access, the condition is already included in the
    record estimate. The fields used by the ref/range access method
    shall not contribute to the filtering estimate since 'filter' is
    percentage of fetched rows that are filtered away.
  */
  if (keyuse) {
    const KEY *key = table->key_info + keyuse->key;

    if (keyuse[0].keypart == FT_KEYPART) {
      /*
        Fulltext indexes are special because keyuse->keypart does not
        contain the keypart number but a constant (FT_KEYPART)
        defining that it is a fulltext index. However, since fulltext
        search demands that all indexed keyparts are used, iterating
        over the next 'actual_key_parts' works.
      */
      for (uint i = 0; i < key->actual_key_parts; i++)
        bitmap_set_bit(&table->tmp_set, key->key_part[i].field->field_index());
    } else {
      const Key_use *curr_ku = keyuse;

      /*
        'keyuse' describes the chosen ref access method for 'tab'. It
        is a pointer into JOIN::keyuse_array which describes all
        possible ways to perform ref access for all indexes of all
        tables. E.g., keyuse for the index "t1.idx(kp1, kp2)" and
        query condition

          "WHERE t1.kp1=1 AND t1.kp1=t2.col AND t1.kp2=2"
        will be
          [keyuse(t1.kp1,1),keyuse(t1.kp1,t2.col),keyuse(t1.kp2,2)]

        1) Since there may be multiple ways to ref-access any index it
        is not enough to look at keyuse[0..actual_key_parts-1].
        Instead, stop iterating when curr_ku no longer points to the
        specified index in 'tab'.

        2) In addition, there may be predicates that are relevant for
        an index but that will not be used by the 'ref' access (the
        keypart is not bound). This could e.g. be because the
        predicate depends on a value from a table later in the join
        sequence or because there is ref_or_null access:

          "WHERE t1.kp1=1 AND t1.kp2=t2.col"
             => t1.kp2 not used by ref since it depends on
                table later in join sequenc
          "WHERE (t1.kp1=1 OR t1.kp1 IS NULL) AND t1.kp2=2"
             => t1.kp2 not used by ref since kp1 is ref_or_null
      */
      while (curr_ku->table_ref == tab->table_ref &&         // 1)
             curr_ku->key == keyuse->key &&                  // 1)
             curr_ku->keypart_map & keyuse->bound_keyparts)  // 2)
      {
        bitmap_set_bit(&table->tmp_set,
                       key->key_part[curr_ku->keypart].field->field_index());
        curr_ku++;
      }
    }
  } else if (tab->range_scan())
    get_fields_used(tab->range_scan(), &table->tmp_set);

  /*
    Early exit if the only conditions for the table refers to columns
    used by the access method.
  */
  if (bitmap_is_subset(&table->cond_set, &table->tmp_set)) {
    assert(filter == COND_FILTER_ALLPASS);
    goto cleanup;
  }
  /*
    If the range optimizer has made row estimates for predicates that
    are not used by the chosen access method, the estimate from the
    range optimizer is used as filtering effect for those fields. We
    do this because the range optimizer is more accurate than index
    statistics.
  */
  if (!table->quick_keys.is_clear_all()) {
    char buf[MAX_FIELDS / 8];
    my_bitmap_map *bitbuf =
        static_cast<my_bitmap_map *>(static_cast<void *>(&buf));
    MY_BITMAP fields_current_quick;

    for (uint keyno = 0; keyno < table->s->keys; keyno++) {
      if (table->quick_keys.is_set(keyno)) {
        // The range optimizer made a row estimate for this index

        bitmap_init(&fields_current_quick, bitbuf, table->s->fields);

        const KEY *key = table->key_info + keyno;
        for (uint i = 0; i < table->quick_key_parts[keyno]; i++)
          bitmap_set_bit(&fields_current_quick,
                         key->key_part[i].field->field_index());

        /*
          If any of the fields used to get the rows estimate for this
          index were used to get a rows estimate for another index
          already contributing to 'filter', or by the access method we
          ignore it.
        */
        if (bitmap_is_overlapping(&table->tmp_set, &fields_current_quick))
          continue;

        bitmap_union(&table->tmp_set, &fields_current_quick);

        const float selectivity = static_cast<float>(table->quick_rows[keyno]) /
                                  static_cast<float>(tab->records());
        // Cannot possible access more rows than there are in the table
        filter *= std::min(selectivity, 1.0f);
      }
    }
  }

  /*
    Filtering effect for predicates that can be gathered from the
    range optimizer is now reflected in 'filter', and the fields of
    those predicates are set in 'tmp_set' to avoid that a
    single predicate contributes twice to 'filter'.

    Only calculate the filtering effect if
    1) There are query conditions, and
    2) At least one of the query conditions affect a field that is not
       going to be ignored in 'tab'. In other words, there has to
       exist a condition on a field that is not used by the ref/range
       access method.
  */
  if (tab->join()->where_cond &&                             // 1)
      !bitmap_is_subset(&table->cond_set, &table->tmp_set))  // 2)
  {
    /*
      Get filtering effect for predicates that are not already
      reflected in 'filter'. The below call gets this filtering effect
      based on index statistics and guesstimates.
    */
    filter *= tab->join()->where_cond->get_filtering_effect(
        tab->join()->thd, tab->table_ref->map(), used_tables, &table->tmp_set,
        static_cast<double>(tab->records()));
  }

  /*
    Cost calculations and picking the right join order assumes that a
    positive number of output rows from each joined table. We assume
    that at least one row in the table match the condition.  Not all
    code is able to cope with estimates of less than one row.  (For
    example, DupsWeedout may include extra tables in its
    duplicate-eliminating range in such cases.)
  */
  filter = max(filter, 1.0f / tab->records());

  /*
    For large tables, the restriction above may still give very small
    numbers when calculating fan-out.  The code below makes sure that
    there is a lower limit on fan-out.
    TODO: Should evaluate whether this restriction makes sense.  It
          can cause the estimated size of the result set to be
          different for different join orders. However, some unwanted
          effects on DBT-3 was observed when removing it, so keeping
          it for now.
  */
  if ((filter * fanout) < 0.05F) filter = 0.05F / static_cast<float>(fanout);

cleanup:
  filtering_effect_trace.end();
  parent_trace.add("final_filtering_effect", filter);

  // Clear tmp_set so it can be used elsewhere
  bitmap_clear_all(&table->tmp_set);
  assert(filter >= 0.0F && filter <= 1.0F);
  return filter;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_prepare.cc
Function: Prepared_statement::execute_loop
    backtracking all the way to Prepared_statement::execute_loop().

    As the DA has not yet been reset at this point, we'll need to
    reset the previous statement's result status first.
    Test with rpl_sp_effects and friends.
  */
  thd->get_stmt_da()->reset_diagnostics_area();
  thd->get_stmt_da()->set_error_status(thd, ER_NEED_REPREPARE);
  m_invalidated = true;
  m_attempt++;

  return true;
}

/**
  Requests for repreparation of statement.
  @returns true if request has been placed.
*/
bool ask_to_reprepare(THD *thd) {


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_prepare.cc
Function: disable_general_log
static bool disable_general_log(THD *thd) {
  if ((thd->variables.option_bits & OPTION_LOG_OFF) != 0) return false;
  thd->variables.option_bits |= OPTION_LOG_OFF;
  return true;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_profile.cc
Function: PROFILING::start_new_query
void PROFILING::start_new_query(const char *initial_state) {
  DBUG_TRACE;

  /* This should never happen unless the server is radically altered. */
  if (unlikely(current != nullptr)) {
    DBUG_PRINT("warning", ("profiling code was asked to start a new query "
                           "before the old query was finished.  This is "
                           "probably a bug."));
    finish_current_query();
  }

  enabled = ((thd->variables.option_bits & OPTION_PROFILING) != 0);

  if (!enabled) return;

  assert(current == nullptr);
  current = new QUERY_PROFILE(this, initial_state);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_profile.cc
Function: PROFILING::set_query_source
void QUERY_PROFILE::set_query_source(const char *query_source_arg,
                                     size_t query_length_arg) {
  /* Truncate to avoid DoS attacks. */
  size_t length = min(MAX_QUERY_LENGTH, query_length_arg);

  assert(m_query_source.str == nullptr); /* we don't leak memory */
  if (query_source_arg != nullptr) {
    m_query_source.str =
        my_strndup(key_memory_PROFILE, query_source_arg, length, MYF(0));
    m_query_source.length = length;
  }
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_profile.cc
Function: PROFILING::finish_current_query
void PROFILING::finish_current_query() {
  DBUG_TRACE;
  if (current != nullptr) {
    /* The last fence-post, so we can support the span before this. */
    status_change("ending", nullptr, nullptr, 0);

    if ((enabled) && /* ON at start? */
        ((thd->variables.option_bits & OPTION_PROFILING) !=
         0) && /* and ON at end? */
        (current->m_query_source.str != nullptr) &&
        (!current->entries.is_empty())) {
      current->profiling_query_id = next_profile_id(); /* assign an id */

      history.push_back(current);
      last = current; /* never contains something that is not in the history. */
      current = nullptr;
    } else {
      delete current;
      current = nullptr;
    }
  }

  /* Maintain the history size. */
  while (history.elements > thd->variables.profiling_history_size)
    delete history.pop();
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_reload.cc
Function: flush_tables_with_read_lock
bool flush_tables_with_read_lock(THD *thd, Table_ref *all_tables) {
  Lock_tables_prelocking_strategy lock_tables_prelocking_strategy;
  Table_ref *table_list;

  /*
    This is called from SQLCOM_FLUSH, the transaction has
    been committed implicitly.
  */

  if (thd->locked_tables_mode) {
    my_error(ER_LOCK_OR_ACTIVE_TRANSACTION, MYF(0));
    goto error;
  }

  /*
    Acquire SNW locks on tables to be flushed. Don't acquire global
    IX and database-scope IX locks on the tables as this will make
    this statement incompatible with FLUSH TABLES WITH READ LOCK.
  */
  if (lock_table_names(thd, all_tables, nullptr,
                       thd->variables.lock_wait_timeout,
                       MYSQL_OPEN_SKIP_SCOPED_MDL_LOCK))
    goto error;

  DEBUG_SYNC(thd, "flush_tables_with_read_lock_after_acquire_locks");

  for (table_list = all_tables; table_list;
       table_list = table_list->next_global) {
    /* Request removal of table from cache. */
    tdc_remove_table(thd, TDC_RT_REMOVE_UNUSED, table_list->db,
                     table_list->table_name, false);
    /* Reset ticket to satisfy asserts in open_tables(). */
    table_list->mdl_request.ticket = nullptr;
  }

  /*
    Before opening and locking tables the below call also waits
    for old shares to go away, so the fact that we don't pass
    MYSQL_OPEN_IGNORE_FLUSH flag to it is important.
    Also we don't pass MYSQL_OPEN_HAS_MDL_LOCK flag as we want
    to open underlying tables if merge table is flushed.
    For underlying tables of the merge the below call has to
    acquire SNW locks to ensure that they can be locked for
    read without further waiting.
  */
  if (open_and_lock_tables(thd, all_tables, MYSQL_OPEN_SKIP_SCOPED_MDL_LOCK,
                           &lock_tables_prelocking_strategy) ||
      thd->locked_tables_list.init_locked_tables(thd)) {
    goto error;
  }
  thd->variables.option_bits |= OPTION_TABLE_LOCK;

  /*
    We don't downgrade MDL_SHARED_NO_WRITE here as the intended
    post effect of this call is identical to LOCK TABLES <...> READ,
    and we didn't use thd->in_lock_talbes and
    thd->sql_command= SQLCOM_LOCK_TABLES hacks to enter the LTM.
  */

  return false;

error:
  return true;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_reload.cc
Function: flush_tables_for_export
bool flush_tables_for_export(THD *thd, Table_ref *all_tables) {
  Lock_tables_prelocking_strategy lock_tables_prelocking_strategy;

  /*
    This is called from SQLCOM_FLUSH, the transaction has
    been committed implicitly.
  */

  if (thd->locked_tables_mode) {
    my_error(ER_LOCK_OR_ACTIVE_TRANSACTION, MYF(0));
    return true;
  }

  /*
    Acquire SNW locks on tables to be exported. Don't acquire
    global IX as this will make this statement incompatible
    with FLUSH TABLES WITH READ LOCK.
    We can't acquire SRO locks instead of SNW locks as it will
    make two concurrent FLUSH TABLE ... FOR EXPORT statements
    for the same table possible, which creates race between
    creation/deletion of metadata file.
  */
  if (open_and_lock_tables(thd, all_tables, MYSQL_OPEN_SKIP_SCOPED_MDL_LOCK,
                           &lock_tables_prelocking_strategy)) {
    return true;
  }

  // Check if all storage engines support FOR EXPORT.
  for (Table_ref *table_list = all_tables; table_list;
       table_list = table_list->next_global) {
    if (!(table_list->table->file->ha_table_flags() & HA_CAN_EXPORT)) {
      my_error(ER_ILLEGAL_HA, MYF(0), table_list->table_name);
      return true;
    }
  }

  // Notify the storage engines that the tables should be made ready for export.
  for (Table_ref *table_list = all_tables; table_list;
       table_list = table_list->next_global) {
    handler *handler_file = table_list->table->file;
    int error = handler_file->ha_extra(HA_EXTRA_EXPORT);
    if (error) {
      handler_file->print_error(error, MYF(0));
      return true;
    }
  }

  // Enter LOCKED TABLES mode.
  if (thd->locked_tables_list.init_locked_tables(thd)) return true;
  thd->variables.option_bits |= OPTION_TABLE_LOCK;

  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_select.cc
Function: JOIN::setup_semijoin_materialized_table
bool JOIN::setup_semijoin_materialized_table(JOIN_TAB *tab, uint tableno,
                                             POSITION *inner_pos,
                                             POSITION *sjm_pos) {
  DBUG_TRACE;
  Table_ref *const emb_sj_nest = inner_pos->table->emb_sj_nest;
  Semijoin_mat_optimize *const sjm_opt = &emb_sj_nest->nested_join->sjm;
  Semijoin_mat_exec *const sjm_exec = tab->sj_mat_exec();
  const uint field_count = emb_sj_nest->nested_join->sj_inner_exprs.size();

  assert(field_count > 0);
  assert(inner_pos->sj_strategy == SJ_OPT_MATERIALIZE_LOOKUP ||
         inner_pos->sj_strategy == SJ_OPT_MATERIALIZE_SCAN);

  /*
    Set up the table to write to, do as
    Query_result_union::create_result_table does
  */
  sjm_exec->table_param = Temp_table_param();
  count_field_types(query_block, &sjm_exec->table_param,
                    emb_sj_nest->nested_join->sj_inner_exprs, false, true);
  sjm_exec->table_param.bit_fields_as_long = true;

  char buffer[NAME_LEN];
  const size_t len = snprintf(buffer, sizeof(buffer) - 1, "<subquery%u>",
                              emb_sj_nest->nested_join->query_block_id);
  char *name = (char *)thd->mem_root->Alloc(len + 1);
  if (name == nullptr) return true; /* purecov: inspected */

  memcpy(name, buffer, len);
  name[len] = '\0';
  TABLE *table;
  if (!(table =
            create_tmp_table(thd, &sjm_exec->table_param,
                             emb_sj_nest->nested_join->sj_inner_exprs, nullptr,
                             true /* distinct */, true /* save_sum_fields */,
                             thd->variables.option_bits | TMP_TABLE_ALL_COLUMNS,
                             HA_POS_ERROR /* rows_limit */, name)))
    return true; /* purecov: inspected */
  sjm_exec->table = table;
  map2table[tableno] = tab;
  table->file->ha_extra(HA_EXTRA_IGNORE_DUP_KEY);
  sj_tmp_tables.push_back(table);
  sjm_exec_list.push_back(sjm_exec);

  /*
    Hash_field is not applicable for MATERIALIZE_LOOKUP. If hash_field is
    created for temporary table, semijoin_types_allow_materialization must
    assure that MATERIALIZE_LOOKUP can't be chosen.
  */
  assert((inner_pos->sj_strategy == SJ_OPT_MATERIALIZE_LOOKUP &&
          !table->hash_field) ||
         inner_pos->sj_strategy == SJ_OPT_MATERIALIZE_SCAN);

  auto tl = new (thd->mem_root) Table_ref("", name, TL_IGNORE);
  if (tl == nullptr) return true; /* purecov: inspected */
  tl->table = table;

  /*
    If the SJ nest is inside an outer join nest, this tmp table belongs to
    it. It's important for attachment of the semi-join ON condition with the
    proper guards, to this table. If it's an AJ nest it's an outer join
    nest too.
  */
  if (emb_sj_nest->is_aj_nest())
    tl->embedding = emb_sj_nest;
  else
    tl->embedding = emb_sj_nest->outer_join_nest();
  /*
    Above, we do not set tl->emb_sj_nest, neither first_sj_inner nor
    last_sj_inner; it's because there's no use to say that this table is part
    of the SJ nest; but it's necessary to say that it's part of any outer join
    nest. The antijoin nest is an outer join nest, but from the POV of the
    sj-tmp table it's only an outer join nest, so there is no need to set
    emb_sj_nest even in this case.
  */

  // Table is "nullable" if inner table of an outer_join
  if (tl->is_inner_table_of_outer_join()) table->set_nullable();

  tl->set_tableno(tableno);

  table->pos_in_table_list = tl;
  table->pos_in_table_list->query_block = query_block;

  if (!(sjm_opt->mat_fields = (Item_field **)thd->mem_root->Alloc(
            field_count * sizeof(Item_field **))))
    return true;

  for (uint fieldno = 0; fieldno < field_count; fieldno++) {
    if (!(sjm_opt->mat_fields[fieldno] =
              new Item_field(table->visible_field_ptr()[fieldno])))
      return true;
  }

  tab->table_ref = tl;
  tab->set_table(table);
  tab->set_position(sjm_pos);

  tab->worst_seeks = 1.0;
  tab->set_records((ha_rows)emb_sj_nest->nested_join->sjm.expected_rowcount);

  tab->found_records = tab->records();
  tab->read_time = emb_sj_nest->nested_join->sjm.scan_cost.total_cost();

  tab->init_join_cond_ref(tl);

  table->keys_in_use_for_query.set_all();
  sjm_pos->table = tab;
  sjm_pos->sj_strategy = SJ_OPT_NONE;

  sjm_pos->use_join_buffer = false;
  /*
    No need to recalculate filter_effect since there are no post-read
    conditions for materialized tables.
  */
  sjm_pos->filter_effect = 1.0;

  /*
    Key_use objects are required so that create_ref_for_key() can set up
    a proper ref access for this table.
  */
  Key_use_array *keyuse =
      create_keyuse_for_table(thd, field_count, sjm_opt->mat_fields,
                              emb_sj_nest->nested_join->sj_outer_exprs);
  if (!keyuse) return true;

  double fanout = ((uint)tab->idx() == const_tables)
                      ? 1.0
                      : best_ref[tab->idx() - 1]->position()->prefix_rowcount;
  if (!sjm_exec->is_scan) {
    sjm_pos->key = keyuse->begin();  // MaterializeLookup will use the index
    sjm_pos->read_cost =
        emb_sj_nest->nested_join->sjm.lookup_cost.total_cost() * fanout;
    tab->set_keyuse(keyuse->begin());
    tab->keys().set_bit(0);  // There is one index - use it always
    tab->set_index(0);
    sjm_pos->rows_fetched = 1.0;
    tab->set_type(JT_REF);
  } else {
    sjm_pos->key = nullptr;  // No index use for MaterializeScan
    sjm_pos->read_cost = tab->read_time * fanout;
    sjm_pos->rows_fetched = static_cast<double>(tab->records());
    tab->set_type(JT_ALL);
  }
  sjm_pos->set_prefix_join_cost((tab - join_tab), cost_model());

  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_select.cc
Function: make_join_readinfo
bool make_join_readinfo(JOIN *join, uint no_jbuf_after) {
  const bool statistics = !join->thd->lex->is_explain();
  const bool prep_for_pos = join->need_tmp_before_win ||
                            join->select_distinct ||
                            !join->group_list.empty() || !join->order.empty() ||
                            join->m_windows.elements > 0;

  DBUG_TRACE;
  ASSERT_BEST_REF_IN_JOIN_ORDER(join);

  Opt_trace_context *const trace = &join->thd->opt_trace;
  Opt_trace_object wrapper(trace);
  Opt_trace_array trace_refine_plan(trace, "refine_plan");

  if (setup_semijoin_dups_elimination(join, no_jbuf_after))
    return true; /* purecov: inspected */

  for (uint i = join->const_tables; i < join->tables; i++) {
    QEP_TAB *const qep_tab = &join->qep_tab[i];
    if (!qep_tab->position()) continue;

    JOIN_TAB *const tab = join->best_ref[i];
    TABLE *const table = qep_tab->table();
    Table_ref *const table_ref = qep_tab->table_ref;
    /*
     Need to tell handlers that to play it safe, it should fetch all
     columns of the primary key of the tables: this is because MySQL may
     build row pointers for the rows, and for all columns of the primary key
     the read set has not necessarily been set by the server code.
    */
    if (prep_for_pos) table->prepare_for_position();

    Opt_trace_object trace_refine_table(trace);
    trace_refine_table.add_utf8_table(table_ref);

    if (tab->use_join_cache() != JOIN_CACHE::ALG_NONE)
      qep_tab->init_join_cache(tab);

    switch (qep_tab->type()) {
      case JT_EQ_REF:
      case JT_REF_OR_NULL:
      case JT_REF:
      case JT_SYSTEM:
      case JT_CONST:
        if (table->covering_keys.is_set(qep_tab->ref().key) &&
            !table->no_keyread)
          table->set_keyread(true);
        else
          qep_tab->push_index_cond(tab, qep_tab->ref().key,
                                   &trace_refine_table);
        break;
      case JT_ALL:
        join->thd->set_status_no_index_used();
        qep_tab->using_dynamic_range = (tab->use_quick == QS_DYNAMIC_RANGE);
        [[fallthrough]];
      case JT_INDEX_SCAN:
        if (tab->position()->filter_effect != COND_FILTER_STALE_NO_CONST &&
            !tab->sj_mat_exec()) {
          /*
            rows_w_const_cond is # of rows which will be read by the access
            method, minus those which will not pass the constant condition;
            that's how calculate_scan_cost() works. Such number is useful inside
            the planner, but obscure to the reader of EXPLAIN; so we put the
            real count of read rows into rows_fetched, and move the constant
            condition's filter to filter_effect.
          */
          double rows_w_const_cond = qep_tab->position()->rows_fetched;
          table_ref->fetch_number_of_rows();
          tab->position()->rows_fetched =
              static_cast<double>(table->file->stats.records);
          if (tab->position()->filter_effect != COND_FILTER_STALE) {
            // Constant condition moves to filter_effect:
            if (tab->position()->rows_fetched == 0)  // avoid division by zero
              tab->position()->filter_effect = 0.0f;
            else
              tab->position()->filter_effect *= static_cast<float>(
                  rows_w_const_cond / tab->position()->rows_fetched);
          }
        }
        if (qep_tab->using_dynamic_range) {
          join->thd->set_status_no_good_index_used();
          if (statistics) join->thd->inc_status_select_range_check();
        } else {
          if (statistics) {
            if (i == join->const_tables)
              join->thd->inc_status_select_scan();
            else
              join->thd->inc_status_select_full_join();
          }
        }
        break;
      case JT_RANGE:
      case JT_INDEX_MERGE:
        qep_tab->using_dynamic_range = (tab->use_quick == QS_DYNAMIC_RANGE);
        if (statistics) {
          if (i == join->const_tables)
            join->thd->inc_status_select_range();
          else
            join->thd->inc_status_select_full_range_join();
        }
        if (!table->no_keyread && qep_tab->type() == JT_RANGE) {
          if (table->covering_keys.is_set(used_index(qep_tab->range_scan()))) {
            assert(used_index(qep_tab->range_scan()) != MAX_KEY);
            table->set_keyread(true);
          }
          if (!table->key_read)
            qep_tab->push_index_cond(tab, used_index(qep_tab->range_scan()),
                                     &trace_refine_table);
        }
        if (tab->position()->filter_effect != COND_FILTER_STALE_NO_CONST) {
          double rows_w_const_cond = qep_tab->position()->rows_fetched;
          qep_tab->position()->rows_fetched =
              tab->range_scan()->num_output_rows();
          if (tab->position()->filter_effect != COND_FILTER_STALE) {
            // Constant condition moves to filter_effect:
            if (tab->position()->rows_fetched == 0)  // avoid division by zero
              tab->position()->filter_effect = 0.0f;
            else
              tab->position()->filter_effect *= static_cast<float>(
                  rows_w_const_cond / tab->position()->rows_fetched);
          }
        }
        break;
      case JT_FT:
        if (tab->join()->fts_index_access(tab)) {
          table->set_keyread(true);
          table->covering_keys.set_bit(tab->ft_func()->key);
        }
        break;
      default:
        DBUG_PRINT("error", ("Table type %d found",
                             qep_tab->type())); /* purecov: deadcode */
        assert(0);
        break; /* purecov: deadcode */
    }

    if (tab->position()->filter_effect <= COND_FILTER_STALE) {
      /*
        Give a proper value for EXPLAIN.
        For performance reasons, we do not recalculate the filter for
        non-EXPLAIN queries; thus, EXPLAIN CONNECTION may show 100%
        for a query.

        Also calculate the proper value if max_join_size is in effect and there
        is a limit, since it's needed in order to calculate how many rows to
        read from the base table if rows are filtered before the limit is
        applied.
      */
      tab->position()->filter_effect =
          (join->thd->lex->is_explain() ||
           (join->m_select_limit != HA_POS_ERROR &&
            !Overlaps(join->thd->variables.option_bits, OPTION_BIG_SELECTS)))
              ? calculate_condition_filter(
                    tab,
                    (tab->ref().key != -1) ? tab->position()->key : nullptr,
                    tab->prefix_tables() & ~table_ref->map(),
                    tab->position()->rows_fetched, false, false,
                    trace_refine_table)
              : COND_FILTER_ALLPASS;
    }

    assert(!table_ref->is_recursive_reference() || qep_tab->type() == JT_ALL);

    qep_tab->set_reversed_access(tab->reversed_access);

    // Materialize derived tables prior to accessing them.
    if (table_ref->is_table_function()) {
      qep_tab->materialize_table = QEP_TAB::MATERIALIZE_TABLE_FUNCTION;
      if (tab->dependent) qep_tab->rematerialize = true;
    } else if (table_ref->uses_materialization()) {
      qep_tab->materialize_table = QEP_TAB::MATERIALIZE_DERIVED;
    }

    if (qep_tab->sj_mat_exec())
      qep_tab->materialize_table = QEP_TAB::MATERIALIZE_SEMIJOIN;

    if (table_ref->is_derived() &&
        table_ref->derived_query_expression()->m_lateral_deps) {
      auto deps = table_ref->derived_query_expression()->m_lateral_deps;
      plan_idx last = NO_PLAN_IDX;
      for (JOIN_TAB **tab2 = join->map2table; deps; tab2++, deps >>= 1) {
        if (deps & 1) last = std::max(last, (*tab2)->idx());
      }
      /*
        We identified the last dependency of table_ref in the plan, and it's
        the table whose reading must trigger rematerialization of table_ref.
      */
      if (last != NO_PLAN_IDX) {
        QEP_TAB &t = join->qep_tab[last];
        t.lateral_derived_tables_depend_on_me |= TableBitmap(i);
        trace_refine_table.add_utf8("rematerialized_for_each_row_of",
                                    t.table()->alias);
      }
    }
  }

  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_show.cc
Function: get_quote_char_for_identifier
    get_quote_char_for_identifier()
    thd		Thread handler
    name	name to quote
    length	length of name

  IMPLEMENTATION
    Force quoting in the following cases:
      - name is empty (for one, it is possible when we use this function for
        quoting user and host names for DEFINER clause);
      - name is a keyword;
      - name includes a special character;
    Otherwise identifier is quoted only if the option OPTION_QUOTE_SHOW_CREATE
    is set.

  RETURN
    EOF	  No quote character is needed
    #	  Quote character
*/

int get_quote_char_for_identifier(const THD *thd, const char *name,
                                  size_t length) {
  if (length && !is_keyword(name, length) && !require_quotes(name, length) &&
      !(thd->variables.option_bits & OPTION_QUOTE_SHOW_CREATE))
    return EOF;
  if (thd->variables.sql_mode & MODE_ANSI_QUOTES) return '"';
  return '`';
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: rm_table_check_fks
static bool rm_table_check_fks(THD *thd, Drop_tables_ctx *drop_ctx) {
  /*
    In FOREIGN_KEY_CHECKS=0 mode it is allowed to drop parent without
    dropping child at the same time, so we return early.
    In FOREIGN_KEY_CHECKS=1 mode we need to check if we are about to
    drop parent table without dropping child table.
  */
  if (thd->variables.option_bits & OPTION_NO_FOREIGN_KEY_CHECKS) return false;

  // Earlier we assert that only SEs supporting atomic DDL support FKs.
  for (Table_ref *table : drop_ctx->base_atomic_tables) {
    dd::cache::Dictionary_client::Auto_releaser releaser(thd->dd_client());
    const dd::Table *table_def = nullptr;
    if (thd->dd_client()->acquire(table->db, table->table_name, &table_def))
      return true;
    assert(table_def != nullptr);

    if (table_def && table_def->hidden() == dd::Abstract_table::HT_HIDDEN_SE) {
      my_error(ER_NO_SUCH_TABLE, MYF(0), table->db, table->table_name);
      assert(true);
      return true;
    }

    for (const dd::Foreign_key_parent *fk : table_def->foreign_key_parents()) {
      if (drop_ctx->drop_database) {
        /*
          In case of DROP DATABASE list of tables to be dropped can be huge.
          We avoid scanning it by assuming that DROP DATABASE will drop all
          tables in the database and no tables from other databases.
        */
        if (my_strcasecmp(table_alias_charset, fk->child_schema_name().c_str(),
                          table->db) != 0) {
          my_error(ER_FK_CANNOT_DROP_PARENT, MYF(0), table->table_name,
                   fk->fk_name().c_str(), fk->child_table_name().c_str());
          return true;
        }
      } else {
        if (my_strcasecmp(table_alias_charset, fk->child_schema_name().c_str(),
                          table->db) == 0 &&
            my_strcasecmp(table_alias_charset, fk->child_table_name().c_str(),
                          table->table_name) == 0)
          continue;

        bool child_dropped = false;

        for (Table_ref *dropped : drop_ctx->base_atomic_tables) {
          if (my_strcasecmp(table_alias_charset,
                            fk->child_schema_name().c_str(),
                            dropped->db) == 0 &&
              my_strcasecmp(table_alias_charset, fk->child_table_name().c_str(),
                            dropped->table_name) == 0) {
            child_dropped = true;
            break;
          }
        }

        if (!child_dropped) {
          my_error(ER_FK_CANNOT_DROP_PARENT, MYF(0), table->table_name,
                   fk->fk_name().c_str(), fk->child_table_name().c_str());
          return true;
        }
      }
    }
  }

  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: prepare_preexisting_foreign_key not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: prepare_preexisting_foreign_key not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: prepare_preexisting_foreign_key not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: prepare_preexisting_foreign_key not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: prepare_preexisting_foreign_key not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: prepare_foreign_key not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: prepare_foreign_key not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: prepare_foreign_key not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: prepare_foreign_key not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: prepare_preexisting_self_ref_foreign_key
            See comment in prepare_preexisting_self_ref_foreign_key() about
            allowing charset discrepancies between child and parent columns in
            FOREIGN_KEY_CHECKS=0 mode.
          */
          if (!create_info->db_type->check_fk_column_compat(
                  &child_column_type, &parent_column_type,
                  !(thd->variables.option_bits &
                    OPTION_NO_FOREIGN_KEY_CHECKS))) {
            my_error(ER_FK_INCOMPATIBLE_COLUMNS, MYF(0), fk->key_part[j].str,
                     ref_column_name, fk->name);
            return true;
          }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: mysql_rename_table
bool mysql_rename_table(THD *thd, handlerton *base, const char *old_db,
                        const char *old_name, const char *old_fk_db,
                        const char *old_fk_name, const dd::Schema &new_schema,
                        const char *new_db, const char *new_name, uint flags) {
  DBUG_TRACE;
  DBUG_PRINT("enter", ("old: '%s'.'%s'  new: '%s'.'%s'", old_db, old_name,
                       new_db, new_name));

  /*
    Only SEs which support atomic DDL are allowed not to commit
    changes to the data-dictionary.
  */
  assert(!(flags & NO_DD_COMMIT) || (base->flags & HTON_SUPPORTS_ATOMIC_DDL));
  /*
    Check if the new_db database exists. The problem is that some
    SE's may not verify if new_db database exists and they might
    succeed renaming the table. Moreover, even the InnoDB engine
    succeeds renaming the table without verifying if the new_db
    database exists when innodb_file_per_table=0.
  */

  // Check if we hit FN_REFLEN bytes along with file extension.
  char from[FN_REFLEN + 1];
  char to[FN_REFLEN + 1];
  size_t length;
  bool was_truncated;
  build_table_filename(from, sizeof(from) - 1, old_db, old_name, "",
                       flags & FN_FROM_IS_TMP);
  length = build_table_filename(to, sizeof(to) - 1, new_db, new_name, "",
                                flags & FN_TO_IS_TMP, &was_truncated);
  if (was_truncated || length + reg_ext_length > FN_REFLEN) {
    my_error(ER_IDENT_CAUSES_TOO_LONG_PATH, MYF(0), sizeof(to) - 1, to);
    return true;
  }

  dd::cache::Dictionary_client::Auto_releaser releaser(thd->dd_client());
  const dd::Table *from_table_def = nullptr;
  dd::Table *to_table_def = nullptr;

  if (thd->dd_client()->acquire(old_db, old_name, &from_table_def) ||
      thd->dd_client()->acquire_for_modification(old_db, old_name,
                                                 &to_table_def))
    return true;

  Table_ddl_hton_notification_guard notification_guard{
      thd,
      &(thd->lex->query_block->get_table_list()->mdl_request.key),
      ha_ddl_type::HA_RENAME_DDL,
      old_db,
      old_name,
      new_db,
      new_name};

  if (notification_guard.notify()) return true;

  // Tables with a defined secondary engine cannot be renamed, except if:
  //   (a) The renaming is only temporary, which may happen if e.g.,
  //   ALGORITHM=COPY is used, OR
  //   (b) The secondary storage engine supports DDL.
  if (from_table_def->options().exists("secondary_engine") &&
      !(flags & FN_IS_TMP)) {
    LEX_CSTRING secondary_engine;
    from_table_def->options().get("secondary_engine", &secondary_engine,
                                  thd->mem_root);

    if (!ha_secondary_engine_supports_ddl(thd, secondary_engine)) {
      my_error(ER_SECONDARY_ENGINE_DDL, MYF(0));
      return true;
    }
  }

  // Set schema id, table name and hidden attribute.
  to_table_def->set_schema_id(new_schema.id());
  to_table_def->set_name(new_name);
  to_table_def->set_hidden((flags & FN_TO_IS_TMP)
                               ? dd::Abstract_table::HT_HIDDEN_DDL
                               : dd::Abstract_table::HT_VISIBLE);

  /* Adjust parent table for self-referencing foreign keys. */
  for (dd::Foreign_key *fk : *(to_table_def->foreign_keys())) {
    if (my_strcasecmp(table_alias_charset,
                      fk->referenced_table_schema_name().c_str(),
                      old_fk_db) == 0 &&
        my_strcasecmp(table_alias_charset, fk->referenced_table_name().c_str(),
                      old_fk_name) == 0) {
      fk->set_referenced_table_schema_name(new_db);
      fk->set_referenced_table_name(new_name);
    }
  }

  /*
    Unless suppressed update generated foreign key names
    (as they have table_name<SE-specific or default suffix>#### format).
  */
  if (!(flags & NO_FK_RENAME) &&
      dd::rename_foreign_keys(thd, old_db, old_fk_name, base, new_db,
                              to_table_def))
    return true;

  if (!(flags & NO_CC_RENAME) &&
      dd::rename_check_constraints(old_name, to_table_def))
    return true;

  // Get the handler for the table, and issue an error if we cannot load it.
  handler *file =
      (base == nullptr ? nullptr
                       : get_new_handler((TABLE_SHARE *)nullptr,
                                         from_table_def->partition_type() !=
                                             dd::Table::PT_NONE,
                                         thd->mem_root, base));
  if (!file) {
    my_error(ER_STORAGE_ENGINE_NOT_LOADED, MYF(0), old_db, old_name);
    return true;
  }

  /*
    If lower_case_table_names == 2 (case-preserving but case-insensitive
    file system) and the storage is not HA_FILE_BASED, we need to provide
    a lowercase file name.
  */
  char lc_from[FN_REFLEN + 1];
  char lc_to[FN_REFLEN + 1];
  char *from_base = from;
  char *to_base = to;
  if (lower_case_table_names == 2 &&
      !(file->ha_table_flags() & HA_FILE_BASED)) {
    char tmp_name[NAME_LEN + 1];
    my_stpcpy(tmp_name, old_name);
    my_casedn_str(files_charset_info, tmp_name);
    build_table_filename(lc_from, sizeof(lc_from) - 1, old_db, tmp_name, "",
                         flags & FN_FROM_IS_TMP);
    from_base = lc_from;

    my_stpcpy(tmp_name, new_name);
    my_casedn_str(files_charset_info, tmp_name);
    build_table_filename(lc_to, sizeof(lc_to) - 1, new_db, tmp_name, "",
                         flags & FN_TO_IS_TMP);
    to_base = lc_to;
  }

  /*
    Temporarily disable foreign key checks, if requested, while the
    handler is involved.
  */
  ulonglong save_bits = thd->variables.option_bits;
  if (flags & NO_FK_CHECKS)
    thd->variables.option_bits |= OPTION_NO_FOREIGN_KEY_CHECKS;

  Rename_table_error_handler error_handler;
  thd->push_internal_handler(&error_handler);
  int error =
      file->ha_rename_table(from_base, to_base, from_table_def, to_table_def);
  thd->pop_internal_handler();

  thd->variables.option_bits = save_bits;

  if (error != 0) {
    if (error == HA_ERR_WRONG_COMMAND)
      my_error(ER_NOT_SUPPORTED_YET, MYF(0), "ALTER TABLE");
    else {
      char errbuf[MYSYS_STRERROR_SIZE];
      my_error(ER_ERROR_ON_RENAME, MYF(0), from, to, error,
               my_strerror(errbuf, sizeof(errbuf), error));
    }
    destroy(file);
    return true;
  }

  /*
    Note that before WL#7743 we have renamed table in the data-dictionary
    before renaming it in storage engine. However with WL#7743 engines
    supporting atomic DDL are allowed to update dd::Table object describing
    new version of table in handler::rename_table(). Hence it should saved
    after this call.
    So to avoid extra calls to DD layer and to keep code simple the
    renaming of table in the DD was moved past rename in SE for all SEs.
    From crash-safety point of view order doesn't matter for engines
    supporting atomic DDL. And for engines which can't do atomic DDL in
    either case there are scenarios in which DD and SE get out of sync.
  */
  bool result = thd->dd_client()->update(to_table_def);

  /*
    Only rename histograms when this isn't a rename for temporary names
    (we will never have a histogram for a temporary name).

    Note that this won't catch "ALTER TABLE ... ALGORITHM=COPY" since the COPY
    algorithm will first rename to a temporary name, and then to the final name.
    That case is handled in the function mysql_alter_table.
  */
  if (!result && !((flags & FN_TO_IS_TMP) || (flags & FN_FROM_IS_TMP))) {
    result = rename_histograms(thd, old_db, old_name, new_db, new_name);
  }

  if (!(flags & NO_DD_COMMIT))
    result = trans_intermediate_ddl_commit(thd, result);

  if (result) {
    /*
      In cases when we are executing atomic DDL it is responsibility of the
      caller to revert the changes to SE by rolling back transaction.

      If storage engine supports atomic DDL but commit was requested by the
      caller the above call to trans_intermediate_ddl_commit() will roll
      back the transaction on failure and thus revert change to SE.
    */
    if (!(flags & NO_DD_COMMIT))
      (void)file->ha_rename_table(to_base, from_base, to_table_def,
                                  const_cast<dd::Table *>(from_table_def));
    destroy(file);
    return true;
  }
  destroy(file);

#ifdef HAVE_PSI_TABLE_INTERFACE
  /*
    Remove the old table share from the pfs table share array. The new table
    share will be created when the renamed table is first accessed.
  */
  bool temp_table = (bool)is_prefix(old_name, tmp_file_prefix);
  PSI_TABLE_CALL(drop_table_share)
  (temp_table, old_db, static_cast<int>(strlen(old_db)), old_name,
   static_cast<int>(strlen(old_name)));
#endif

  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: fk_column_change_type not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: fk_column_change_type not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: fk_column_change_type not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: fk_column_change_type not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: fk_column_change_type not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: mysql_alter_table
bool mysql_alter_table(THD *thd, const char *new_db, const char *new_name,
                       HA_CREATE_INFO *create_info, Table_ref *table_list,
                       Alter_info *alter_info) {
  DBUG_TRACE;

  /*
    Check if we attempt to alter mysql.slow_log or
    mysql.general_log table and return an error if
    it is the case.
    TODO: this design is obsolete and will be removed.
  */
  enum_log_table_type table_kind =
      query_logger.check_if_log_table(table_list, false);

  if (table_kind != QUERY_LOG_NONE) {
    /* Disable alter of enabled query log tables */
    if (query_logger.is_log_table_enabled(table_kind)) {
      my_error(ER_BAD_LOG_STATEMENT, MYF(0), "ALTER");
      return true;
    }

    /* Disable alter of log tables to unsupported engine */
    if ((create_info->used_fields & HA_CREATE_USED_ENGINE) &&
        (!create_info->db_type || /* unknown engine */
         !(create_info->db_type->flags & HTON_SUPPORT_LOG_TABLES))) {
      my_error(ER_UNSUPORTED_LOG_ENGINE, MYF(0));
      return true;
    }

    if (alter_info->flags & Alter_info::ALTER_PARTITION) {
      my_error(ER_WRONG_USAGE, MYF(0), "PARTITION", "log table");
      return true;
    }
  }

  // Reject request to ALTER TABLE with START TRANSACTION.
  if (create_info->m_transactional_ddl) {
    my_error(ER_NOT_ALLOWED_WITH_START_TRANSACTION, MYF(0),
             "with ALTER TABLE command.");
    return true;
  }

  if (alter_info->with_validation != Alter_info::ALTER_VALIDATION_DEFAULT &&
      !(alter_info->flags &
        (Alter_info::ALTER_ADD_COLUMN | Alter_info::ALTER_CHANGE_COLUMN))) {
    my_error(ER_WRONG_USAGE, MYF(0), "ALTER", "WITH VALIDATION");
    return true;
  }

  if ((alter_info->flags & Alter_info::ALTER_ADD_COLUMN) ==
      Alter_info::ALTER_ADD_COLUMN) {
    for (auto create_field : alter_info->create_list) {
      if (create_field.m_default_val_expr) {
        // ALTER TABLE .. DEFAULT (NDF function) should be rejected for mixed or
        // row binlog_format. For statement binlog_format it should be allowed
        // to continue and warning should be logged and/or pushed to the client
        if ((thd->variables.option_bits & OPTION_BIN_LOG) &&
            thd->lex->is_stmt_unsafe(
                Query_tables_list::BINLOG_STMT_UNSAFE_SYSTEM_FUNCTION)) {
          if (thd->variables.binlog_format == BINLOG_FORMAT_STMT) {
            LogErr(WARNING_LEVEL, ER_SERVER_BINLOG_UNSAFE_SYSTEM_FUNCTION,
                   "ALTER TABLE .. DEFAULT (NDF function)");
            push_warning(thd, Sql_condition::SL_WARNING,
                         ER_BINLOG_UNSAFE_SYSTEM_FUNCTION,
                         ER_THD(thd, ER_BINLOG_UNSAFE_SYSTEM_FUNCTION));
            break;
          } else {
            my_error(ER_BINLOG_UNSAFE_SYSTEM_FUNCTION, MYF(0));
            return true;
          }
        }
      }
    }
  }

  // LOCK clause doesn't make any sense for ALGORITHM=INSTANT.
  if (alter_info->requested_algorithm ==
          Alter_info::ALTER_TABLE_ALGORITHM_INSTANT &&
      alter_info->requested_lock != Alter_info::ALTER_TABLE_LOCK_DEFAULT) {
    my_error(ER_WRONG_USAGE, MYF(0), "ALGORITHM=INSTANT",
             "LOCK=NONE/SHARED/EXCLUSIVE");
    return true;
  }

  THD_STAGE_INFO(thd, stage_init);

  // Reject invalid usage of the 'mysql' tablespace.
  if (dd::invalid_tablespace_usage(thd, table_list->db, table_list->table_name,
                                   create_info))
    return true;

  /*
    Assign target tablespace name to enable locking in lock_table_names().
    Reject invalid name lengths. Names will be validated after the table is
    opened and the SE (needed for SE specific validation) is identified.
  */
  if (create_info->tablespace) {
    if (validate_tablespace_name_length(create_info->tablespace)) return true;

    if (lex_string_strmake(thd->mem_root, &table_list->target_tablespace_name,
                           create_info->tablespace,
                           strlen(create_info->tablespace))) {
      my_error(ER_OUT_OF_RESOURCES, MYF(ME_FATALERROR));
      return true;
    }
  }

  /* Validate that AUTOEXTEND_SIZE option is not specified for
  temporary tables */
  if (is_temporary_table(table_list)) {
    if (create_info->m_implicit_tablespace_autoextend_size > 0) {
      my_error(ER_CANNOT_USE_AUTOEXTEND_SIZE_CLAUSE, MYF(0), "temporary");
      return true;
    }
  }

  /*
    Reject invalid tablespace name lengths specified for partitions.
    Names will be validated after the table has been opened.
  */
  if (validate_partition_tablespace_name_lengths(thd->lex->part_info))
    return true;

  /*
    Assign the partition info, so that the locks on tablespaces
    assigned for any new partitions added would be acquired during
    open_table.
  */
  thd->work_part_info = thd->lex->part_info;

  /*
    Code below can handle only base tables so ensure that we won't open a view.
    Note that RENAME TABLE the only ALTER clause which is supported for views
    has been already processed.
  */
  table_list->required_type = dd::enum_table_type::BASE_TABLE;

  /*
    If we are about to ALTER non-temporary table we need to get permission
    from/notify interested storage engines.
  */
  Table_ddl_hton_notification_guard notification_guard{
      thd, &table_list->mdl_request.key, HA_ALTER_DDL};

  if (!is_temporary_table(table_list) && notification_guard.notify())
    return true;

  Alter_table_prelocking_strategy alter_prelocking_strategy;

  DEBUG_SYNC(thd, "alter_table_before_open_tables");
  uint tables_opened;
  bool error = open_tables(thd, &table_list, &tables_opened, 0,
                           &alter_prelocking_strategy);

  DEBUG_SYNC(thd, "alter_opened_table");

  if (error) return true;

  // If we are removing a functional index, add any related hidden generated
  // columns to the drop list as well.
  if (handle_drop_functional_index(thd, alter_info, table_list)) {
    return true;
  }

  // If we are renaming a functional index, rename any related hidden generated
  // columns as well.
  if (alter_info->flags & Alter_info::ALTER_RENAME_INDEX) {
    if (handle_rename_functional_index(thd, alter_info, table_list)) {
      return true; /* purecov: deadcode */
    }
  }

  // Check tablespace name validity for the relevant engine.
  {
    // If there is no target handlerton, use the current.
    const handlerton *target_handlerton = create_info->db_type;
    if (target_handlerton == nullptr)
      target_handlerton = table_list->table->file->ht;

    /*
      Reject invalid tablespace names for the relevant engine, if the ALTER
      statement changes either tablespace or engine. We do this after the table
      has been opened because we need the handlerton and tablespace information.
      No need to validate if neither engine nor tablespace is changed, then the
      validation was done when the table was created.
    */
    if (create_info->tablespace || create_info->db_type) {
      // If there is no target table level tablespace, use the current.
      const char *target_tablespace = create_info->tablespace;
      if (target_tablespace == nullptr)
        target_tablespace = table_list->table->s->tablespace;

      // Check the tablespace/engine combination.
      assert(target_handlerton);
      if (target_tablespace != nullptr &&
          validate_tablespace_name(TS_CMD_NOT_DEFINED, target_tablespace,
                                   target_handlerton))
        return true;
    }

    // Reject invalid tablespace names specified for partitions.
    if (validate_partition_tablespace_names(thd->lex->part_info,
                                            target_handlerton))
      return true;
  }

  if (validate_secondary_engine_option(thd, *alter_info, *create_info,
                                       *table_list->table))
    return true;

  if (lock_trigger_names(thd, table_list)) return true;

  /*
    If we're in LOCK TABLE mode, we must lock the target tablespace name
    as well as the currently used tablesapces (since these may have been
    introduced by a previous ALTER while already in LOCK TABLE mode).
  */
  if (thd->locked_tables_mode &&
      get_and_lock_tablespace_names(thd, table_list, nullptr,
                                    thd->variables.lock_wait_timeout, MYF(0))) {
    return true;
  }

  if (table_list->table->s->db_type() != create_info->db_type &&
      (alter_info->flags & Alter_info::ALTER_OPTIONS) &&
      (create_info->used_fields & HA_CREATE_USED_ENGINE)) {
    handlerton *actual_hton = get_viable_handlerton_for_alter(
        thd, *create_info, table_list->table->s->db_type());
    if (actual_hton == nullptr) return true;

    create_info->db_type = actual_hton;
  }

  const handlerton *hton = create_info->db_type;
  if (hton == nullptr) {
    hton = table_list->table->s->db_type();
  }
  assert(hton != nullptr);
  if ((alter_info->flags & Alter_info::ANY_ENGINE_ATTRIBUTE) != 0 &&
      ((hton->flags & HTON_SUPPORTS_ENGINE_ATTRIBUTE) == 0 &&
       DBUG_EVALUATE_IF("simulate_engine_attribute_support", false, true))) {
    my_error(ER_ENGINE_ATTRIBUTE_NOT_SUPPORTED, MYF(0),
             ha_resolve_storage_engine_name(hton));
    return true;
  }

  TABLE *table = table_list->table;
  table->use_all_columns();
  MDL_ticket *mdl_ticket = table->mdl_ticket;

  /*
    Prohibit changing of the UNION list of a non-temporary MERGE table
    under LOCK tables. It would be quite difficult to reuse a shrunk
    set of tables from the old table or to open a new TABLE object for
    an extended list and verify that they belong to locked tables.
  */
  if ((thd->locked_tables_mode == LTM_LOCK_TABLES ||
       thd->locked_tables_mode == LTM_PRELOCKED_UNDER_LOCK_TABLES) &&
      (create_info->used_fields & HA_CREATE_USED_UNION) &&
      (table->s->tmp_table == NO_TMP_TABLE)) {
    my_error(ER_LOCK_OR_ACTIVE_TRANSACTION, MYF(0));
    return true;
  }

  Alter_table_ctx alter_ctx(thd, table_list, tables_opened, new_db, new_name);

  /*
    Acquire and keep schema locks until commit time, so the DD layer can
    safely assert that we have proper MDL on objects stored in the DD.
  */
  dd::Schema_MDL_locker mdl_locker_1(thd), mdl_locker_2(thd);
  const dd::Schema *schema = nullptr;
  const dd::Schema *new_schema = nullptr;
  const dd::Table *old_table_def = nullptr;
  /*
    This releaser allows us to keep uncommitted DD objects cached
    in the Dictionary_client until commit time.
  */
  dd::cache::Dictionary_client::Auto_releaser releaser(thd->dd_client());
  if (mdl_locker_1.ensure_locked(alter_ctx.db) ||
      mdl_locker_2.ensure_locked(alter_ctx.new_db) ||
      thd->dd_client()->acquire(alter_ctx.db, &schema) ||
      thd->dd_client()->acquire(alter_ctx.new_db, &new_schema))
    return true;

  if ((table->s->tmp_table == NO_TMP_TABLE) &&
      thd->dd_client()->acquire(alter_ctx.db, alter_ctx.table_name,
                                &old_table_def))
    return true;

  // If this is a temporary table, the schema might not exist even
  // if we have successfully opened the table
  if (schema == nullptr) {
    assert(table->s->tmp_table);
    my_error(ER_BAD_DB_ERROR, MYF(0), alter_ctx.db);
    return true;
  }

  assert((table->s->tmp_table != NO_TMP_TABLE) || old_table_def != nullptr);

  if (new_schema == nullptr) {
    my_error(ER_BAD_DB_ERROR, MYF(0), alter_ctx.new_db);
    return true;
  }

  /*
    Add old and new (if any) databases to the list of accessed databases
    for this statement. Needed for MTS.
  */
  thd->add_to_binlog_accessed_dbs(alter_ctx.db);
  if (alter_ctx.is_database_changed())
    thd->add_to_binlog_accessed_dbs(alter_ctx.new_db);

  // Ensure that triggers are in the same schema as their subject table.
  if (alter_ctx.is_database_changed() && old_table_def != nullptr &&
      old_table_def->has_trigger()) {
    my_error(ER_TRG_IN_WRONG_SCHEMA, MYF(0));
    return true;
  }

  /* Check that we are not trying to rename to an existing table */
  if (alter_ctx.is_table_renamed()) {
    if (table->s->tmp_table != NO_TMP_TABLE) {
      if (find_temporary_table(thd, alter_ctx.new_db, alter_ctx.new_name)) {
        my_error(ER_TABLE_EXISTS_ERROR, MYF(0), alter_ctx.new_alias);
        return true;
      }
    } else {
      MDL_request_list mdl_requests;

      mdl_requests.push_front(&alter_ctx.target_mdl_request);
      /*
        If we are moving the table to a different database, we also
        need IX lock on the database name so that the target database
        is protected by MDL while the table is moved.
      */
      if (alter_ctx.is_database_changed())
        mdl_requests.push_front(&alter_ctx.target_db_mdl_request);

      /*
        Global intention exclusive lock must have been already acquired when
        table to be altered was open, so there is no need to do it here.
      */
      assert(thd->mdl_context.owns_equal_or_stronger_lock(
          MDL_key::GLOBAL, "", "", MDL_INTENTION_EXCLUSIVE));

      if (thd->mdl_context.acquire_locks(&mdl_requests,
                                         thd->variables.lock_wait_timeout))
        return true;

      DEBUG_SYNC(thd, "locked_table_name");
      /*
        Table maybe does not exist, but we got an exclusive lock
        on the name, now we can safely try to find out for sure.
      */
      const dd::Abstract_table *at = nullptr;
      if (thd->dd_client()->acquire(alter_ctx.new_db, alter_ctx.new_name, &at))
        return true;

      if (at != nullptr) {
        /* Table will be closed in do_command() */
        my_error(ER_TABLE_EXISTS_ERROR, MYF(0), alter_ctx.new_alias);
        return true;
      }
    }
  }

  if (!create_info->db_type) {
    if (table->part_info && create_info->used_fields & HA_CREATE_USED_ENGINE) {
      /*
        This case happens when the user specified
        ENGINE = x where x is a non-existing storage engine
        We set create_info->db_type to default_engine_type
        to ensure we don't change underlying engine type
        due to a erroneously given engine name.
      */
      create_info->db_type = table->part_info->default_engine_type;
    } else
      create_info->db_type = table->s->db_type();
  }

  if (check_engine(alter_ctx.new_db, alter_ctx.new_name, create_info))
    return true;

  /*
    Do not allow change of storage engine if table participates in a foreign
    key. Even in cases when both source and target storage engines support
    foreign keys the fine details of what is supported might differ.
  */
  if (create_info->db_type != table->s->db_type() && old_table_def != nullptr &&
      (old_table_def->foreign_keys().size() ||
       old_table_def->foreign_key_parents().size())) {
    my_error(ER_FK_CANNOT_CHANGE_ENGINE, MYF(0));
    return true;
  }

  /*
   If foreign key is added then check permission to access parent table.

   In function "check_fk_parent_table_access", create_info->db_type is used
   to identify whether engine supports FK constraint or not. Since
   create_info->db_type is set here, check to parent table access is delayed
   till this point for the alter operation.
  */
  if ((alter_info->flags & Alter_info::ADD_FOREIGN_KEY) &&
      check_fk_parent_table_access(thd, create_info, alter_info))
    return true;

  Foreign_key_parents_invalidator fk_invalidator;

  if (table->s->tmp_table == NO_TMP_TABLE) {
    MDL_request_list mdl_requests;

    if (collect_fk_parents_for_new_fks(
            thd, table_list->db, table_list->table_name, alter_info,
            MDL_SHARED_UPGRADABLE, nullptr, &mdl_requests, nullptr))
      return true;

    /*
      Acquire SU locks on parent and child tables so we can access
      their definition while checking if this ALTER TABLE will break
      any FKs involving them.

      TODO: Refine set of ALTER TABLE commands for which we do this.
            This is obviously necessary for ADD/DROP KEY and COLUMN
            modifications. But are there any other operations which
            might affect indexes somehow?
    */
    if (!is_simple_rename_or_index_change(alter_info)) {
      if (collect_fk_parents_for_all_fks(thd, old_table_def, nullptr,
                                         MDL_SHARED_UPGRADABLE, &mdl_requests,
                                         nullptr))
        return true;

      if (create_info->db_type != table->s->db_type()) {
        /*
          By changing table's storage engine we might be introducing parent
          table for previously orphan foreign keys in the new SE. We need
          to lock child tables of such orphan foreign keys. OTOH it is safe
          to assume that if SE is changed table can't be parent in any
          foreign keys in old SE.

          Note that here and in other similar places we assume that ALTER
          TABLE which combines change of SE and renaming of table is executed
          by changing SE first and then performing rename (this is closer to
          ALTER TABLE real implementation). Because of this such ALTER TABLEs
          need to pick up orphan foreign keys associated with old table names
          as well. Thus we use old table name to get list of orphans.
        */
        assert(old_table_def->foreign_key_parents().size() == 0);

        if (collect_fk_children(thd, table_list->db, table_list->table_name,
                                create_info->db_type, MDL_SHARED_UPGRADABLE,
                                &mdl_requests))
          return true;
      } else {
        if (collect_fk_children(thd, old_table_def, MDL_SHARED_UPGRADABLE,
                                &mdl_requests))
          return true;
      }

      if (alter_ctx.is_table_renamed() &&
          collect_fk_children(thd, alter_ctx.new_db, alter_ctx.new_alias,
                              create_info->db_type, MDL_SHARED_UPGRADABLE,
                              &mdl_requests))
        return true;
    }

    /*
      Lock names of foreign keys to be dropped.

      Note that we can't lock names of foreign keys to be added yet
      because database in which they will be created depends on ALTER
      TABLE algorithm we are going to choose later.
    */
    if (collect_fk_names_for_dropped_fks(thd, table_list->db, alter_info,
                                         old_table_def, &mdl_requests))
      return true;

    /*
      Under LOCK TABLES all parent tables must be locked at least in READ
      mode. Otherwise, our ALTER TABLE will leave after itself child table
      locked for WRITE, without corresponding parent tables locked and thus
      without ability to perform FK checks when child table is modified.
    */
    if (thd->locked_tables_mode == LTM_LOCK_TABLES ||
        thd->locked_tables_mode == LTM_PRELOCKED_UNDER_LOCK_TABLES) {
      MDL_request_list::Iterator it(mdl_requests);
      MDL_request *mdl_request;

      while ((mdl_request = it++) != nullptr) {
        if (mdl_request->key.mdl_namespace() != MDL_key::TABLE) continue;

        if (!thd->mdl_context.owns_equal_or_stronger_lock(
                MDL_key::TABLE, mdl_request->key.db_name(),
                mdl_request->key.name(), MDL_SHARED_READ_ONLY)) {
          my_error(ER_TABLE_NOT_LOCKED, MYF(0), mdl_request->key.name());
          return true;
        }
      }
    }

    if (!mdl_requests.is_empty() &&
        thd->mdl_context.acquire_locks(&mdl_requests,
                                       thd->variables.lock_wait_timeout))
      return true;

    DEBUG_SYNC(thd, "alter_table_after_mdl_lock_fk");

    /*
      If we are executing ALTER TABLE RENAME under LOCK TABLES we also need
      to check that all previously orphan tables which reference new table
      name through foreign keys are locked for write. Otherwise this ALTER
      will leave after itself parent table locked for WRITE without child
      tables locked for WRITE. This will break FK LOCK TABLES invariants if
      some of previously orphan FKs have referential actions which update
      child table.

      The same should be done when we are going to add parent table to
      previously orphan foreign keys by changing table storage engine.

      In theory, we can reduce chance of MDL deadlocks by also checking at
      this stage that all child and parent tables for FKs in which this
      table participates are locked for WRITE (as we will have to acquire
      to exclusive MDLs on these tables later). But this is, probably, too
      severe restriction since many 3rd-party online ALTER tools use ALTER
      TABLE RENAME under LOCK TABLES and are unaware of it.
    */
    if (thd->locked_tables_mode == LTM_LOCK_TABLES ||
        thd->locked_tables_mode == LTM_PRELOCKED_UNDER_LOCK_TABLES) {
      MDL_request_list orphans_mdl_requests;

      if (create_info->db_type != table->s->db_type()) {
        assert(old_table_def->foreign_key_parents().size() == 0);
        if (collect_fk_children(thd, table_list->db, table_list->table_name,
                                create_info->db_type, MDL_EXCLUSIVE,
                                &orphans_mdl_requests))
          return true;
      }
      if (alter_ctx.is_table_renamed() &&
          collect_fk_children(thd, alter_ctx.new_db, alter_ctx.new_alias,
                              create_info->db_type, MDL_EXCLUSIVE,
                              &orphans_mdl_requests))
        return true;

      if (!orphans_mdl_requests.is_empty()) {
        MDL_request_list::Iterator it(orphans_mdl_requests);
        MDL_request *mdl_request;

        while ((mdl_request = it++) != nullptr) {
          if (mdl_request->key.mdl_namespace() != MDL_key::TABLE) continue;

          if (!thd->mdl_context.owns_equal_or_stronger_lock(
                  MDL_key::TABLE, mdl_request->key.db_name(),
                  mdl_request->key.name(), MDL_SHARED_NO_READ_WRITE)) {
            my_error(ER_TABLE_NOT_LOCKED_FOR_WRITE, MYF(0),
                     mdl_request->key.name());
            return true;
          }
        }
      }
    }
  }

  /*
   If this is an ALTER TABLE and no explicit row type specified reuse
   the table's row type.
   Note : this is the same as if the row type was specified explicitly.
  */
  if (create_info->row_type == ROW_TYPE_NOT_USED) {
    /* ALTER TABLE without explicit row type */
    create_info->row_type = table->s->row_type;
  } else {
    /* ALTER TABLE with specific row type */
    create_info->used_fields |= HA_CREATE_USED_ROW_FORMAT;
  }

  DBUG_PRINT("info", ("old type: %s  new type: %s",
                      ha_resolve_storage_engine_name(table->s->db_type()),
                      ha_resolve_storage_engine_name(create_info->db_type)));
  if (ha_check_storage_engine_flag(table->s->db_type(),
                                   HTON_ALTER_NOT_SUPPORTED) ||
      ha_check_storage_engine_flag(create_info->db_type,
                                   HTON_ALTER_NOT_SUPPORTED)) {
    DBUG_PRINT("info", ("doesn't support alter"));
    my_error(ER_ILLEGAL_HA, MYF(0), table_list->table_name);
    return true;
  }

  THD_STAGE_INFO(thd, stage_setup);

  if (is_simple_rename_or_index_change(alter_info) && !table->s->tmp_table) {
    // This requires X-lock, no other lock levels supported.
    if (alter_info->requested_lock != Alter_info::ALTER_TABLE_LOCK_DEFAULT &&
        alter_info->requested_lock != Alter_info::ALTER_TABLE_LOCK_EXCLUSIVE) {
      my_error(ER_ALTER_OPERATION_NOT_SUPPORTED, MYF(0), "LOCK=NONE/SHARED",
               "LOCK=EXCLUSIVE");
      return true;
    }
    return simple_rename_or_index_change(thd, *new_schema, table_list,
                                         alter_info->keys_onoff, &alter_ctx);
  }

  /* We have to do full alter table. */
  bool partition_changed = false;
  partition_info *new_part_info = nullptr;
  {
    if (prep_alter_part_table(thd, table, alter_info, create_info, &alter_ctx,
                              &partition_changed, &new_part_info)) {
      return true;
    }
  }

  /*
    Store all columns that are going to be dropped, since we need this list
    when removing column statistics later. The reason we need to store it here,
    is that 'mysql_prepare_alter_table' may remove some of the columns from
    the drop_list.
  */
  histograms::columns_set columns;
  for (const auto column : alter_info->drop_list) {
    if (column->type == Alter_drop::COLUMN) columns.emplace(column->name);
  }
  const Alter_column *alter = nullptr;
  uint i = 0;
  while (i < alter_info->alter_list.size()) {
    alter = alter_info->alter_list[i];
    if (alter->change_type() == Alter_column::Type::RENAME_COLUMN)
      columns.emplace(alter->name);
    i++;
  }

  Create_field *create_field;
  List_iterator<Create_field> list_it(alter_info->create_list);
  while ((create_field = list_it++)) {
    if (create_field->change != nullptr) columns.emplace(create_field->change);
  }

  /*
    Type of a constraint marked for DROP with DROP CONSTRAINT clause is unknown.
    Resolve type of a constraint by name.
  */
  Drop_constraint_type_resolver drop_constraint_type_resolver(alter_info);
  if (drop_constraint_type_resolver.is_type_resolution_needed() &&
      (drop_constraint_type_resolver.resolve_constraints_type(thd, table,
                                                              old_table_def)))
    return true;

  /*
    Type of a constraint marked for ALTER with ALTER CONSTRAINT clause is
    unknown. Resolve type of a constraint by name.
  */
  Enforce_constraint_type_resolver enforce_constraint_type_resolver(alter_info);
  if (enforce_constraint_type_resolver.is_type_resolution_needed() &&
      (enforce_constraint_type_resolver.resolve_constraints_type(
          thd, table, old_table_def)))
    return true;

  // Prepare check constraints for alter table operation.
  if (prepare_check_constraints_for_alter(thd, table, alter_info, &alter_ctx))
    return true;

  if (mysql_prepare_alter_table(thd, old_table_def, table, create_info,
                                alter_info, &alter_ctx)) {
    return true;
  }

  // Check restrictions on ALTER TABLE operations that affects GIPK and PK.
  if (check_primary_key_alter_restrictions(thd, create_info->db_type,
                                           alter_info, table))
    return true;

  /*
    Check if we are changing the SRID specification on a geometry column that
    has a spatial index. If that is the case, reject the change since allowing
    geometries with different SRIDs in a spatial index will make the index
    useless.
  */
  if (!is_alter_geometry_column_valid(alter_info)) return true;

  if (set_table_default_charset(thd, create_info, *schema)) return true;

  /*
    Use copy algorithm if:
    - old_alter_table system variable is set without in-place requested using
      the ALGORITHM clause.
    - Or if in-place is impossible for given operation.
    - Changes to partitioning needs to be handled using table copying
      algorithm unless the engine supports partitioning changes using
      in-place API (because it supports auto-partitioning or simply
      can do partitioning changes using in-place using mark-up in
      partition_info object).
  */
  if ((thd->variables.old_alter_table &&
       alter_info->requested_algorithm !=
           Alter_info::ALTER_TABLE_ALGORITHM_INPLACE &&
       alter_info->requested_algorithm !=
           Alter_info::ALTER_TABLE_ALGORITHM_INSTANT) ||
      is_inplace_alter_impossible(table, create_info, alter_info) ||
      (partition_changed &&
       !(table->s->db_type()->partition_flags() & HA_USE_AUTO_PARTITION) &&
       !new_part_info)) {
    if (alter_info->requested_algorithm ==
        Alter_info::ALTER_TABLE_ALGORITHM_INPLACE) {
      my_error(ER_ALTER_OPERATION_NOT_SUPPORTED, MYF(0), "ALGORITHM=INPLACE",
               "ALGORITHM=COPY");
      return true;
    }
    if (alter_info->requested_algorithm ==
        Alter_info::ALTER_TABLE_ALGORITHM_INSTANT) {
      my_error(ER_ALTER_OPERATION_NOT_SUPPORTED, MYF(0), "ALGORITHM=INSTANT",
               "ALGORITHM=COPY");
      return true;
    }
    alter_info->requested_algorithm = Alter_info::ALTER_TABLE_ALGORITHM_COPY;
  }

  /*
    If 'avoid_temporal_upgrade' mode is not enabled, then the
    pre MySQL 5.6.4 old temporal types if present is upgraded to the
    current format.
  */

  mysql_mutex_lock(&LOCK_global_system_variables);
  bool check_temporal_upgrade = !avoid_temporal_upgrade;
  mysql_mutex_unlock(&LOCK_global_system_variables);

  if (check_temporal_upgrade) {
    if (upgrade_old_temporal_types(thd, alter_info)) return true;
  }

  /*
    ALTER TABLE ... ENGINE to the same engine is a common way to
    request table rebuild. Set ALTER_RECREATE flag to force table
    rebuild.
  */
  if (create_info->db_type == table->s->db_type() &&
      create_info->used_fields & HA_CREATE_USED_ENGINE)
    alter_info->flags |= Alter_info::ALTER_RECREATE;

  /*
    If the old table had partitions and we are doing ALTER TABLE ...
    engine= <new_engine>, the new table must preserve the original
    partitioning. This means that the new engine is still the
    partitioning engine, not the engine specified in the parser.
    This is discovered in prep_alter_part_table, which in such case
    updates create_info->db_type.
    It's therefore important that the assignment below is done
    after prep_alter_part_table.
  */
  handlerton *new_db_type = create_info->db_type;
  handlerton *old_db_type = table->s->db_type();
  TABLE *new_table = nullptr;
  ha_rows copied = 0, deleted = 0;

  /*
    Handling of symlinked tables:
    If no rename:
      Create new data file and index file on the same disk as the
      old data and index files.
      Copy data.
      Rename new data file over old data file and new index file over
      old index file.
      Symlinks are not changed.

   If rename:
      Create new data file and index file on the same disk as the
      old data and index files.  Create also symlinks to point at
      the new tables.
      Copy data.
      At end, rename intermediate tables, and symlinks to intermediate
      table, to final table name.
      Remove old table and old symlinks

    If rename is made to another database:
      Create new tables in new database.
      Copy data.
      Remove old table and symlinks.
  */
  char index_file[FN_REFLEN], data_file[FN_REFLEN];

  if (!alter_ctx.is_database_changed()) {
    if (create_info->index_file_name) {
      /* Fix index_file_name to have 'tmp_name' as basename */
      my_stpcpy(index_file, alter_ctx.tmp_name);
      create_info->index_file_name =
          fn_same(index_file, create_info->index_file_name, 1);
    }
    if (create_info->data_file_name) {
      /* Fix data_file_name to have 'tmp_name' as basename */
      my_stpcpy(data_file, alter_ctx.tmp_name);
      create_info->data_file_name =
          fn_same(data_file, create_info->data_file_name, 1);
    }
  } else {
    /* Ignore symlink if db is changed. */
    create_info->data_file_name = create_info->index_file_name = nullptr;
  }

  DEBUG_SYNC(thd, "alter_table_before_create_table_no_lock");
  DBUG_EXECUTE_IF("sleep_before_create_table_no_lock", my_sleep(100000););
  /*
    Promote first timestamp column, when explicit_defaults_for_timestamp
    is not set
  */
  if (!thd->variables.explicit_defaults_for_timestamp)
    promote_first_timestamp_column(&alter_info->create_list);

  /*
    Create .FRM for new version of table with a temporary name.
    We don't log the statement, it will be logged later.

    Keep information about keys in newly created table as it
    will be used later to construct Alter_inplace_info object
    and by fill_alter_inplace_info() call.
  */
  KEY *key_info;
  uint key_count;
  FOREIGN_KEY *fk_key_info = nullptr;
  uint fk_key_count = 0;

  Alter_info::enum_enable_or_disable keys_onoff =
      ((alter_info->keys_onoff == Alter_info::LEAVE_AS_IS &&
        table->file->indexes_are_disabled())
           ? Alter_info::DISABLE
           : alter_info->keys_onoff);

  /*
    Take the X metadata lock on temporary name used for new version of
    the table. This ensures that concurrent I_S queries won't try to open it.
  */

  MDL_request tmp_name_mdl_request;
  bool is_tmp_table = (table->s->tmp_table != NO_TMP_TABLE);

  // Avoid these tables to be visible by I_S/SHOW queries.
  create_info->m_hidden = !is_tmp_table;

  if (!is_tmp_table) {
    MDL_REQUEST_INIT(&tmp_name_mdl_request, MDL_key::TABLE, alter_ctx.new_db,
                     alter_ctx.tmp_name, MDL_EXCLUSIVE, MDL_STATEMENT);
    if (thd->mdl_context.acquire_lock(&tmp_name_mdl_request,
                                      thd->variables.lock_wait_timeout))
      return true;
  }

  // Stop if we have invalid encryption clause.
  if (!is_tmp_table && validate_table_encryption(thd, create_info)) return true;

  /*
    For temporary tables or tables in SEs supporting atomic DDL dd::Table
    object describing new version of table. This object will be created in
    memory in create_table_impl() and will not be put into the on-disk DD
    and DD Object Cache.

    We become responsible for destroying this dd::Table object (for
    temporary tables until we pass its ownership to the TABLE_SHARE).
  */
  std::unique_ptr<dd::Table> non_dd_table_def;

  {
    Disable_binlog_guard binlog_guard(thd);
    /* Prevent intermediate commits to invoke commit order */
    Implicit_substatement_state_guard substatement_guard(
        thd, enum_implicit_substatement_guard_mode ::
                 DISABLE_GTID_AND_SPCO_IF_SPCO_ACTIVE);
    error = create_table_impl(
        thd, *new_schema, alter_ctx.new_db, alter_ctx.tmp_name,
        alter_ctx.table_name, alter_ctx.get_tmp_path(), create_info, alter_info,
        true, 0, true, true,
        /*
          If target SE supports atomic DDL do not store
          new table version in on-disk DD.
          It is not required to rollback statement in
          case of error and allows to keep correct names
          for pre-existing foreign keys in the dd::Table
          object for new table version.
         */
        (new_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL), nullptr, &key_info,
        &key_count, keys_onoff, &fk_key_info, &fk_key_count, alter_ctx.fk_info,
        alter_ctx.fk_count, old_table_def,
        alter_ctx.fk_max_generated_name_number, &non_dd_table_def, nullptr);
  }

  if (error) {
    /*
      Play it safe, rollback possible changes to the data-dictionary,
      so failed mysql_alter_table()/mysql_recreate_table() do not
      require rollback in the caller. Also do full rollback in unlikely
      case we have THD::transaction_rollback_request.
    */
    trans_rollback_stmt(thd);
    trans_rollback(thd);
    return true;
  }

  /*
    Atomic replacement of the table is possible only if both old and new
    storage engines support DDL atomicity.
  */
  bool atomic_replace = (new_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL) &&
                        (old_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL);

  /* Remember that we have not created table in storage engine yet. */
  bool no_ha_table = true;

  /* Indicates special case when we do ALTER TABLE which is really no-op. */
  bool is_noop = false;

  /*
    Indicates special case involving non-atomic ALTER TABLE which adds
    foreign keys and then fails at the late stage. Such ALTER TABLE still
    requires FK parent invalidation even despite of error.
  */
  bool invalidate_fk_parents_on_error = false;

  dd::Encrypt_result old_er{false, false};
  dd::Encrypt_result new_er{false, false};

  /*
    If we are ALTERing non-temporary table in SE not supporting atomic DDL
    we don't have dd::Table object describing new version of table yet.
    Retrieve it now.
  */
  dd::Table *table_def = non_dd_table_def.get();
  if (!table_def) {
    if (thd->dd_client()->acquire_for_modification(
            alter_ctx.new_db, alter_ctx.tmp_name, &table_def))
      goto err_new_table_cleanup;

    set_check_constraints_alter_mode(table_def, alter_info);

    assert(table_def);
  }

  if (!is_tmp_table) {
    // Check for usage of prefix key index in PARTITION BY KEY() function.
    dd::warn_on_deprecated_prefix_key_partition(
        thd, alter_ctx.db, alter_ctx.table_name, table_def, false);
  }

  if (remove_secondary_engine(thd, *table_list, *create_info, old_table_def))
    goto err_new_table_cleanup;

  // If we are changing the tablespace or the table encryption type.
  if (old_table_def &&
      (create_info->used_fields & HA_CREATE_USED_TABLESPACE ||
       create_info->used_fields & HA_CREATE_USED_ENCRYPT ||
       create_info->used_fields & HA_CREATE_USED_AUTOEXTEND_SIZE ||
       alter_ctx.is_database_changed())) {
    bool source_is_general_tablespace{false};
    bool source_encrytion_type{false};
    bool destination_is_general_tablespace{false};
    bool destination_encrytion_type{false};

    // Determine source tablespace type and encryption type.
    old_er = dd::is_tablespace_encrypted(thd, *old_table_def,
                                         &source_is_general_tablespace);
    if (old_er.error) {
      goto err_new_table_cleanup;
    }
    source_encrytion_type = old_er.value;
    if (!source_is_general_tablespace &&
        old_table_def->options().exists("encrypt_type")) {
      dd::String_type et;
      (void)old_table_def->options().get("encrypt_type", &et);
      assert(et.empty() == false);
      source_encrytion_type = is_encrypted(et);
    }

    // Determine destination tablespace type and encryption type.
    new_er = dd::is_tablespace_encrypted(thd, *table_def,
                                         &destination_is_general_tablespace);
    if (new_er.error) {
      goto err_new_table_cleanup;
    }
    destination_encrytion_type = new_er.value;
    if (!destination_is_general_tablespace &&
        table_def->options().exists("encrypt_type")) {
      dd::String_type et;
      (void)table_def->options().get("encrypt_type", &et);
      assert(et.empty() == false);
      destination_encrytion_type = is_encrypted(et);
    }

    /*
      Disallow converting a general tablespace to a file-per-table
      tablespace without a explicit ENCRYPTION clause.
    */
    if (source_is_general_tablespace && source_encrytion_type == true &&
        !destination_is_general_tablespace &&
        !(create_info->used_fields & HA_CREATE_USED_ENCRYPT)) {
      my_error(ER_TARGET_TABLESPACE_UNENCRYPTED, MYF(0));
      goto err_new_table_cleanup;
    }

    /*
      Disallow moving encrypted table (using general or file-per-table
      tablespace) to a unencrypted general tablespace.
    */
    if (source_encrytion_type && destination_is_general_tablespace &&
        !destination_encrytion_type) {
      my_error(ER_TARGET_TABLESPACE_UNENCRYPTED, MYF(0));
      goto err_new_table_cleanup;
    }

    /*
      Check table encryption privilege, if table encryption type differ
      from schema encryption type.
    */
    if (new_schema->default_encryption() != destination_encrytion_type) {
      // Ignore privilege check and show warning if database is same and
      // table encryption type is not changed.
      bool show_warning = !alter_ctx.is_database_changed() &&
                          source_encrytion_type == destination_encrytion_type;

      if (!show_warning && opt_table_encryption_privilege_check) {
        if (check_table_encryption_admin_access(thd)) {
          my_error(ER_CANNOT_SET_TABLE_ENCRYPTION, MYF(0));
          return true;
        }
      } else if (new_schema->default_encryption() &&
                 !destination_encrytion_type) {
        push_warning(thd, Sql_condition::SL_WARNING,
                     WARN_UNENCRYPTED_TABLE_IN_ENCRYPTED_DB,
                     ER_THD(thd, WARN_UNENCRYPTED_TABLE_IN_ENCRYPTED_DB));
      }
    }
  }

  if (old_table_def) {
    if (is_checked_for_upgrade(*old_table_def)) {
      DBUG_PRINT("admin", ("Transfering upgrade mark "
                           "from Table %s (%llu) to Table %s (%llu)",
                           old_table_def->name().c_str(), old_table_def->id(),
                           table_def->name().c_str(), table_def->id()));
      table_def->mark_as_checked_for_upgrade();
    }
  }

  /*
    Check if new table definition is compatible with foreign keys
    on other tales which reference this one. We want to do this
    before starting potentially expensive main phases of COPYing
    or INPLACE ALTER TABLE.
  */
  if (!is_tmp_table) {
    if (new_db_type != old_db_type) {
      /*
        By changing table's storage engine we might be introducing parent
        table for previously orphan foreign keys in the new SE. We need
        to lock child tables of such orphan foreign keys. OTOH it is safe
        to assume that if SE is changed table can't be parent in any
        foreign keys in old SE.

        We assume that ALTER TABLE which combines change of SE and renaming
        of table is executed by changing SE first and then performing rename
        (this is closer to ALTER TABLE real implementation). So such ALTER
        TABLEs  need to pick up orphan foreign keys associated with old table
        names as well. Thus we use old table name in the below check.
      */
      assert(old_table_def->foreign_key_parents().size() == 0);

      if (check_fk_children_after_parent_def_change(
              thd, table_list->db, table_list->table_name, nullptr, nullptr,
              new_db_type, table_def))
        goto err_new_table_cleanup;
    } else {
      if (check_fk_children_after_parent_def_change(
              thd, table_list->db, table_list->table_name, new_db_type,
              old_table_def, table_def, alter_info))
        goto err_new_table_cleanup;
    }

    if (alter_ctx.is_table_renamed() &&
        check_fk_children_after_parent_def_change(
            thd, alter_ctx.new_db, alter_ctx.new_alias, table_list->db,
            table_list->table_name, new_db_type, table_def))
      goto err_new_table_cleanup;
  }

  if (alter_info->requested_algorithm !=
      Alter_info::ALTER_TABLE_ALGORITHM_COPY) {
    Alter_inplace_info ha_alter_info(create_info, alter_info,
                                     alter_ctx.error_if_not_empty, key_info,
                                     key_count, thd->work_part_info);
    TABLE *altered_table = nullptr;
    bool use_inplace = true;

    /* Fill the Alter_inplace_info structure. */
    if (fill_alter_inplace_info(thd, table, &ha_alter_info))
      goto err_new_table_cleanup;

    DBUG_EXECUTE_IF("innodb_index_drop_count_zero", {
      if (ha_alter_info.index_drop_count) {
        my_error(ER_ALTER_OPERATION_NOT_SUPPORTED, MYF(0), "Index rebuild",
                 "Without rebuild");
        return true;
      }
    };);

    DBUG_EXECUTE_IF("innodb_index_drop_count_one", {
      if (ha_alter_info.index_drop_count != 1) {
        my_error(ER_ALTER_OPERATION_NOT_SUPPORTED, MYF(0), "Index change",
                 "Index rebuild");
        return true;
      }
    };);

    // We assume that the table is non-temporary.
    assert(!table->s->tmp_table);

    if (!(altered_table = open_table_uncached(
              thd, alter_ctx.get_tmp_path(), alter_ctx.new_db,
              alter_ctx.tmp_name, true, false, *table_def)))
      goto err_new_table_cleanup;

    /* Set markers for fields in TABLE object for altered table. */
    update_altered_table(ha_alter_info, altered_table);

    /*
      Mark all columns in 'altered_table' as used to allow usage
      of its record[0] buffer and Field objects during in-place
      ALTER TABLE.
    */
    altered_table->column_bitmaps_set_no_signal(&altered_table->s->all_set,
                                                &altered_table->s->all_set);

    set_column_static_defaults(altered_table, alter_info->create_list);

    if (ha_alter_info.handler_flags == 0) {
      /*
        No-op ALTER, no need to call handler API functions.

        If this code path is entered for an ALTER statement that
        should not be a real no-op, new handler flags should be added
        and fill_alter_inplace_info() adjusted.

        Note that we can end up here if an ALTER statement has clauses
        that cancel each other out (e.g. ADD/DROP identically index).

        Also note that we ignore the LOCK clause here.
      */
      close_temporary_table(thd, altered_table, true, false);

      if (!(create_info->db_type->flags & HTON_SUPPORTS_ATOMIC_DDL)) {
        // Delete temporary table object from data dictionary.
        bool result = dd::drop_table(thd, alter_ctx.new_db, alter_ctx.tmp_name,
                                     *table_def);
        (void)trans_intermediate_ddl_commit(thd, result);
      }

      is_noop = true;
      goto end_inplace_noop;
    }

    // Ask storage engine whether to use copy or in-place
    enum_alter_inplace_result inplace_supported =
        table->file->check_if_supported_inplace_alter(altered_table,
                                                      &ha_alter_info);

    // If INSTANT was requested but it is not supported, report error.
    if (alter_info->requested_algorithm ==
            Alter_info::ALTER_TABLE_ALGORITHM_INSTANT &&
        inplace_supported != HA_ALTER_INPLACE_INSTANT &&
        inplace_supported != HA_ALTER_ERROR) {
      ha_alter_info.report_unsupported_error("ALGORITHM=INSTANT",
                                             "ALGORITHM=COPY/INPLACE");
      close_temporary_table(thd, altered_table, true, false);
      goto err_new_table_cleanup;
    }

    switch (inplace_supported) {
      case HA_ALTER_INPLACE_EXCLUSIVE_LOCK:
        // If SHARED lock and no particular algorithm was requested, use COPY.
        if (alter_info->requested_lock == Alter_info::ALTER_TABLE_LOCK_SHARED &&
            alter_info->requested_algorithm ==
                Alter_info::ALTER_TABLE_ALGORITHM_DEFAULT) {
          use_inplace = false;
        }
        // Otherwise, if weaker lock was requested, report error.
        else if (alter_info->requested_lock ==
                     Alter_info::ALTER_TABLE_LOCK_NONE ||
                 alter_info->requested_lock ==
                     Alter_info::ALTER_TABLE_LOCK_SHARED) {
          ha_alter_info.report_unsupported_error("LOCK=NONE/SHARED",
                                                 "LOCK=EXCLUSIVE");
          close_temporary_table(thd, altered_table, true, false);
          goto err_new_table_cleanup;
        }
        break;
      case HA_ALTER_INPLACE_SHARED_LOCK_AFTER_PREPARE:
      case HA_ALTER_INPLACE_SHARED_LOCK:
        // If weaker lock was requested, report error.
        if (alter_info->requested_lock == Alter_info::ALTER_TABLE_LOCK_NONE) {
          ha_alter_info.report_unsupported_error("LOCK=NONE", "LOCK=SHARED");
          close_temporary_table(thd, altered_table, true, false);
          goto err_new_table_cleanup;
        }
        break;
      case HA_ALTER_INPLACE_NO_LOCK_AFTER_PREPARE:
      case HA_ALTER_INPLACE_NO_LOCK:
      case HA_ALTER_INPLACE_INSTANT:
        /*
          Note that any instant operation is also in fact in-place operation.

          It is totally safe to execute operation using instant algorithm if it
          has no drawbacks as compared to in-place algorithm even if user
          explicitly asked for ALGORITHM=INPLACE. Doing so, also allows to
          keep code in engines which support only limited subset of in-place
          ALTER TABLE operations as instant metadata only changes simple.

          If instant algorithm has some downsides to in-place algorithm and user
          explicitly asks for ALGORITHM=INPLACE it is responsibility of storage
          engine to fallback to in-place algorithm execution by returning
          HA_ALTER_INPLACE_NO_LOCK or HA_ALTER_INPLACE_NO_LOCK_AFTER_PREPARE.
        */
        break;
      case HA_ALTER_INPLACE_NOT_SUPPORTED:
        // If INPLACE was requested, report error.
        if (alter_info->requested_algorithm ==
            Alter_info::ALTER_TABLE_ALGORITHM_INPLACE) {
          ha_alter_info.report_unsupported_error("ALGORITHM=INPLACE",
                                                 "ALGORITHM=COPY");
          close_temporary_table(thd, altered_table, true, false);
          goto err_new_table_cleanup;
        }
        // COPY with LOCK=NONE is not supported, no point in trying.
        if (alter_info->requested_lock == Alter_info::ALTER_TABLE_LOCK_NONE) {
          ha_alter_info.report_unsupported_error("LOCK=NONE", "LOCK=SHARED");
          close_temporary_table(thd, altered_table, true, false);
          goto err_new_table_cleanup;
        }
        // Otherwise use COPY
        use_inplace = false;
        break;
      case HA_ALTER_ERROR:
      default:
        close_temporary_table(thd, altered_table, true, false);
        goto err_new_table_cleanup;
    }

    if (use_inplace) {
      if (mysql_inplace_alter_table(thd, *schema, *new_schema, old_table_def,
                                    table_def, table_list, table, altered_table,
                                    &ha_alter_info, inplace_supported,
                                    &alter_ctx, columns, fk_key_info,
                                    fk_key_count, &fk_invalidator)) {
        return true;
      }

      goto end_inplace;
    } else {
      close_temporary_table(thd, altered_table, true, false);
    }
  }

  /* ALTER TABLE using copy algorithm. */

  /* Check if ALTER TABLE is compatible with foreign key definitions. */
  if (fk_check_copy_alter_table(thd, table_list, old_table_def, alter_info))
    goto err_new_table_cleanup;

  if (!table->s->tmp_table) {
    MDL_request_list mdl_requests;

    // COPY algorithm doesn't work with concurrent writes.
    if (alter_info->requested_lock == Alter_info::ALTER_TABLE_LOCK_NONE) {
      my_error(ER_ALTER_OPERATION_NOT_SUPPORTED_REASON, MYF(0), "LOCK=NONE",
               ER_THD(thd, ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_COPY),
               "LOCK=SHARED");
      goto err_new_table_cleanup;
    }

    // If EXCLUSIVE lock is requested, upgrade already.
    if (alter_info->requested_lock == Alter_info::ALTER_TABLE_LOCK_EXCLUSIVE &&
        wait_while_table_is_used(thd, table, HA_EXTRA_FORCE_REOPEN))
      goto err_new_table_cleanup;

    /*
      Otherwise upgrade to SHARED_NO_WRITE.
      Note that under LOCK TABLES, we will already have SHARED_NO_READ_WRITE.
    */
    if (alter_info->requested_lock != Alter_info::ALTER_TABLE_LOCK_EXCLUSIVE &&
        thd->mdl_context.upgrade_shared_lock(mdl_ticket, MDL_SHARED_NO_WRITE,
                                             thd->variables.lock_wait_timeout))
      goto err_new_table_cleanup;

    DEBUG_SYNC(thd, "alter_table_copy_after_lock_upgrade");

    /*
      COPY algorithm creates new table version in the new database.
      So if new database differs from old one we need to lock all
      foreign key names in new table version. If it is the same as
      the old one we need to lock only names of foreign keys added.

      Also if table is renamed we need to acquire locks on all foreign
      key names involved (taking into account adjustment of auto-generated
      names).
    */
    if (alter_ctx.is_database_changed()) {
      if (collect_fk_names(thd, alter_ctx.new_db, table_def, &mdl_requests))
        goto err_new_table_cleanup;
    } else {
      if (collect_fk_names_for_new_fks(
              thd, alter_ctx.new_db, table_list->table_name, alter_info,
              new_db_type,
              get_fk_max_generated_name_number(table_list->table_name,
                                               old_table_def, new_db_type),
              &mdl_requests))
        goto err_new_table_cleanup;
    }

    if (alter_ctx.is_table_renamed() &&
        collect_fk_names_for_rename_table(
            thd, table_list->db, table_list->table_name, table_def, new_db_type,
            alter_ctx.new_db, alter_ctx.new_name, &mdl_requests))
      goto err_new_table_cleanup;

    /*
      Acquire SRO locks on parent tables for newly added foreign keys
      in order to prevent concurrent DML on them.

      This is temporary workaround to the problem caused by the fact that
      InnoDB makes such foreign keys visible in its internal dictionary
      cache before ALTER TABLE commit. So such DML can result in access
      to our temporary table without prior acquisition of metadata lock
      on it (which would have blocked such access normally). As result
      our ALTER TABLE can fail due to locks acquired by these accesses.

      Long-term the problem should be solved by adjusting InnoDB code
      to avoid making such uncommitted changes visible to other
      connections.
    */
    if (collect_fk_parents_for_new_fks(
            thd, table_list->db, table_list->table_name, alter_info,
            MDL_SHARED_READ_ONLY, nullptr, &mdl_requests, nullptr))
      goto err_new_table_cleanup;

    if (!mdl_requests.is_empty() &&
        thd->mdl_context.acquire_locks(&mdl_requests,
                                       thd->variables.lock_wait_timeout))
      goto err_new_table_cleanup;

    /*
      Check if ALTER TABLE results in any foreign key name conflicts
      before starting potentially expensive copying operation.
    */
    if (!dd::get_dictionary()->is_dd_table_name(table_list->db,
                                                table_list->table_name) &&
        (new_db_type->flags & HTON_SUPPORTS_FOREIGN_KEYS)) {
      if (alter_ctx.is_database_changed()) {
        /*
          If new table version was created schema different from the old one
          we need to check names for both pre-existing and newly added foreign
          keys.
        */
        for (FOREIGN_KEY *fk = fk_key_info; fk < fk_key_info + fk_key_count;
             ++fk) {
          bool exists;
          if (thd->dd_client()->check_foreign_key_exists(*new_schema, fk->name,
                                                         &exists))
            goto err_new_table_cleanup;

          if (exists) {
            my_error(ER_FK_DUP_NAME, MYF(0), fk->name);
            goto err_new_table_cleanup;
          }
        }
      } else {
        /* Otherwise we can limit our check to newly added foreign keys only. */
        for (FOREIGN_KEY *fk = fk_key_info + alter_ctx.fk_count;
             fk < fk_key_info + fk_key_count; ++fk) {
          bool exists;
          if (thd->dd_client()->check_foreign_key_exists(*new_schema, fk->name,
                                                         &exists))
            goto err_new_table_cleanup;

          if (exists) {
            my_error(ER_FK_DUP_NAME, MYF(0), fk->name);
            goto err_new_table_cleanup;
          }
        }
      }

      if (alter_ctx.is_table_renamed() &&
          check_fk_names_before_rename(thd, table_list, *table_def, new_db_type,
                                       *new_schema, alter_ctx))
        goto err_new_table_cleanup;
    }
  }

  {
    if (ha_create_table(thd, alter_ctx.get_tmp_path(), alter_ctx.new_db,
                        alter_ctx.tmp_name, create_info, false, true,
                        table_def))
      goto err_new_table_cleanup;

    /* Mark that we have created table in storage engine. */
    no_ha_table = false;

    if (create_info->options & HA_LEX_CREATE_TMP_TABLE) {
      if (thd->decide_logging_format(table_list) ||
          !open_table_uncached(thd, alter_ctx.get_tmp_path(), alter_ctx.new_db,
                               alter_ctx.tmp_name, true, true, *table_def))
        goto err_new_table_cleanup;
      /* in case of alter temp table send the tracker in OK packet */
      if (thd->session_tracker.get_tracker(SESSION_STATE_CHANGE_TRACKER)
              ->is_enabled())
        thd->session_tracker.get_tracker(SESSION_STATE_CHANGE_TRACKER)
            ->mark_as_changed(thd, {});
    }

    /* Open the table since we need to copy the data. */
    if (table->s->tmp_table != NO_TMP_TABLE) {
      Table_ref tbl(alter_ctx.new_db, alter_ctx.tmp_name, TL_READ_NO_INSERT);
      /* Table is in thd->temporary_tables */
      (void)open_temporary_table(thd, &tbl);
      new_table = tbl.table;
      /* Transfer dd::Table ownership to temporary table's share. */
      new_table->s->tmp_table_def = non_dd_table_def.release();
    } else {
      /* table is a normal table: Create temporary table in same directory */
      /* Open our intermediate table. */
      new_table =
          open_table_uncached(thd, alter_ctx.get_tmp_path(), alter_ctx.new_db,
                              alter_ctx.tmp_name, true, true, *table_def);
    }
    if (!new_table) goto err_new_table_cleanup;
    /*
      Note: In case of MERGE table, we do not attach children. We do not
      copy data for MERGE tables. Only the children have data.
    */

    // It's now safe to take the table level lock.
    if (lock_tables(thd, table_list, alter_ctx.tables_opened, 0))
      goto err_new_table_cleanup;
  }

  /*
    We do not copy data for MERGE tables. Only the children have data.
    MERGE tables have HA_NO_COPY_ON_ALTER set.
  */
  if (!(new_table->file->ha_table_flags() & HA_NO_COPY_ON_ALTER)) {
    new_table->next_number_field = new_table->found_next_number_field;
    THD_STAGE_INFO(thd, stage_copy_to_tmp_table);
    DBUG_EXECUTE_IF("abort_copy_table", {
      my_error(ER_LOCK_WAIT_TIMEOUT, MYF(0));
      goto err_new_table_cleanup;
    });

    if (copy_data_between_tables(thd, thd->m_stage_progress_psi, table,
                                 new_table, alter_info->create_list, &copied,
                                 &deleted, alter_info->keys_onoff, &alter_ctx))
      goto err_new_table_cleanup;

    DEBUG_SYNC(thd, "alter_after_copy_table");
  } else {
    /* Should be MERGE only */
    assert(new_table->file->ht->db_type == DB_TYPE_MRG_MYISAM);
    if (!table->s->tmp_table &&
        wait_while_table_is_used(thd, table, HA_EXTRA_FORCE_REOPEN))
      goto err_new_table_cleanup;
    THD_STAGE_INFO(thd, stage_manage_keys);
    DEBUG_SYNC(thd, "alter_table_manage_keys");
    alter_table_manage_keys(thd, table, table->file->indexes_are_disabled(),
                            alter_info->keys_onoff);
    assert(!(new_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL));

    /* Prevent intermediate commits to invoke commit order */
    Implicit_substatement_state_guard substatement_guard(
        thd, enum_implicit_substatement_guard_mode ::
                 DISABLE_GTID_AND_SPCO_IF_SPCO_ACTIVE);

    if (trans_commit_stmt(thd) || trans_commit_implicit(thd))
      goto err_new_table_cleanup;
  }

  if (table->s->tmp_table != NO_TMP_TABLE) {
    /* Close lock if this is a transactional table */
    if (thd->lock) {
      if (thd->locked_tables_mode != LTM_LOCK_TABLES &&
          thd->locked_tables_mode != LTM_PRELOCKED_UNDER_LOCK_TABLES) {
        mysql_unlock_tables(thd, thd->lock);
        thd->lock = nullptr;
      } else {
        /*
          If LOCK TABLES list is not empty and contains this table,
          unlock the table and remove the table from this list.
        */
        mysql_lock_remove(thd, thd->lock, table);
      }
    }
    /* Remove link to old table and rename the new one */
    close_temporary_table(thd, table, true, true);
    /* Should pass the 'new_name' as we store table name in the cache */
    if (rename_temporary_table(thd, new_table, alter_ctx.new_db,
                               alter_ctx.new_name))
      goto err_new_table_cleanup;
    /*
      We don't replicate alter table statement on temporary tables
      in RBR mode.
    */
    if (!thd->is_current_stmt_binlog_format_row() &&
        write_bin_log(thd, true, thd->query().str, thd->query().length)) {
      /*
        We can't revert replacement of old table version with a new one
        at this point. So, if possible, commit the statement to avoid
        new table version being emptied by statement rollback.
      */
      if (!thd->transaction_rollback_request) {
        (void)trans_commit_stmt(thd);
        (void)trans_commit_implicit(thd);
      }
      return true;
    }

    // Do implicit commit for consistency with non-temporary table case/
    if (trans_commit_stmt(thd) || trans_commit_implicit(thd)) return true;

    goto end_temporary;
  }

  /*
    Close the intermediate table that will be the new table, but do
    not delete it! Even though MERGE tables do not have their children
    attached here it is safe to call close_temporary_table().
  */
  close_temporary_table(thd, new_table, true, false);
  new_table = nullptr;

  DEBUG_SYNC(thd, "alter_table_before_rename_result_table");
  DBUG_EXECUTE_IF("exit_after_alter_table_before_rename", {
    my_error(ER_UNKNOWN_ERROR, MYF(0));
    return true;
  });

  /*
    Data is copied. Now we:
    1) Wait until all other threads will stop using old version of table
       by upgrading shared metadata lock to exclusive one.
    2) Close instances of table open by this thread and replace them
       with placeholders to simplify reopen process.
    3) Rename the old table to a temp name, rename the new one to the
       old name.
    4) If we are under LOCK TABLES and don't do ALTER TABLE ... RENAME
       we reopen new version of table.
    5) Write statement to the binary log.
    6) If we are under LOCK TABLES and do ALTER TABLE ... RENAME we
       remove placeholders and release metadata locks.
    7) If we are not not under LOCK TABLES we rely on the caller
      (mysql_execute_command()) to release metadata locks.
  */

  THD_STAGE_INFO(thd, stage_rename_result_table);

  if (wait_while_table_is_used(thd, table, HA_EXTRA_PREPARE_FOR_RENAME))
    goto err_new_table_cleanup;

  if (collect_and_lock_fk_tables_for_complex_alter_table(
          thd, table_list, old_table_def, &alter_ctx, alter_info, old_db_type,
          new_db_type, &fk_invalidator))
    goto err_new_table_cleanup;

  /*
    To ensure DDL atomicity after this point support from both old and
    new engines is necessary. If either of them lacks such support let
    us commit transaction so changes to data-dictionary are more closely
    reflect situations in SEs.

    Also if new SE supports atomic DDL then we have not stored new table
    definition in on-disk data-dictionary so far. It is time to do this
    now if ALTER TABLE as a whole won't be atomic.
  */
  if (!atomic_replace) {
    if ((new_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL) &&
        thd->dd_client()->store(non_dd_table_def.get()))
      goto err_new_table_cleanup;

    /* Prevent intermediate commits to invoke commit order */
    Implicit_substatement_state_guard substatement_guard(thd);

    if (trans_commit_stmt(thd) || trans_commit_implicit(thd))
      goto err_new_table_cleanup;

    // Safety, in-memory dd::Table is no longer totally correct.
    non_dd_table_def.reset();
  }

  char backup_name[32];
  assert(sizeof(my_thread_id) == 4);
  snprintf(backup_name, sizeof(backup_name), "%s2-%lx-%x", tmp_file_prefix,
           current_pid, thd->thread_id());
  if (lower_case_table_names) my_casedn_str(files_charset_info, backup_name);

  close_all_tables_for_name(thd, table->s, false, nullptr);
  table_list->table = table = nullptr; /* Safety */

  /*
    Rename the old version to temporary name to have a backup in case
    anything goes wrong while renaming the new table.

    Take the X metadata lock on this temporary name too. This ensures that
    concurrent I_S queries won't try to open it. Assert to ensure we do not
    come here when ALTERing temporary table.
  */
  {
    assert(!is_tmp_table);
    MDL_request backup_name_mdl_request;
    MDL_REQUEST_INIT(&backup_name_mdl_request, MDL_key::TABLE, alter_ctx.db,
                     backup_name, MDL_EXCLUSIVE, MDL_STATEMENT);
    dd::cache::Dictionary_client::Auto_releaser releaser_2(thd->dd_client());
    const dd::Table *backup_table = nullptr;

    if (thd->mdl_context.acquire_lock(&backup_name_mdl_request,
                                      thd->variables.lock_wait_timeout) ||
        thd->dd_client()->acquire(alter_ctx.db, backup_name, &backup_table)) {
      /* purecov: begin tested */
      /*
        We need to clear THD::transaction_rollback_request (which might
        be set due to MDL deadlock) before attempting to remove new version
        of table.
      */
      if (thd->transaction_rollback_request) {
        trans_rollback_stmt(thd);
        trans_rollback(thd);
      }

      if (!atomic_replace) {
        (void)quick_rm_table(thd, new_db_type, alter_ctx.new_db,
                             alter_ctx.tmp_name, FN_IS_TMP);
      }
      goto err_with_mdl;
      /* purecov: end */
    }

    if (backup_table != nullptr) {
      /* purecov: begin tested */
      my_error(ER_TABLE_EXISTS_ERROR, MYF(0), backup_name);

      if (!atomic_replace) {
        (void)quick_rm_table(thd, new_db_type, alter_ctx.new_db,
                             alter_ctx.tmp_name, FN_IS_TMP);
      }
      goto err_with_mdl;
      /* purecov: end */
    }
  }

  if (mysql_rename_table(thd, old_db_type, alter_ctx.db, alter_ctx.table_name,
                         alter_ctx.db, alter_ctx.table_name, *schema,
                         alter_ctx.db, backup_name,
                         FN_TO_IS_TMP | (atomic_replace ? NO_DD_COMMIT : 0) |
                             NO_FK_RENAME | NO_CC_RENAME)) {
    // Rename to temporary name failed, delete the new table, abort ALTER.
    if (!atomic_replace) {
      /*
        In non-atomic mode situations when the SE has requested rollback
        should be handled already, by executing rollback right inside
        mysql_rename_table() call.
      */
      assert(!thd->transaction_rollback_request);
      (void)quick_rm_table(thd, new_db_type, alter_ctx.new_db,
                           alter_ctx.tmp_name, FN_IS_TMP);
    }
    goto err_with_mdl;
  }

  /*
    The below code assumes that only SE capable of atomic DDL support FK.
    This is somewhat simplifies error handling below.

    Note that we need to handle FKs atomically with this rename in order
    to handle scenario when, for example, MyISAM table is altered to InnoDB
    SE and some FKs are added at the same time.
  */
  assert(!(new_db_type->flags & HTON_SUPPORTS_FOREIGN_KEYS) ||
         (new_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL));

  /*
    We also assume that we can't have non-atomic ALTER TABLE which
    will preserve any foreign keys (i.e. such ALTER TABLE can only
    drop all foreign keys on the table, or add new foreign keys to
    table which previously didn't have any).
  */
  assert(atomic_replace || alter_ctx.fk_count == 0);

  /*
    If both old and new SEs support atomic DDL then we have not stored
    new table definition in on-disk data-dictionary so far. It is time
    to do this now. However, before doing this we need to rename foreign
    keys in old table definition to temporary names to avoid conflicts
    with duplicate names.
  */
  if (atomic_replace) {
    if (alter_ctx.fk_count > 0 &&
        adjust_foreign_key_names_for_old_table_version(thd, alter_ctx.db,
                                                       backup_name))
      goto err_with_mdl;

    if (thd->dd_client()->store(non_dd_table_def.get())) goto err_with_mdl;

    // Safety, in-memory dd::Table is no longer totally correct.
    non_dd_table_def.reset();
  }

  // Rename the new table to the correct name.
  if (mysql_rename_table(
          thd, new_db_type, alter_ctx.new_db, alter_ctx.tmp_name, alter_ctx.db,
          alter_ctx.table_name, *new_schema, alter_ctx.new_db,
          alter_ctx.new_alias,
          (FN_FROM_IS_TMP |
           ((new_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL) ? NO_DD_COMMIT
                                                            : 0) |
           (alter_ctx.is_table_renamed() ? 0 : NO_FK_RENAME | NO_CC_RENAME))) ||
      ((new_db_type->flags & HTON_SUPPORTS_FOREIGN_KEYS) &&
       adjust_fks_for_complex_alter_table(thd, table_list, &alter_ctx,
                                          alter_info, new_db_type,
                                          &fk_invalidator)) ||
      /*
        Try commit changes if ALTER TABLE as whole is not atomic and we have
        not done this in the above mysql_rename_table() call.
      */
      (!atomic_replace && (new_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL) &&
       trans_intermediate_ddl_commit(thd, false))) {
    // Rename failed, delete the temporary table.
    if (!atomic_replace) {
      if (new_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL) {
        /*
          If ALTER TABLE as whole is not atomic and the above rename or
          FK changes have failed without cleaning up after themselves,
          we need to do this now.
        */
        (void)trans_intermediate_ddl_commit(thd, true);
      }

      /*
        In non-atomic mode situations when the SE has requested rollback
        should be handled already.
      */
      assert(!thd->transaction_rollback_request);

      (void)quick_rm_table(thd, new_db_type, alter_ctx.new_db,
                           alter_ctx.tmp_name, FN_IS_TMP);

      // Restore the backup of the original table to its original name.
      // If the operation fails, we need to retry it to avoid leaving
      // the dictionary inconsistent.
      //
      // This hack might become unnecessary once InnoDB stops acquiring
      // gap locks on DD tables (which might cause deadlocks).
      uint retries = 20;
      while (retries-- &&
             mysql_rename_table(
                 thd, old_db_type, alter_ctx.db, backup_name, alter_ctx.db,
                 backup_name, *schema, alter_ctx.db, alter_ctx.alias,
                 FN_FROM_IS_TMP | NO_FK_CHECKS | NO_FK_RENAME | NO_CC_RENAME))
        ;
    }
    goto err_with_mdl;
  }

  /*
    If ALTER TABLE is non-atomic and fails after this point it can add
    foreign keys and such addition won't be reverted. So we need to
    invalidate table objects for foreign key parents even on error.
  */
  if (!atomic_replace) invalidate_fk_parents_on_error = true;

  // Handle trigger name, check constraint names and histograms statistics.
  {
    dd::Table *backup_table = nullptr;
    dd::Table *new_dd_table = nullptr;
    if (thd->dd_client()->acquire_for_modification(alter_ctx.db, backup_name,
                                                   &backup_table) ||
        thd->dd_client()->acquire_for_modification(
            alter_ctx.new_db, alter_ctx.new_alias, &new_dd_table))
      goto err_with_mdl;
    assert(backup_table != nullptr && new_dd_table != nullptr);

    /*
      Check if this is an ALTER command that will cause histogram statistics to
      become invalid. If that is the case; remove the histogram statistics.

      This will take care of scenarios when COPY alter is used, but not INPLACE.
      Do this before the commit for non-transactional tables, because the
      new_dd_table is invalidated on commit.
    */
    if (alter_table_drop_histograms(thd, table_list, alter_info, create_info,
                                    columns, backup_table, new_dd_table))
      goto err_with_mdl; /* purecov: deadcode */

    bool update = (new_dd_table->check_constraints()->size() > 0);
    // Set mode for new_dd_table's check constraints.
    set_check_constraints_alter_mode(new_dd_table, alter_info);

    /*
      Check constraint names are unique per schema, we cannot create them while
      both table version exists. Adjust check constraint names in old table
      version.
    */
    if (adjust_check_constraint_names_for_old_table_version(thd, alter_ctx.db,
                                                            backup_table))
      goto err_with_mdl;

    // Reset check constraint's mode.
    reset_check_constraints_alter_mode(new_dd_table);

    /*
      Since trigger names have to be unique per schema, we cannot
      create them while both the old and the tmp version of the
      table exist.
    */
    if (backup_table->has_trigger()) {
      new_dd_table->copy_triggers(backup_table);
      backup_table->drop_all_triggers();
      update = true;
    }
    if (!is_checked_for_upgrade(*new_dd_table) &&
        is_checked_for_upgrade(*backup_table)) {
      new_dd_table->mark_as_checked_for_upgrade();
      update = true;
    }
    if (update) {
      if (thd->dd_client()->update(backup_table) ||
          thd->dd_client()->update(new_dd_table))
        goto err_with_mdl;

      /* Prevent intermediate commits to invoke commit order */
      Implicit_substatement_state_guard substatement_guard(thd);
      if (!atomic_replace && (trans_commit_stmt(thd) || trans_commit(thd)))
        goto err_with_mdl;
    }
  }

  // If the ALTER command was a rename, rename any existing histograms.
  if (alter_ctx.is_table_renamed() &&
      rename_histograms(thd, table_list->db, table_list->table_name, new_db,
                        new_name)) {
    goto err_with_mdl; /* purecov: deadcode */
  }

  // ALTER TABLE succeeded, delete the backup of the old table.
  if (quick_rm_table(thd, old_db_type, alter_ctx.db, backup_name,
                     FN_IS_TMP | (atomic_replace ? NO_DD_COMMIT : 0))) {
    /*
      The fact that deletion of the backup failed is not critical
      error, but still worth reporting as it might indicate serious
      problem with server.

      TODO: In !atomic_replace case we might need to do FK parents
            invalidation here. However currently our FKs are not
            even named correctly at this point, so we postpone
            fixing this issue until we solve FK naming problem.
    */
    goto err_with_mdl;
  }

end_inplace_noop:

  THD_STAGE_INFO(thd, stage_end);

  DBUG_EXECUTE_IF("sleep_alter_before_main_binlog", my_sleep(6000000););
  DEBUG_SYNC(thd, "alter_table_before_main_binlog");

  ha_binlog_log_query(thd, create_info->db_type, LOGCOM_ALTER_TABLE,
                      thd->query().str, thd->query().length, alter_ctx.db,
                      alter_ctx.table_name);

  assert(!(mysql_bin_log.is_open() &&
           thd->is_current_stmt_binlog_format_row() &&
           (create_info->options & HA_LEX_CREATE_TMP_TABLE)));

  /*
    If this is no-op ALTER TABLE we don't have transaction started.
    We can't use binlog's trx cache in this case as it requires active
    transaction with valid XID.
  */
  if (write_bin_log(thd, true, thd->query().str, thd->query().length,
                    atomic_replace && !is_noop))
    goto err_with_mdl;

  if (!is_noop) {
    Uncommitted_tables_guard uncommitted_tables(thd);

    uncommitted_tables.add_table(table_list);

    if (update_referencing_views_metadata(thd, table_list, new_db, new_name,
                                          !atomic_replace, &uncommitted_tables))
      goto err_with_mdl;

    if (alter_ctx.is_table_renamed())
      tdc_remove_table(thd, TDC_RT_REMOVE_ALL, alter_ctx.new_db,
                       alter_ctx.new_name, false);
  }

  // Commit if it was not done before in order to be able to reopen tables.
  if (atomic_replace && (trans_commit_stmt(thd) || trans_commit_implicit(thd)))
    goto err_with_mdl;

  if ((new_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL) && new_db_type->post_ddl)
    new_db_type->post_ddl(thd);
  if ((old_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL) && old_db_type->post_ddl)
    old_db_type->post_ddl(thd);

#ifndef WORKAROUND_TO_BE_REMOVED_BY_WL6049
  {
    Table_ref table_list_reopen(alter_ctx.new_db, alter_ctx.new_name,
                                alter_ctx.new_alias, TL_READ);
    table_list_reopen.mdl_request.ticket =
        alter_ctx.is_table_renamed() ? alter_ctx.target_mdl_request.ticket
                                     : mdl_ticket;

    Open_table_context ot_ctx(thd, MYSQL_OPEN_REOPEN);

    if (open_table(thd, &table_list_reopen, &ot_ctx)) return true;

    assert(table_list_reopen.table == thd->open_tables);
    close_thread_table(thd, &thd->open_tables);
  }
#endif

end_inplace:

  fk_invalidator.invalidate(thd);

  if (alter_ctx.is_table_renamed())
    thd->locked_tables_list.rename_locked_table(
        table_list, alter_ctx.new_db, alter_ctx.new_name,
        alter_ctx.target_mdl_request.ticket);

  {
    bool reopen_error = thd->locked_tables_list.reopen_tables(thd);

    if (thd->locked_tables_mode == LTM_LOCK_TABLES ||
        thd->locked_tables_mode == LTM_PRELOCKED_UNDER_LOCK_TABLES) {
      if (alter_ctx.is_table_renamed()) {
        /*
          Release metadata lock on old table name and keep the lock
          on the new one. We have to ignore reopen_error in this case
          as we will mess up FK invariants for LOCK TABLES otherwise.
        */
        thd->mdl_context.release_all_locks_for_name(mdl_ticket);
        thd->mdl_context.set_lock_duration(alter_ctx.target_mdl_request.ticket,
                                           MDL_EXPLICIT);
        alter_ctx.target_mdl_request.ticket->downgrade_lock(
            MDL_SHARED_NO_READ_WRITE);
        if (alter_ctx.is_database_changed())
          thd->mdl_context.set_lock_duration(
              alter_ctx.target_db_mdl_request.ticket, MDL_EXPLICIT);
      } else
        mdl_ticket->downgrade_lock(MDL_SHARED_NO_READ_WRITE);
    }

    if (reopen_error) return true;
  }

end_temporary:
  snprintf(alter_ctx.tmp_name, sizeof(alter_ctx.tmp_name),
           ER_THD(thd, ER_INSERT_INFO), (long)(copied + deleted), (long)deleted,
           (long)thd->get_stmt_da()->current_statement_cond_count());
  my_ok(thd, copied + deleted, 0L, alter_ctx.tmp_name);
  return false;

err_new_table_cleanup:
  if (create_info->options & HA_LEX_CREATE_TMP_TABLE) {
    if (new_table)
      close_temporary_table(thd, new_table, true, true);
    else if (!no_ha_table)
      rm_temporary_table(thd, new_db_type, alter_ctx.get_tmp_path(),
                         non_dd_table_def.get());
  } else {
    /* close_temporary_table() frees the new_table pointer. */
    if (new_table) close_temporary_table(thd, new_table, true, false);

    if (!(new_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL)) {
      if (no_ha_table)  // Only remove from DD.
      {
        dd::cache::Dictionary_client::Auto_releaser releaser_3(
            thd->dd_client());
        const dd::Table *drop_table_def = nullptr;
        if (!thd->dd_client()->acquire(alter_ctx.new_db, alter_ctx.tmp_name,
                                       &drop_table_def)) {
          assert(drop_table_def != nullptr);
          bool result = dd::drop_table(thd, alter_ctx.new_db,
                                       alter_ctx.tmp_name, *drop_table_def);
          (void)trans_intermediate_ddl_commit(thd, result);
        }
      } else  // Remove from both DD and SE.
        (void)quick_rm_table(thd, new_db_type, alter_ctx.new_db,
                             alter_ctx.tmp_name, FN_IS_TMP);
    } else {
      trans_rollback_stmt(thd);
      /*
        Full rollback in case we have THD::transaction_rollback_request
        and to synchronize DD state in cache and on disk (as statement
        rollback doesn't clear DD cache of modified uncommitted objects).
      */
      trans_rollback(thd);
    }
    if ((new_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL) &&
        new_db_type->post_ddl)
      new_db_type->post_ddl(thd);
  }

  if (alter_ctx.error_if_not_empty &
      Alter_table_ctx::GEOMETRY_WITHOUT_DEFAULT) {
    my_error(ER_INVALID_USE_OF_NULL, MYF(0));
  }

  /*
    No default value was provided for a DATE/DATETIME field, the
    current sql_mode doesn't allow the '0000-00-00' value and
    the table to be altered isn't empty.
    Report error here. Ignore error checkin for push_zero_date_warning()
    as we return true right below.
  */
  if ((alter_ctx.error_if_not_empty &
       Alter_table_ctx::DATETIME_WITHOUT_DEFAULT) &&
      (thd->variables.sql_mode & MODE_NO_ZERO_DATE) &&
      thd->get_stmt_da()->current_row_for_condition()) {
    (void)push_zero_date_warning(thd, alter_ctx.datetime_field);
  }
  return true;

err_with_mdl:
  /*
    An error happened while we were holding exclusive name metadata lock
    on table being altered. Before releasing locks we need to rollback
    changes to the data-dictionary, storage angine and binary log (if
    they were not committed earlier) and execute post DDL hooks.
    We also try to reopen old version of the table under LOCK TABLES
    if possible.
  */

  trans_rollback_stmt(thd);
  /*
    Full rollback in case we have THD::transaction_rollback_request
    and to synchronize DD state in cache and on disk (as statement
    rollback doesn't clear DD cache of modified uncommitted objects).
  */
  trans_rollback(thd);
  if ((new_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL) && new_db_type->post_ddl)
    new_db_type->post_ddl(thd);
  if ((old_db_type->flags & HTON_SUPPORTS_ATOMIC_DDL) && old_db_type->post_ddl)
    old_db_type->post_ddl(thd);

  if (atomic_replace) {
    /*
      If both old and new storage engines support atomic DDL all changes
      were reverted at this point. So we can safely try to reopen table
      under old name.
    */
  } else {
    /*
      If ALTER TABLE ... RENAME ... ALGORITHM=COPY is non-atomic we can't
      be sure that rename step was reverted, so we simply remove table
      from the list of locked tables.
    */
    if (alter_ctx.is_table_renamed())
      thd->locked_tables_list.unlink_all_closed_tables(thd, nullptr, 0);
  }

  /*
    ALTER TABLE which changes table storage engine from MyISAM to InnoDB
    and adds foreign keys at the same time can fail after installing
    new table version. In this case we still need to invalidate table
    objects for parent tables to avoid creating discrepancy between
    data-dictionary and cache contents.
  */
  if (invalidate_fk_parents_on_error) fk_invalidator.invalidate(thd);

  (void)thd->locked_tables_list.reopen_tables(thd);

  if ((thd->locked_tables_mode == LTM_LOCK_TABLES ||
       thd->locked_tables_mode == LTM_PRELOCKED_UNDER_LOCK_TABLES)) {
    /*
      Non-atomic ALTER TABLE ... RENAME ... ALGORITHM=COPY can add
      foreign keys if at the same time SE is changed from, e.g.,
      MyISAM to InnoDB. Since releasing metadata locks on old or new
      table name can break FK invariants for LOCK TABLES in various
      scenarios we keep both of them.
    */
    if (!atomic_replace && alter_ctx.is_table_renamed()) {
      thd->mdl_context.set_lock_duration(alter_ctx.target_mdl_request.ticket,
                                         MDL_EXPLICIT);
      alter_ctx.target_mdl_request.ticket->downgrade_lock(
          MDL_SHARED_NO_READ_WRITE);
      if (alter_ctx.is_database_changed())
        thd->mdl_context.set_lock_duration(
            alter_ctx.target_db_mdl_request.ticket, MDL_EXPLICIT);
    }
    mdl_ticket->downgrade_lock(MDL_SHARED_NO_READ_WRITE);
  }

  return true;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: check_fk_children_after_parent_def_change
      to check_fk_children_after_parent_def_change().
    */
    if (adjust_fk_child_after_parent_def_change(
            thd, false /* Update FKs. */, check_charsets, schema_name,
            table_name, parent_table_db, parent_table_name, hton,
            parent_table_def, parent_alter_info, nullptr))
      return true;

    if (invalidate_tdc) {
      mysql_ha_flush_table(thd, schema_name, table_name);
      close_all_tables_for_name(thd, schema_name, table_name, false);
    }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: adjust_fks_for_complex_alter_table not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: adjust_fks_for_complex_alter_table not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: adjust_fks_for_complex_alter_table not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: adjust_fks_for_complex_alter_table not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: adjust_fks_for_complex_alter_table not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: fk_column_change_type not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: fk_column_change_type not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: fk_column_change_type not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_table.cc
Function: fk_column_change_type not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_thd_internal_api.cc
Function: thd_binlog_format
int thd_binlog_format(const THD *thd) {
  if (mysql_bin_log.is_open() && (thd->variables.option_bits & OPTION_BIN_LOG))
    return (int)thd->variables.binlog_format;
  else
    return BINLOG_FORMAT_UNSPEC;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_thd_internal_api.cc
Function: thd_is_dd_update_stmt
bool thd_is_dd_update_stmt(const THD *thd) {
  assert(thd != nullptr);

  /*
    OPTION_DD_UPDATE_CONTEXT flag is set when thread switches context to
    update data dictionary tables for the
      * DDL statements.
      * Administration statements as ANALYZE TABLE.
      * Event threads for next activation time of a event and to update status.
      * SDI import.
      ...
    So verifying OPTION_DD_UPDATE_CONTEXT flag value to check if thread is
    updating the data dictionary tables.
  */
  return (thd->variables.option_bits & OPTION_DD_UPDATE_CONTEXT);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_thd_api.cc
Function: thd_test_options
long long thd_test_options(const MYSQL_THD thd, long long test_options) {
  return thd->variables.option_bits & test_options;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_thd_api.cc
Function: thd_allow_batch
int thd_allow_batch(MYSQL_THD thd) {
  if ((thd->variables.option_bits & OPTION_ALLOW_BATCH) ||
      (thd->slave_thread && opt_replica_allow_batching))
    return 1;
  return 0;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/dict/dict0dd.cc
Function: dd_table_load_fk
dberr_t dd_table_load_fk(dd::cache::Dictionary_client *client,
                         const char *tbl_name, const char **col_names,
                         dict_table_t *m_table, const dd::Table *dd_table,
                         THD *thd, bool dict_locked, bool check_charsets,
                         dict_names_t *fk_tables) {
  dberr_t err = DB_SUCCESS;
  dict_err_ignore_t ignore_err = DICT_ERR_IGNORE_NONE;

  /* Check whether FOREIGN_KEY_CHECKS is set to 0. If so, the table
  can be opened even if some FK indexes are missing. If not, the table
  can't be opened in the same situation */
  if (thd_test_options(thd, OPTION_NO_FOREIGN_KEY_CHECKS)) {
    ignore_err = DICT_ERR_IGNORE_FK_NOKEY;
  }

  err = dd_table_load_fk_from_dd(m_table, dd_table, col_names, ignore_err,
                                 dict_locked);

  if (err != DB_SUCCESS) {
    return err;
  }

  if (dict_locked) {
    dict_sys_mutex_exit();
  }

  DBUG_EXECUTE_IF("enable_stack_overrun_post_alter_commit",
                  { DBUG_SET("+d,simulate_stack_overrun"); });
  err = dd_table_check_for_child(client, tbl_name, col_names, m_table,
                                 check_charsets, ignore_err, fk_tables);
  DBUG_EXECUTE_IF("enable_stack_overrun_post_alter_commit",
                  { DBUG_SET("-d,simulate_stack_overrun"); });

  if (dict_locked) {
    dict_sys_mutex_enter();
  }

  return err;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_tmp_table.cc
Function: create_tmp_table_field_tmp_name not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_tmp_table.cc
Function: create_tmp_table_field_tmp_name not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_tmp_table.cc
Function: create_tmp_table_field_tmp_name not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_tmp_table.cc
Function: create_tmp_table_field_tmp_name not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_tmp_table.cc
Function: create_tmp_table_field_tmp_name not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_tmp_table.cc
Function: create_tmp_table_field_tmp_name not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_tmp_table.cc
Function: create_tmp_table_field_tmp_name not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_tmp_table.cc
Function: create_tmp_table_field_tmp_name not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_tmp_table.cc
Function: create_tmp_table_field_tmp_name not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_union.cc
Function: Query_expression::optimize
bool Query_expression::optimize(THD *thd, TABLE *materialize_destination,
                                bool create_iterators,
                                bool finalize_access_paths) {
  DBUG_TRACE;

  if (!finalize_access_paths) {
    assert(!create_iterators);
  }

  assert(is_prepared() && !is_optimized());

  Change_current_query_block save_query_block(thd);

  ha_rows estimated_rowcount = 0;
  double estimated_cost = 0.0;

  if (query_result() != nullptr) query_result()->estimated_rowcount = 0;

  for (Query_block *query_block = first_query_block(); query_block != nullptr;
       query_block = query_block->next_query_block()) {
    thd->lex->set_current_query_block(query_block);

    // LIMIT is required for optimization
    if (set_limit(thd, query_block)) return true; /* purecov: inspected */

    if (query_block->optimize(thd, finalize_access_paths)) return true;

    /*
      Accumulate estimated number of rows.
      1. Implicitly grouped query has one row (with HAVING it has zero or one
         rows).
      2. If GROUP BY clause is optimized away because it was a constant then
         query produces at most one row.
     */
    if (contributes_to_rowcount_estimate(query_block))
      estimated_rowcount += (query_block->is_implicitly_grouped() ||
                             query_block->join->group_optimized_away)
                                ? 1
                                : query_block->join->best_rowcount;

    estimated_cost += query_block->join->best_read;

    // Table_ref::fetch_number_of_rows() expects to get the number of rows
    // from all earlier query blocks from the query result, so we need to update
    // it as we go. In particular, this is used when optimizing a recursive
    // SELECT in a CTE, so that it knows how many rows the non-recursive query
    // blocks will produce.
    //
    // TODO(sgunders): Communicate this in a different way when the query result
    // goes away.
    if (query_result() != nullptr) {
      query_result()->estimated_rowcount = estimated_rowcount;
      query_result()->estimated_cost = estimated_cost;
    }
  }

  if (!is_simple() && query_term()->open_result_tables(thd, 0)) return true;

  if ((uncacheable & UNCACHEABLE_DEPENDENT) && estimated_rowcount <= 1) {
    /*
      This depends on outer references, so optimization cannot assume that all
      executions will always produce the same row. So, increase the counter to
      prevent that this table is replaced with a constant.
      Not testing all bits of "uncacheable", as if derived table sets user
      vars (UNCACHEABLE_SIDEEFFECT) the logic above doesn't apply.
    */
    estimated_rowcount = PLACEHOLDER_TABLE_ROW_ESTIMATE;
  }

  if (!is_simple()) {
    if (optimize_set_operand(thd, this, query_term())) return true;
    if (set_limit(thd, query_term()->query_block())) return true;
    if (!is_union()) query_result()->set_limit(select_limit_cnt);
  }

  query_result()->estimated_rowcount = estimated_rowcount;
  query_result()->estimated_cost = estimated_cost;

  // If the caller has asked for materialization directly into a table of its
  // own, and we can do so, do an unfinished materialization (see the comment
  // on this function for more details).
  if (thd->lex->m_sql_cmd != nullptr &&
      thd->lex->m_sql_cmd->using_secondary_storage_engine()) {
    // Not supported when using secondary storage engine.
    create_access_paths(thd);
  } else if (estimated_rowcount <= 1 ||
             use_iterator(materialize_destination, query_term())) {
    // Don't do it for const tables, as for those, optimize_derived() wants to
    // run the query during optimization, and thus needs an iterator.
    //
    // Do note that JOIN::extract_func_dependent_tables() can want to read from
    // the derived table during the optimization phase even if it has
    // estimated_rowcount larger than one (e.g., because it understands it can
    // get only one row due to a unique index), but will detect that the table
    // has not been created, and treat the the lookup as non-const.
    create_access_paths(thd);
  } else if (materialize_destination != nullptr &&
             can_materialize_directly_into_result()) {
    assert(!is_simple());
    const bool calc_found_rows =
        (first_query_block()->active_options() & OPTION_FOUND_ROWS);
    m_query_blocks_to_materialize = set_operation()->setup_materialize_set_op(
        thd, materialize_destination,
        /*union_distinct_only=*/false, calc_found_rows);
  } else {
    // Recursive CTEs expect to see the rows in the result table immediately
    // after writing them.
    assert(!is_recursive());
    create_access_paths(thd);
  }

  set_optimized();  // All query blocks optimized, update the state

  if (item != nullptr) {
    // If we're part of an IN subquery, the containing engine may want to
    // add its own iterators on top, e.g. to materialize us.
    //
    // TODO(sgunders): See if we can do away with the engine concept
    // altogether, now that there's much less execution logic in them.
    assert(!unfinished_materialization());
    item->create_iterators(thd);
    if (m_root_access_path == nullptr) {
      return false;
    }
  }

  if (create_iterators && IteratorsAreNeeded(thd, m_root_access_path)) {
    JOIN *join = query_term()->query_block()->join;

    DBUG_EXECUTE_IF(
        "ast", Query_term *qn = m_query_term;
        DBUG_PRINT("ast", ("\n%s", thd->query().str)); if (qn) {
          std::ostringstream buf;
          qn->debugPrint(0, buf);
          DBUG_PRINT("ast", ("\n%s", buf.str().c_str()));
        });

    DBUG_EXECUTE_IF(
        "ast", bool is_root_of_join = (join != nullptr); DBUG_PRINT(
            "ast", ("Query plan:\n%s\n",
                    PrintQueryPlan(0, m_root_access_path, join, is_root_of_join)
                        .c_str())););

    m_root_iterator = CreateIteratorFromAccessPath(
        thd, m_root_access_path, join, /*eligible_for_batch_mode=*/true);
    if (m_root_iterator == nullptr) {
      return true;
    }

    if (thd->lex->using_hypergraph_optimizer()) {
      if (finalize_full_text_functions(thd, this)) {
        return true;
      }
    }

    if (false) {
      // This can be useful during debugging.
      // TODO(sgunders): Consider adding the SET DEBUG force-subplan line here,
      // like we have on EXPLAIN FORMAT=tree if subplan_tokens is active.
      bool is_root_of_join = (join != nullptr);
      fprintf(
          stderr, "Query plan:\n%s\n",
          PrintQueryPlan(0, m_root_access_path, join, is_root_of_join).c_str());
    }
  }

  // When done with the outermost query expression, and if max_join_size is in
  // effect, estimate the total number of row accesses in the query, and error
  // out if it exceeds max_join_size.
  if (outer_query_block() == nullptr &&
      !Overlaps(thd->variables.option_bits, OPTION_BIG_SELECTS) &&
      !thd->lex->is_explain() &&
      EstimateRowAccesses(m_root_access_path, /*num_evaluations=*/1.0,
                          std::numeric_limits<double>::infinity()) >
          static_cast<double>(thd->variables.max_join_size)) {
    my_error(ER_TOO_BIG_SELECT, MYF(0));
    return true;
  }

  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_update.cc
Function: Sql_cmd_update::update_single_table
bool Sql_cmd_update::update_single_table(THD *thd) {
  DBUG_TRACE;

  myf error_flags = MYF(0); /**< Flag for fatal errors */
  /*
    Most recent handler error
    =  1: Some non-handler error
    =  0: Success
    = -1: No more rows to process, or reached limit
  */
  int error = 0;

  Query_block *const query_block = lex->query_block;
  Query_expression *const unit = lex->unit;
  Table_ref *const table_list = query_block->get_table_list();
  Table_ref *const update_table_ref = table_list->updatable_base_table();
  TABLE *const table = update_table_ref->table;

  assert(table->pos_in_table_list == update_table_ref);

  const bool transactional_table = table->file->has_transactions();

  const bool has_update_triggers =
      table->triggers && table->triggers->has_update_triggers();

  const bool has_after_triggers =
      has_update_triggers &&
      table->triggers->has_triggers(TRG_EVENT_UPDATE, TRG_ACTION_AFTER);

  Opt_trace_context *const trace = &thd->opt_trace;

  if (unit->set_limit(thd, unit->global_parameters()))
    return true; /* purecov: inspected */

  ha_rows limit = unit->select_limit_cnt;
  const bool using_limit = limit != HA_POS_ERROR;

  if (limit == 0 && thd->lex->is_explain()) {
    Modification_plan plan(thd, MT_UPDATE, table, "LIMIT is zero", true, 0);
    bool err = explain_single_table_modification(thd, thd, &plan, query_block);
    return err;
  }

  // Used to track whether there are no rows that need to be read
  bool no_rows = limit == 0;

  THD::killed_state killed_status = THD::NOT_KILLED;
  assert(CountHiddenFields(query_block->fields) == 0);
  COPY_INFO update(COPY_INFO::UPDATE_OPERATION, &query_block->fields,
                   update_value_list);
  if (update.add_function_default_columns(table, table->write_set)) return true;

  const bool safe_update = thd->variables.option_bits & OPTION_SAFE_UPDATES;

  assert(!(table->all_partitions_pruned_away || m_empty_query));

  Item *conds = nullptr;
  ORDER *order = query_block->order_list.first;
  if (!no_rows && query_block->get_optimizable_conditions(thd, &conds, nullptr))
    return true; /* purecov: inspected */

  /*
    See if we can substitute expressions with equivalent generated
    columns in the WHERE and ORDER BY clauses of the UPDATE statement.
    It is unclear if this is best to do before or after the other
    substitutions performed by substitute_for_best_equal_field(). Do
    it here for now, to keep it consistent with how multi-table
    updates are optimized in JOIN::optimize().
  */
  if (conds || order)
    static_cast<void>(substitute_gc(thd, query_block, conds, nullptr, order));

  if (conds != nullptr) {
    if (table_list->check_option) {
      // See the explanation in multi-table UPDATE code path
      // (Query_result_update::prepare).
      table_list->check_option->walk(&Item::disable_constant_propagation,
                                     enum_walk::POSTFIX, nullptr);
    }
    COND_EQUAL *cond_equal = nullptr;
    Item::cond_result result;
    if (optimize_cond(thd, &conds, &cond_equal,
                      query_block->m_current_table_nest, &result))
      return true;

    if (result == Item::COND_FALSE) {
      no_rows = true;  // Impossible WHERE
      if (thd->lex->is_explain()) {
        Modification_plan plan(thd, MT_UPDATE, table, "Impossible WHERE", true,
                               0);
        bool err =
            explain_single_table_modification(thd, thd, &plan, query_block);
        return err;
      }
    }
    if (conds != nullptr) {
      conds = substitute_for_best_equal_field(thd, conds, cond_equal, nullptr);
      if (conds == nullptr) return true;

      conds->update_used_tables();
    }
  }

  /*
    Also try a second time after locking, to prune when subqueries and
    stored programs can be evaluated.
  */
  if (table->part_info && !no_rows) {
    if (prune_partitions(thd, table, query_block, conds))
      return true; /* purecov: inspected */
    if (table->all_partitions_pruned_away) {
      no_rows = true;

      if (thd->lex->is_explain()) {
        Modification_plan plan(thd, MT_UPDATE, table,
                               "No matching rows after partition pruning", true,
                               0);
        bool err =
            explain_single_table_modification(thd, thd, &plan, query_block);
        return err;
      }
      my_ok(thd);
      return false;
    }
  }
  // Initialize the cost model that will be used for this table
  table->init_cost_model(thd->cost_model());

  /* Update the table->file->stats.records number */
  table->file->info(HA_STATUS_VARIABLE | HA_STATUS_NO_LOCK);

  table->mark_columns_needed_for_update(thd,
                                        false /*mark_binlog_columns=false*/);

  AccessPath *range_scan = nullptr;
  join_type type = JT_UNKNOWN;

  auto cleanup = create_scope_guard([&range_scan, table] {
    destroy(range_scan);
    table->set_keyread(false);
    table->file->ha_index_or_rnd_end();
    free_io_cache(table);
    filesort_free_buffers(table, true);
  });

  if (conds &&
      thd->optimizer_switch_flag(OPTIMIZER_SWITCH_ENGINE_CONDITION_PUSHDOWN)) {
    table->file->cond_push(conds);
  }

  {  // Enter scope for optimizer trace wrapper
    Opt_trace_object wrapper(&thd->opt_trace);
    wrapper.add_utf8_table(update_table_ref);

    if (!no_rows && conds != nullptr) {
      Key_map keys_to_use(Key_map::ALL_BITS), needed_reg_dummy;
      MEM_ROOT temp_mem_root(key_memory_test_quick_select_exec,
                             thd->variables.range_alloc_block_size);
      no_rows = test_quick_select(
                    thd, thd->mem_root, &temp_mem_root, keys_to_use, 0, 0,
                    limit, safe_update, ORDER_NOT_RELEVANT, table,
                    /*skip_records_in_range=*/false, conds, &needed_reg_dummy,
                    table->force_index, query_block, &range_scan) < 0;
      if (thd->is_error()) return true;
    }
    if (no_rows) {
      if (thd->lex->is_explain()) {
        Modification_plan plan(thd, MT_UPDATE, table, "Impossible WHERE", true,
                               0);
        bool err =
            explain_single_table_modification(thd, thd, &plan, query_block);
        return err;
      }

      char buff[MYSQL_ERRMSG_SIZE];
      snprintf(buff, sizeof(buff), ER_THD(thd, ER_UPDATE_INFO), 0L, 0L,
               (long)thd->get_stmt_da()->current_statement_cond_count());
      my_ok(thd, 0, 0, buff);

      DBUG_PRINT("info", ("0 records updated"));
      return false;
    }
  }  // Ends scope for optimizer trace wrapper

  /* If running in safe sql mode, don't allow updates without keys */
  if (table->quick_keys.is_clear_all()) {
    thd->server_status |= SERVER_QUERY_NO_INDEX_USED;

    /*
      No safe update error will be returned if:
      1) Statement is an EXPLAIN OR
      2) LIMIT is present.

      Append the first warning (if any) to the error message. Allows the user
      to understand why index access couldn't be chosen.
    */
    if (!lex->is_explain() && safe_update && !using_limit) {
      my_error(ER_UPDATE_WITHOUT_KEY_IN_SAFE_MODE, MYF(0),
               thd->get_stmt_da()->get_first_condition_message());
      return true;
    }
  }
  if (query_block->has_ft_funcs() && init_ftfuncs(thd, query_block))
    return true; /* purecov: inspected */

  if (conds != nullptr) table->update_const_key_parts(conds);

  order = simple_remove_const(order, conds);
  bool need_sort;
  bool reverse = false;
  bool used_key_is_modified = false;
  uint used_index;
  {
    ORDER_with_src order_src(order, ESC_ORDER_BY, /*const_optimized=*/true);
    used_index = get_index_for_order(&order_src, table, limit, range_scan,
                                     &need_sort, &reverse);
    if (range_scan != nullptr) {
      // May have been changed by get_index_for_order().
      type = calc_join_type(range_scan);
    }
  }
  if (need_sort) {  // Assign table scan index to check below for modified key
                    // fields:
    used_index = table->file->key_used_on_scan;
  }
  if (used_index != MAX_KEY) {  // Check if we are modifying a key that we are
                                // used to search with:
    used_key_is_modified = is_key_used(table, used_index, table->write_set);
  } else if (range_scan) {
    /*
      select->range_scan != NULL and used_index == MAX_KEY happens for index
      merge and should be handled in a different way.
    */
    used_key_is_modified = (!unique_key_range(range_scan) &&
                            uses_index_on_fields(range_scan, table->write_set));
  }

  if (table->part_info)
    used_key_is_modified |= table->part_info->num_partitions_used() > 1 &&
                            partition_key_modified(table, table->write_set);

  const bool using_filesort = order && need_sort;

  table->mark_columns_per_binlog_row_image(thd);

  if (prepare_partial_update(trace, query_block->fields, *update_value_list))
    return true; /* purecov: inspected */

  if (table->setup_partial_update()) return true; /* purecov: inspected */

  ha_rows updated_rows = 0;
  ha_rows found_rows = 0;

  unique_ptr_destroy_only<Filesort> fsort;
  unique_ptr_destroy_only<RowIterator> iterator;

  {  // Start of scope for Modification_plan
    ha_rows rows;
    if (range_scan)
      rows = range_scan->num_output_rows();
    else if (!conds && !need_sort && limit != HA_POS_ERROR)
      rows = limit;
    else {
      update_table_ref->fetch_number_of_rows();
      rows = table->file->stats.records;
    }
    DEBUG_SYNC(thd, "before_single_update");
    Modification_plan plan(thd, MT_UPDATE, table, type, range_scan, conds,
                           used_index, limit,
                           (!using_filesort && (used_key_is_modified || order)),
                           using_filesort, used_key_is_modified, rows);
    DEBUG_SYNC(thd, "planned_single_update");
    if (thd->lex->is_explain()) {
      bool err =
          explain_single_table_modification(thd, thd, &plan, query_block);
      return err;
    }

    if (thd->lex->is_ignore()) table->file->ha_extra(HA_EXTRA_IGNORE_DUP_KEY);

    if (used_key_is_modified || order) {
      /*
        We can't update table directly;  We must first search after all
        matching rows before updating the table!
      */

      /* note: We avoid sorting if we sort on the used index */
      if (using_filesort) {
        /*
          Doing an ORDER BY;  Let filesort find and sort the rows we are going
          to update
          NOTE: filesort will call table->prepare_for_position()
        */
        JOIN join(thd, query_block);  // Only for holding examined_rows.
        AccessPath *path = create_table_access_path(
            thd, table, range_scan, /*table_ref=*/nullptr,
            /*position=*/nullptr, /*count_examined_rows=*/true);

        if (conds != nullptr) {
          path = NewFilterAccessPath(thd, path, conds);
        }

        // Force filesort to sort by position.
        fsort.reset(new (thd->mem_root) Filesort(
            thd, {table}, /*keep_buffers=*/false, order, limit,
            /*remove_duplicates=*/false,
            /*force_sort_rowids=*/true, /*unwrap_rollup=*/false));
        path = NewSortAccessPath(thd, path, fsort.get(), order,
                                 /*count_examined_rows=*/false);
        iterator = CreateIteratorFromAccessPath(
            thd, path, &join, /*eligible_for_batch_mode=*/true);
        // Prevent cleanup in JOIN::destroy() and in the cleanup condition
        // guard, to avoid double-destroy of the SortingIterator.
        table->sorting_iterator = nullptr;

        if (iterator == nullptr || iterator->Init()) return true;
        thd->inc_examined_row_count(join.examined_rows);

        /*
          Filesort has already found and selected the rows we want to update,
          so we don't need the where clause
        */
        destroy(range_scan);
        range_scan = nullptr;
        conds = nullptr;
      } else {
        /*
          We are doing a search on a key that is updated. In this case
          we go through the matching rows, save a pointer to them and
          update these in a separate loop based on the pointer. In the end,
          we get a result file that looks exactly like what filesort uses
          internally, which allows us to read from it
          using SortFileIndirectIterator.

          TODO: Find something less ugly.
         */
        Key_map covering_keys_for_cond;  // @todo - move this
        if (used_index < MAX_KEY && covering_keys_for_cond.is_set(used_index))
          table->set_keyread(true);

        table->prepare_for_position();
        table->file->try_semi_consistent_read(true);
        auto end_semi_consistent_read = create_scope_guard(
            [table] { table->file->try_semi_consistent_read(false); });

        /*
          When we get here, we have one of the following options:
          A. used_index == MAX_KEY
          This means we should use full table scan, and start it with
          init_read_record call
          B. used_index != MAX_KEY
          B.1 quick select is used, start the scan with init_read_record
          B.2 quick select is not used, this is full index scan (with LIMIT)
          Full index scan must be started with init_read_record_idx
        */

        AccessPath *path;
        if (used_index == MAX_KEY || range_scan) {
          path = create_table_access_path(thd, table, range_scan,
                                          /*table_ref=*/nullptr,
                                          /*position=*/nullptr,
                                          /*count_examined_rows=*/false);
        } else {
          empty_record(table);
          path = NewIndexScanAccessPath(thd, table, used_index,
                                        /*use_order=*/true, reverse,
                                        /*count_examined_rows=*/false);
        }

        iterator = CreateIteratorFromAccessPath(
            thd, path, /*join=*/nullptr, /*eligible_for_batch_mode=*/true);
        // Prevent cleanup in JOIN::destroy() and in the cleanup condition
        // guard, to avoid double-destroy of the SortingIterator.
        table->sorting_iterator = nullptr;

        if (iterator == nullptr || iterator->Init()) {
          return true;
        }

        THD_STAGE_INFO(thd, stage_searching_rows_for_update);
        ha_rows tmp_limit = limit;

        IO_CACHE *tempfile =
            (IO_CACHE *)my_malloc(key_memory_TABLE_sort_io_cache,
                                  sizeof(IO_CACHE), MYF(MY_FAE | MY_ZEROFILL));

        if (open_cached_file(tempfile, mysql_tmpdir, TEMP_PREFIX,
                             DISK_BUFFER_SIZE, MYF(MY_WME))) {
          my_free(tempfile);
          return true;
        }

        while (!(error = iterator->Read()) && !thd->killed) {
          assert(!thd->is_error());
          thd->inc_examined_row_count(1);

          if (conds != nullptr) {
            const bool skip_record = conds->val_int() == 0;
            if (thd->is_error()) {
              error = 1;
              /*
                Don't try unlocking the row if skip_record reported an error
                since in this case the transaction might have been rolled back
                already.
              */
              break;
            }
            if (skip_record) {
              table->file->unlock_row();
              continue;
            }
          }
          if (table->file->was_semi_consistent_read())
            continue; /* repeat the read of the same row if it still exists */

          table->file->position(table->record[0]);
          if (my_b_write(tempfile, table->file->ref, table->file->ref_length)) {
            error = 1; /* purecov: inspected */
            break;     /* purecov: inspected */
          }
          if (!--limit && using_limit) {
            error = -1;
            break;
          }
        }

        if (thd->killed && !error)  // Aborted
          error = 1;                /* purecov: inspected */
        limit = tmp_limit;
        end_semi_consistent_read.rollback();
        if (used_index < MAX_KEY && covering_keys_for_cond.is_set(used_index))
          table->set_keyread(false);
        table->file->ha_index_or_rnd_end();
        iterator.reset();

        // Change reader to use tempfile
        if (reinit_io_cache(tempfile, READ_CACHE, 0L, false, false))
          error = 1; /* purecov: inspected */

        if (error >= 0) {
          close_cached_file(tempfile);
          my_free(tempfile);
          return error > 0;
        }

        iterator = NewIterator<SortFileIndirectIterator>(
            thd, thd->mem_root, Mem_root_array<TABLE *>{table}, tempfile,
            /*ignore_not_found_rows=*/false, /*has_null_flags=*/false,
            /*examined_rows=*/nullptr);
        if (iterator->Init()) return true;

        destroy(range_scan);
        range_scan = nullptr;
        conds = nullptr;
      }
    } else {
      // No ORDER BY or updated key underway, so we can use a regular read.
      iterator =
          init_table_iterator(thd, table, range_scan,
                              /*table_ref=*/nullptr, /*position=*/nullptr,
                              /*ignore_not_found_rows=*/false,
                              /*count_examined_rows=*/false);
      if (iterator == nullptr) return true; /* purecov: inspected */
    }

    table->file->try_semi_consistent_read(true);
    auto end_semi_consistent_read = create_scope_guard(
        [table] { table->file->try_semi_consistent_read(false); });

    /*
      Generate an error (in TRADITIONAL mode) or warning
      when trying to set a NOT NULL field to NULL.
    */
    thd->check_for_truncated_fields = CHECK_FIELD_WARN;
    thd->num_truncated_fields = 0L;
    THD_STAGE_INFO(thd, stage_updating);

    bool will_batch;
    /// read_removal is only used by NDB storage engine
    bool read_removal = false;

    if (has_after_triggers) {
      /*
        The table has AFTER UPDATE triggers that might access to subject
        table and therefore might need update to be done immediately.
        So we turn-off the batching.
      */
      (void)table->file->ha_extra(HA_EXTRA_UPDATE_CANNOT_BATCH);
      will_batch = false;
    } else {
      // No after update triggers, attempt to start bulk update
      will_batch = !table->file->start_bulk_update();
    }
    if ((table->file->ha_table_flags() & HA_READ_BEFORE_WRITE_REMOVAL) &&
        !thd->lex->is_ignore() && !using_limit && !has_update_triggers &&
        range_scan && ::used_index(range_scan) != MAX_KEY &&
        check_constant_expressions(*update_value_list))
      read_removal = table->check_read_removal(::used_index(range_scan));

    // If the update is batched, we cannot do partial update, so turn it off.
    if (will_batch) table->cleanup_partial_update(); /* purecov: inspected */

    uint dup_key_found;

    while (true) {
      error = iterator->Read();
      if (error || thd->killed) break;
      thd->inc_examined_row_count(1);
      if (conds != nullptr) {
        const bool skip_record = conds->val_int() == 0;
        if (thd->is_error()) {
          error = 1;
          break;
        }
        if (skip_record) {
          table->file
              ->unlock_row();  // Row failed condition check, release lock
          thd->get_stmt_da()->inc_current_row_for_condition();
          continue;
        }
      }
      assert(!thd->is_error());

      if (table->file->was_semi_consistent_read())
        /*
          Reviewer: iterator is reading from the to-be-updated table or
          from a tmp file.
          In the latter case, if the condition of this if() is true,
          it is wrong to "continue"; indeed this will pick up the _next_ row of
          tempfile; it will not re-read-with-lock the current row of tempfile,
          as tempfile is not an InnoDB table and not doing semi consistent read.
          If that happens, we're potentially skipping a row which was found
          matching! OTOH, as the rowid was written to the tempfile, it means it
          matched and thus we have already re-read it in the tempfile-write loop
          above and thus locked it. So we shouldn't come here. How about adding
          an assertion that if reading from tmp file we shouldn't come here?
        */
        continue; /* repeat the read of the same row if it still exists */

      table->clear_partial_update_diffs();

      store_record(table, record[1]);
      bool is_row_changed = false;
      if (fill_record_n_invoke_before_triggers(
              thd, &update, query_block->fields, *update_value_list, table,
              TRG_EVENT_UPDATE, 0, false, &is_row_changed)) {
        error = 1;
        break;
      }
      found_rows++;

      if (is_row_changed) {
        /*
          Default function and default expression values are filled before
          evaluating the view check option. Check option on view using table(s)
          with default function and default expression breaks otherwise.

          It is safe to not invoke CHECK OPTION for VIEW if records are same.
          In this case the row is coming from the view and thus should satisfy
          the CHECK OPTION.
        */
        int check_result = table_list->view_check_option(thd);
        if (check_result != VIEW_CHECK_OK) {
          if (check_result == VIEW_CHECK_SKIP)
            continue;
          else if (check_result == VIEW_CHECK_ERROR) {
            error = 1;
            break;
          }
        }

        /*
          Existing rows in table should normally satisfy CHECK constraints. So
          it should be safe to check constraints only for rows that has really
          changed (i.e. after compare_records()).

          In future, once addition/enabling of CHECK constraints without their
          validation is supported, we might encounter old rows which do not
          satisfy CHECK constraints currently enabled. However, rejecting no-op
          updates to such invalid pre-existing rows won't make them valid and is
          probably going to be confusing for users. So it makes sense to stick
          to current behavior.
        */
        if (invoke_table_check_constraints(thd, table)) {
          if (thd->is_error()) {
            error = 1;
            break;
          }
          // continue when IGNORE clause is used.
          continue;
        }

        if (will_batch) {
          /*
            Typically a batched handler can execute the batched jobs when:
            1) When specifically told to do so
            2) When it is not a good idea to batch anymore
            3) When it is necessary to send batch for other reasons
            (One such reason is when READ's must be performed)

            1) is covered by exec_bulk_update calls.
            2) and 3) is handled by the bulk_update_row method.

            bulk_update_row can execute the updates including the one
            defined in the bulk_update_row or not including the row
            in the call. This is up to the handler implementation and can
            vary from call to call.

            The dup_key_found reports the number of duplicate keys found
            in those updates actually executed. It only reports those if
            the extra call with HA_EXTRA_IGNORE_DUP_KEY have been issued.
            If this hasn't been issued it returns an error code and can
            ignore this number. Thus any handler that implements batching
            for UPDATE IGNORE must also handle this extra call properly.

            If a duplicate key is found on the record included in this
            call then it should be included in the count of dup_key_found
            and error should be set to 0 (only if these errors are ignored).
          */
          error = table->file->ha_bulk_update_row(
              table->record[1], table->record[0], &dup_key_found);
          limit += dup_key_found;
          updated_rows -= dup_key_found;
        } else {
          /* Non-batched update */
          error =
              table->file->ha_update_row(table->record[1], table->record[0]);
        }
        if (error == 0)
          updated_rows++;
        else if (error == HA_ERR_RECORD_IS_THE_SAME)
          error = 0;
        else {
          if (table->file->is_fatal_error(error)) error_flags |= ME_FATALERROR;

          table->file->print_error(error, error_flags);

          // The error can have been downgraded to warning by IGNORE.
          if (thd->is_error()) break;
        }
      }

      if (!error && has_after_triggers &&
          table->triggers->process_triggers(thd, TRG_EVENT_UPDATE,
                                            TRG_ACTION_AFTER, true)) {
        error = 1;
        break;
      }

      if (!--limit && using_limit) {
        /*
          We have reached end-of-file in most common situations where no
          batching has occurred and if batching was supposed to occur but
          no updates were made and finally when the batch execution was
          performed without error and without finding any duplicate keys.
          If the batched updates were performed with errors we need to
          check and if no error but duplicate key's found we need to
          continue since those are not counted for in limit.
        */
        if (will_batch &&
            ((error = table->file->exec_bulk_update(&dup_key_found)) ||
             dup_key_found)) {
          if (error) {
            /*
              ndbcluster is the only handler that returns an error at this
              juncture
            */
            assert(table->file->ht->db_type == DB_TYPE_NDBCLUSTER);
            if (table->file->is_fatal_error(error))
              error_flags |= ME_FATALERROR;

            table->file->print_error(error, error_flags);
            error = 1;
            break;
          }
          /* purecov: begin inspected */
          /*
            Either an error was found and we are ignoring errors or there were
            duplicate keys found with HA_IGNORE_DUP_KEY enabled. In both cases
            we need to correct the counters and continue the loop.
          */

          /*
            Note that NDB disables batching when duplicate keys are to be
            ignored. Any duplicate key found will result in an error returned
            above.
          */
          assert(false);
          limit = dup_key_found;  // limit is 0 when we get here so need to +
          updated_rows -= dup_key_found;
          /* purecov: end */
        } else {
          error = -1;  // Simulate end of file
          break;
        }
      }

      thd->get_stmt_da()->inc_current_row_for_condition();
      assert(!thd->is_error());
      if (thd->is_error()) {
        error = 1;
        break;
      }
    }
    end_semi_consistent_read.rollback();

    dup_key_found = 0;
    /*
      Caching the killed status to pass as the arg to query event constructor;
      The cached value can not change whereas the killed status can
      (externally) since this point and change of the latter won't affect
      binlogging.
      It's assumed that if an error was set in combination with an effective
      killed status then the error is due to killing.
    */
    killed_status = thd->killed;  // get the status of the atomic
    // simulated killing after the loop must be ineffective for binlogging
    DBUG_EXECUTE_IF("simulate_kill_bug27571",
                    { thd->killed = THD::KILL_QUERY; };);
    if (killed_status != THD::NOT_KILLED) error = 1;

    int loc_error;
    if (error && will_batch &&
        (loc_error = table->file->exec_bulk_update(&dup_key_found)))
    /*
      An error has occurred when a batched update was performed and returned
      an error indication. It cannot be an allowed duplicate key error since
      we require the batching handler to treat this as a normal behavior.

      Otherwise we simply remove the number of duplicate keys records found
      in the batched update.
    */
    {
      /* purecov: begin inspected */
      error_flags = MYF(0);
      if (table->file->is_fatal_error(loc_error)) error_flags |= ME_FATALERROR;

      table->file->print_error(loc_error, error_flags);
      error = 1;
      /* purecov: end */
    } else
      updated_rows -= dup_key_found;
    if (will_batch) table->file->end_bulk_update();

    if (read_removal) {
      /* Only handler knows how many records really was written */
      updated_rows = table->file->end_read_removal();
      if (!records_are_comparable(table)) found_rows = updated_rows;
    }

  }  // End of scope for Modification_plan

  if (!transactional_table && updated_rows > 0)
    thd->get_transaction()->mark_modified_non_trans_table(
        Transaction_ctx::STMT);

  iterator.reset();

  /*
    error < 0 means really no error at all: we processed all rows until the
    last one without error. error > 0 means an error (e.g. unique key
    violation and no IGNORE or REPLACE). error == 0 is also an error (if
    preparing the record or invoking before triggers fails). See
    ha_autocommit_or_rollback(error>=0) and return error>=0 below.
    Sometimes we want to binlog even if we updated no rows, in case user used
    it to be sure master and slave are in same state.
  */
  if ((error < 0) ||
      thd->get_transaction()->cannot_safely_rollback(Transaction_ctx::STMT)) {
    if (mysql_bin_log.is_open()) {
      int errcode = 0;
      if (error < 0)
        thd->clear_error();
      else
        errcode = query_error_code(thd, killed_status == THD::NOT_KILLED);

      if (thd->binlog_query(THD::ROW_QUERY_TYPE, thd->query().str,
                            thd->query().length, transactional_table, false,
                            false, errcode)) {
        error = 1;  // Rollback update
      }
    }
  }
  assert(transactional_table || updated_rows == 0 ||
         thd->get_transaction()->cannot_safely_rollback(Transaction_ctx::STMT));

  // If LAST_INSERT_ID(X) was used, report X
  const ulonglong id = thd->arg_of_last_insert_id_function
                           ? thd->first_successful_insert_id_in_prev_stmt
                           : 0;

  if (error < 0) {
    char buff[MYSQL_ERRMSG_SIZE];
    snprintf(buff, sizeof(buff), ER_THD(thd, ER_UPDATE_INFO), (long)found_rows,
             (long)updated_rows,
             (long)thd->get_stmt_da()->current_statement_cond_count());
    my_ok(thd,
          thd->get_protocol()->has_client_capability(CLIENT_FOUND_ROWS)
              ? found_rows
              : updated_rows,
          id, buff);
    DBUG_PRINT("info", ("%ld records updated", (long)updated_rows));
  }
  thd->check_for_truncated_fields = CHECK_FIELD_IGNORE;
  thd->current_found_rows = found_rows;

  assert(CountHiddenFields(*update_value_list) == 0);

  // Following test is disabled, as we get RQG errors that are hard to debug
  // assert((error >= 0) == thd->is_error());
  return error >= 0 || thd->is_error();
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/table.cc
Function: TABLE::setup_partial_update
bool TABLE::setup_partial_update(bool logical_diffs) {
  DBUG_TRACE;
  assert(m_partial_update_info == nullptr);

  THD *thd = current_thd;

  if (!has_columns_marked_for_partial_update()) return false;

  Opt_trace_context *trace = &thd->opt_trace;
  if (trace->is_started()) {
    Opt_trace_object trace_wrapper(trace);
    Opt_trace_object trace_partial_update(trace, "json_partial_update");
    trace_partial_update.add_utf8_table(pos_in_table_list);
    Opt_trace_array columns(trace, "eligible_columns");
    for (uint i = bitmap_get_first_set(m_partial_update_columns);
         i != MY_BIT_NONE;
         i = bitmap_get_next_set(m_partial_update_columns, i)) {
      columns.add_utf8(s->field[i]->field_name);
    }
  }

  m_partial_update_info = new (thd->mem_root)
      Partial_update_info(this, m_partial_update_columns, logical_diffs);
  return thd->is_error();
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/transaction.cc
Function: trans_begin
bool trans_begin(THD *thd, uint flags) {
  bool res = false;
  DBUG_TRACE;

  if (trans_check_state(thd)) return true;

  TX_TRACKER_GET(tst);

  thd->locked_tables_list.unlock_locked_tables(thd);

  assert(!thd->locked_tables_mode);

  if (thd->in_multi_stmt_transaction_mode() ||
      (thd->variables.option_bits & OPTION_TABLE_LOCK)) {
    thd->variables.option_bits &= ~OPTION_TABLE_LOCK;
    thd->server_status &=
        ~(SERVER_STATUS_IN_TRANS | SERVER_STATUS_IN_TRANS_READONLY);
    DBUG_PRINT("info", ("clearing SERVER_STATUS_IN_TRANS"));
    res = ha_commit_trans(thd, true);
  }

  thd->variables.option_bits &= ~OPTION_BEGIN;
  thd->get_transaction()->reset_unsafe_rollback_flags(Transaction_ctx::SESSION);

  if (res) return true;

  /*
    Release transactional metadata locks only after the
    transaction has been committed.
  */
  thd->mdl_context.release_transactional_locks();

  // The RO/RW options are mutually exclusive.
  assert(!((flags & MYSQL_START_TRANS_OPT_READ_ONLY) &&
           (flags & MYSQL_START_TRANS_OPT_READ_WRITE)));
  if (flags & MYSQL_START_TRANS_OPT_READ_ONLY) {
    thd->tx_read_only = true;
    if (tst) tst->set_read_flags(thd, TX_READ_ONLY);
  } else if (flags & MYSQL_START_TRANS_OPT_READ_WRITE) {
    /*
      Explicitly starting a RW transaction when the server is in
      read-only mode, is not allowed unless the user has SUPER priv.
      Implicitly starting a RW transaction is allowed for backward
      compatibility.
    */
    if (check_readonly(thd, true)) return true;
    thd->tx_read_only = false;
    /*
      This flags that tx_read_only was set explicitly, rather than
      just from the session's default.
    */
    if (tst) tst->set_read_flags(thd, TX_READ_WRITE);
  }

  DBUG_EXECUTE_IF("dbug_set_high_prio_trx", {
    assert(thd->tx_priority == 0);
    thd->tx_priority = 1;
  });

  thd->variables.option_bits |= OPTION_BEGIN;
  thd->server_status |= SERVER_STATUS_IN_TRANS;
  if (thd->tx_read_only) thd->server_status |= SERVER_STATUS_IN_TRANS_READONLY;
  DBUG_PRINT("info", ("setting SERVER_STATUS_IN_TRANS"));

  if (tst) tst->add_trx_state(thd, TX_EXPLICIT);

  /* ha_start_consistent_snapshot() relies on OPTION_BEGIN flag set. */
  if (flags & MYSQL_START_TRANS_OPT_WITH_CONS_SNAPSHOT) {
    if (tst) tst->add_trx_state(thd, TX_WITH_SNAPSHOT);
    res = ha_start_consistent_snapshot(thd);
  }

  /*
    Register transaction start in performance schema if not done already.
    We handle explicitly started transactions here, implicitly started
    transactions (and single-statement transactions in autocommit=1 mode)
    are handled in trans_register_ha().
    We can't handle explicit transactions in the same way as implicit
    because we want to correctly attribute statements which follow
    BEGIN but do not touch any transactional tables.
  */
#ifdef HAVE_PSI_TRANSACTION_INTERFACE
  if (thd->m_transaction_psi == nullptr) {
    thd->m_transaction_psi =
        MYSQL_START_TRANSACTION(&thd->m_transaction_state, nullptr, nullptr,
                                thd->tx_isolation, thd->tx_read_only, false);
    DEBUG_SYNC(thd, "after_set_transaction_psi_before_set_transaction_gtid");
    gtid_set_performance_schema_values(thd);
  }
#endif

  return res;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/transaction.cc
Function: trans_rollback_implicit
bool trans_rollback_implicit(THD *thd) {
  int res;
  DBUG_TRACE;

  /*
    Always commit/rollback statement transaction before manipulating
    with the normal one.
    Don't perform rollback in the middle of sub-statement, wait till
    its end.
  */
  assert(thd->get_transaction()->is_empty(Transaction_ctx::STMT) &&
         !thd->in_sub_stmt);

  thd->server_status &=
      ~(SERVER_STATUS_IN_TRANS | SERVER_STATUS_IN_TRANS_READONLY);
  DBUG_PRINT("info", ("clearing SERVER_STATUS_IN_TRANS"));
  res = ha_rollback_trans(thd, true);
  thd->variables.option_bits &= ~OPTION_BEGIN;
  thd->get_transaction()->reset_unsafe_rollback_flags(Transaction_ctx::SESSION);

  /* Rollback should clear transaction_rollback_request flag. */
  assert(!thd->transaction_rollback_request);
  /* The transaction should be marked as complete in P_S. */
  assert(thd->m_transaction_psi == nullptr);

  trans_track_end_trx(thd);

  /*
    Avoid updating modified uncommitted objects when rolling back
    attachable read-write transaction. This is required to allow I_S
    queries to update table statistics during CREATE TABLE ... SELECT,
    otherwise the uncommitted object added by DDL would be removed by I_S
    query.
  */
  if (!thd->is_attachable_rw_transaction_active())
    thd->dd_client()->rollback_modified_objects();

  thd->locked_tables_list.discard_renamed_tablespace_mdls();

  return res;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/transaction.cc
Function: trans_rollback
bool trans_rollback(THD *thd) {
  int res;
  DBUG_TRACE;

  if (trans_check_state(thd)) return true;

  thd->m_transactional_ddl.rollback();

  thd->server_status &=
      ~(SERVER_STATUS_IN_TRANS | SERVER_STATUS_IN_TRANS_READONLY);
  DBUG_PRINT("info", ("clearing SERVER_STATUS_IN_TRANS"));
  res = ha_rollback_trans(thd, true);
  thd->variables.option_bits &= ~OPTION_BEGIN;
  thd->get_transaction()->reset_unsafe_rollback_flags(Transaction_ctx::SESSION);
  thd->lex->start_transaction_opt = 0;

  /* The transaction should be marked as complete in P_S. */
  assert(thd->m_transaction_psi == nullptr);

  thd->tx_priority = 0;

  trans_track_end_trx(thd);

  /*
    Avoid updating modified uncommitted objects when rolling back
    attachable read-write transaction. This is required to allow I_S
    queries to update table statistics during CREATE TABLE ... SELECT,
    otherwise the uncommitted object added by DDL would be removed by I_S
    query.
  */
  if (!thd->is_attachable_rw_transaction_active())
    thd->dd_client()->rollback_modified_objects();

  thd->locked_tables_list.discard_renamed_tablespace_mdls();

  thd->m_transactional_ddl.post_ddl();

  return res;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/transaction.cc
Function: trans_commit
bool trans_commit(THD *thd, bool ignore_global_read_lock) {
  int res;
  DBUG_TRACE;

  DBUG_EXECUTE_IF(
      "crash_on_transactional_ddl_commit",
      if (thd->m_transactional_ddl.inited() &&
          thd->lex->sql_command == SQLCOM_COMMIT) { DBUG_SUICIDE(); });

  if (trans_check_state(thd)) return true;

  thd->server_status &=
      ~(SERVER_STATUS_IN_TRANS | SERVER_STATUS_IN_TRANS_READONLY);
  DBUG_PRINT("info", ("clearing SERVER_STATUS_IN_TRANS"));
  res = ha_commit_trans(thd, true, ignore_global_read_lock);
  if (res == false)
    if (thd->rpl_thd_ctx.session_gtids_ctx().notify_after_transaction_commit(
            thd))
      LogErr(WARNING_LEVEL, ER_TRX_GTID_COLLECT_REJECT);
  /*
    When gtid mode is enabled, a transaction may cause binlog
    rotation, which inserts a record into the gtid system table
    (which is probably a transactional table). Thence, the flag
    SERVER_STATUS_IN_TRANS may be set again while calling
    ha_commit_trans(...) Consequently, we need to reset it back,
    much like we are doing before calling ha_commit_trans(...).

    We would really only need to do this when gtid_mode=on.  However,
    checking gtid_mode requires holding a lock, which is costly.  So
    we clear the bit unconditionally.  This has no side effects since
    if gtid_mode=off the bit is already cleared.
  */
  thd->server_status &= ~SERVER_STATUS_IN_TRANS;
  thd->variables.option_bits &= ~OPTION_BEGIN;
  thd->get_transaction()->reset_unsafe_rollback_flags(Transaction_ctx::SESSION);
  thd->lex->start_transaction_opt = 0;

  /* The transaction should be marked as complete in P_S. */
  assert(thd->m_transaction_psi == nullptr);

  thd->tx_priority = 0;

  trans_track_end_trx(thd);

  /*
    Avoid updating modified uncommitted objects when committing attachable
    read-write transaction. This is required to allow I_S queries to update
    table statistics during CREATE TABLE ... SELECT, otherwise the
    uncommitted object added by DDL would be removed by I_S query.
  */
  if (!thd->is_attachable_rw_transaction_active()) {
    /*
      If the SE failed to commit the transaction, we must rollback the
      modified dictionary objects to make sure the DD cache, the DD
      tables and the state in the SE stay in sync.
    */
    if (res)
      thd->dd_client()->rollback_modified_objects();
    else
      thd->dd_client()->commit_modified_objects();
  }

  thd->locked_tables_list.adjust_renamed_tablespace_mdls(&thd->mdl_context);

  thd->m_transactional_ddl.post_ddl();

  return res;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/transaction.cc
Function: trans_commit_implicit
bool trans_commit_implicit(THD *thd, bool ignore_global_read_lock) {
  bool res = false;
  DBUG_TRACE;

  /*
    Ensure that trans_check_state() was called before trans_commit_implicit()
    by asserting that conditions that are checked in the former function are
    true.
  */
  assert(thd->get_transaction()->is_empty(Transaction_ctx::STMT) &&
         !thd->in_sub_stmt &&
         !thd->get_transaction()->xid_state()->check_in_xa(false));

  if (thd->in_multi_stmt_transaction_mode() ||
      (thd->variables.option_bits & OPTION_TABLE_LOCK)) {
    /* Safety if one did "drop table" on locked tables */
    if (!thd->locked_tables_mode)
      thd->variables.option_bits &= ~OPTION_TABLE_LOCK;
    thd->server_status &=
        ~(SERVER_STATUS_IN_TRANS | SERVER_STATUS_IN_TRANS_READONLY);
    DBUG_PRINT("info", ("clearing SERVER_STATUS_IN_TRANS"));
    res = ha_commit_trans(thd, true, ignore_global_read_lock);
  } else if (tc_log)
    res = tc_log->commit(thd, true);

  if (res == false)
    if (thd->rpl_thd_ctx.session_gtids_ctx().notify_after_transaction_commit(
            thd))
      LogErr(WARNING_LEVEL, ER_TRX_GTID_COLLECT_REJECT);
  thd->variables.option_bits &= ~OPTION_BEGIN;
  thd->get_transaction()->reset_unsafe_rollback_flags(Transaction_ctx::SESSION);

  /* The transaction should be marked as complete in P_S. */
  assert(thd->m_transaction_psi == nullptr);

  /*
    Upon implicit commit, reset the current transaction
    isolation level and access mode. We do not care about
    @@session.completion_type since it's documented
    to not have any effect on implicit commit.
  */
  trans_reset_one_shot_chistics(thd);

  trans_track_end_trx(thd);

  /*
    Avoid updating modified uncommitted objects when committing attachable
    read-write transaction. This is required to allow I_S queries to update
    table statistics during CREATE TABLE ... SELECT, otherwise the
    uncommitted object added by DDL would be removed by I_S query.
  */
  if (!thd->is_attachable_rw_transaction_active()) {
    /*
      If the SE failed to commit the transaction, we must rollback the
      modified dictionary objects to make sure the DD cache, the DD
      tables and the state in the SE stay in sync.
    */
    if (res)
      thd->dd_client()->rollback_modified_objects();
    else
      thd->dd_client()->commit_modified_objects();
  }

  thd->locked_tables_list.adjust_renamed_tablespace_mdls(&thd->mdl_context);
  return res;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/xa.cc
Function: cleanup_trans_state
void cleanup_trans_state(THD *thd) {
  thd->variables.option_bits &= ~OPTION_BEGIN;
  thd->server_status &=
      ~(SERVER_STATUS_IN_TRANS | SERVER_STATUS_IN_TRANS_READONLY);
  thd->get_transaction()->reset_unsafe_rollback_flags(Transaction_ctx::SESSION);
  DBUG_PRINT("info", ("clearing SERVER_STATUS_IN_TRANS"));
  xa::Transaction_cache::remove(thd->get_transaction());
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/xa.cc
Function: applier_reset_xa_trans
bool applier_reset_xa_trans(THD *thd) {
  DBUG_TRACE;
  Transaction_ctx *trn_ctx = thd->get_transaction();

  if (!is_xa_tran_detached_on_prepare(thd)) {
    XID_STATE *xid_state = trn_ctx->xid_state();

    if (MDL_context_backup_manager::instance().create_backup(
            &thd->mdl_context, xid_state->get_xid()->key(),
            xid_state->get_xid()->key_length()))
      return true;

    /*
      In the following the server transaction state gets reset for
      a slave applier thread similarly to xa_commit logics
      except commit does not run.
    */
    thd->variables.option_bits &= ~OPTION_BEGIN;
    trn_ctx->reset_unsafe_rollback_flags(Transaction_ctx::STMT);
    thd->server_status &= ~SERVER_STATUS_IN_TRANS;
    /* Server transaction ctx is detached from THD */
    xa::Transaction_cache::detach(trn_ctx);
    xid_state->reset();
  }
  /*
     The current engine transactions is detached from THD, and
     previously saved is restored.
  */
  attach_native_trx(thd);
  trn_ctx->set_ha_trx_info(Transaction_ctx::SESSION, nullptr);
  trn_ctx->set_no_2pc(Transaction_ctx::SESSION, false);
  trn_ctx->cleanup();
#ifdef HAVE_PSI_TRANSACTION_INTERFACE
  thd->m_transaction_psi = nullptr;
#endif
  thd->mdl_context.release_transactional_locks();
  /*
    On client sessions a XA PREPARE will always be followed by a XA COMMIT
    or a XA ROLLBACK, and both statements will reset the tx isolation level
    and access mode when the statement is finishing a transaction.

    For replicated workload it is possible to have other transactions between
    the XA PREPARE and the XA [COMMIT|ROLLBACK].

    So, if the slave applier changed the current transaction isolation level,
    it needs to be restored to the session default value after having the
    XA transaction prepared.
  */
  trans_reset_one_shot_chistics(thd);

  return thd->is_error();
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/bootstrap.cc
Function: bootstrap::process_iterator not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/bootstrap.cc
Function: bootstrap::process_iterator not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/bootstrap.cc
Function: bootstrap::process_iterator not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/bootstrap.cc
Function: bootstrap::process_iterator not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/bootstrap.cc
Function: bootstrap::process_iterator not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/bootstrap.cc
Function: bootstrap::process_iterator not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/bootstrap.cc
Function: bootstrap::process_iterator not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/item.cc
Function: ItemToString
string ItemToString(const Item *item) {
  if (item == nullptr) return "(none)";
  String str;
  const ulonglong save_bits = current_thd->variables.option_bits;
  current_thd->variables.option_bits &= ~OPTION_QUOTE_SHOW_CREATE;
  item->print(
      current_thd, &str,
      enum_query_type(QT_NO_DEFAULT_DB | QT_SUBSELECT_AS_ONLY_SELECT_NUMBER));
  current_thd->variables.option_bits = save_bits;
  return to_string(str);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/item_cmpfunc.cc
Function: Item_func_isnull::fix_fields
bool Item_in_optimizer::fix_fields(THD *thd, Item **) {
  assert(!fixed);
  Item_in_subselect *subqpred = down_cast<Item_in_subselect *>(args[0]);

  if (!subqpred->fixed && subqpred->fix_fields(thd, nullptr)) return true;
  if (subqpred->left_expr->cols() != subqpred->unit_cols()) {
    assert(false);
    my_error(ER_OPERAND_COLUMNS, MYF(0), subqpred->left_expr->cols());
    return true;
  }
  if (subqpred->is_nullable()) set_nullable(true);
  add_accum_properties(subqpred);
  used_tables_cache |= subqpred->used_tables();
  not_null_tables_cache |= subqpred->not_null_tables();

  /*
    not_null_tables_cache is to hold any table which, if its row is NULL,
    causes the result of the complete Item to be NULL.
    This can never be guaranteed, as the complete Item will return FALSE if
    the subquery's result is empty.
    But, if the Item's owner previously called top_level_item(), a FALSE
    result is equivalent to a NULL result from the owner's POV.
    A NULL value in the left argument will surely lead to a NULL or FALSE
    result for the naked IN. If the complete item is:
    plain IN, or IN IS TRUE, then it will return NULL or FALSE. Otherwise it
    won't and we must remove the left argument from not_null_tables().
    Right argument doesn't need to be handled, as
    Item_subselect::not_null_tables() is always 0.
  */
  if (subqpred->abort_on_null && subqpred->value_transform == BOOL_IS_TRUE) {
  } else {
    not_null_tables_cache &= ~subqpred->left_expr->not_null_tables();
  }
  fixed = true;
  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/item_subselect.cc
Function: subselect_hash_sj_engine::setup
bool subselect_hash_sj_engine::setup(
    THD *thd, const mem_root_deque<Item *> &tmp_columns) {
  /* The result sink where we will materialize the subquery result. */
  Query_result_union *tmp_result_sink;
  /* The table into which the subquery is materialized. */
  TABLE *tmp_table;
  KEY *tmp_key;       /* The only index on the temporary table. */
  uint tmp_key_parts; /* Number of keyparts in tmp_key. */
  uint key_length;

  DBUG_TRACE;

  DBUG_EXECUTE_IF("hash_semijoin_fail_in_setup", {
    my_error(ER_UNKNOWN_ERROR, MYF(0));
    return true;
  });

  /* 1. Create/initialize materialization related objects. */

  /*
    Create and initialize a select result interceptor that stores the
    result stream in a temporary table. The temporary table itself is
    managed (created/filled/etc) internally by the interceptor.
  */
  if (!(tmp_result_sink = new (thd->mem_root) Query_result_union()))
    return true;
  if (tmp_result_sink->create_result_table(
          thd, tmp_columns,
          true,  // Eliminate duplicates
          thd->variables.option_bits | TMP_TABLE_ALL_COLUMNS,
          "<materialized_subquery>", true, true))
    return true;

  tmp_table = tmp_result_sink->table;
  tmp_key = tmp_table->key_info;
  if (tmp_table->hash_field) {
    tmp_key_parts = CountVisibleFields(tmp_columns);
    key_length = ALIGN_SIZE(tmp_table->s->reclength);
  } else {
    tmp_key_parts = tmp_key->user_defined_key_parts;
    key_length = ALIGN_SIZE(tmp_key->key_length) * 2;
  }

  result = tmp_result_sink;

  /*
    Make sure there is only one index on the temp table.
  */
  assert(CountVisibleFields(tmp_columns) == tmp_table->s->fields ||
         // Unique constraint is used and a hash field was added
         (tmp_table->hash_field &&
          CountVisibleFields(tmp_columns) == tmp_table->s->fields - 1));
  /* 2. Create/initialize execution related objects. */

  /*
    Create and initialize the Index_lookup used by the index lookup iterator
    into the materialized subquery result.
  */

  table = tmp_table;
  ref.key = 0; /* The only temp table index. */
  ref.key_length = tmp_key->key_length;
  type = (tmp_table->key_info[0].flags & HA_NOSAME) ? JT_EQ_REF : JT_REF;
  if (!(ref.key_buff = (uchar *)thd->mem_calloc(key_length)) ||
      !(ref.key_copy =
            (store_key **)thd->alloc((sizeof(store_key *) * tmp_key_parts))) ||
      !(ref.items = (Item **)thd->alloc(sizeof(Item *) * tmp_key_parts)))
    return true;

  if (tmp_table->hash_field) {
    ref.keypart_hash = &hash;
  }

  uchar *cur_ref_buff = ref.key_buff;

  /*
    Create an artificial condition to post-filter those rows matched by index
    lookups that cannot be distinguished by the index lookup procedure, for
    example:
    - because of truncation (if the outer column type's length is bigger than
    the inner column type's, index lookup will use a truncated outer
    value as search key, yielding false positives).
    - because the index is over hash_field and thus not unique.

    Prepared statements execution requires that fix_fields is called
    for every execution. In order to call fix_fields we need to create a
    Name_resolution_context and a corresponding Table_ref for the
    temporary table for the subquery, so that all column references to the
    materialized subquery table can be resolved correctly.
  */
  assert(cond == nullptr);
  if (!(cond = new Item_cond_and)) return true;
  /*
    Table reference for tmp_table that is used to resolve column references
    (Item_fields) to columns in tmp_table.
  */
  Table_ref *tmp_table_ref =
      new (thd->mem_root) Table_ref(tmp_table, "<materialized_subquery>");
  if (tmp_table_ref == nullptr) return true;

  // Assign Table_ref pointer temporarily, while creatung fields:
  tmp_table->pos_in_table_list = tmp_table_ref;
  tmp_table_ref->query_block = unit->first_query_block();

  KEY_PART_INFO *key_parts = tmp_key->key_part;
  for (uint part_no = 0; part_no < tmp_key_parts; part_no++) {
    /* New equi-join condition for the current column. */
    Item_func_eq *eq_cond;
    /* Item for the corresponding field from the materialized temp table. */
    Item_field *right_col_item;
    Field *field = tmp_table->visible_field_ptr()[part_no];
    const bool nullable = field->is_nullable();
    ref.items[part_no] = item->left_expr->element_index(part_no);

    if (!(right_col_item =
              new Item_field(thd, &tmp_table_ref->query_block->context,
                             tmp_table_ref, field)) ||
        !(eq_cond = new Item_func_eq(ref.items[part_no], right_col_item)) ||
        ((Item_cond_and *)cond)->add(eq_cond)) {
      delete cond;
      cond = nullptr;
      return true;
    }

    if (tmp_table->hash_field) {
      ref.key_copy[part_no] = new (thd->mem_root)
          store_key_hash_item(thd, field, cur_ref_buff, nullptr,
                              field->pack_length(), ref.items[part_no], &hash);
    } else {
      ref.key_copy[part_no] = new (thd->mem_root) store_key(
          thd, field,
          /* TODO:
             the NULL byte is taken into account in
             key_parts[part_no].store_length, so instead of
             cur_ref_buff + test(maybe_null), we could
             use that information instead.
           */
          cur_ref_buff + (nullable ? 1 : 0), nullable ? cur_ref_buff : nullptr,
          key_parts[part_no].length, ref.items[part_no]);
    }
    if (nullable &&  // nullable column in tmp table,
                     // and UNKNOWN should not be interpreted as FALSE
        !item->abort_on_null) {
      // It must be the single column, or we wouldn't be here
      assert(tmp_key_parts == 1);
      // Be ready to search for NULL into inner column:
      ref.null_ref_key = cur_ref_buff;
      mat_table_has_nulls = NEX_UNKNOWN;
    } else {
      ref.null_ref_key = nullptr;
      mat_table_has_nulls = NEX_IRRELEVANT_OR_FALSE;
    }

    if (tmp_table->hash_field)
      cur_ref_buff += field->pack_length();
    else
      cur_ref_buff += key_parts[part_no].store_length;
  }
  tmp_table->pos_in_table_list = nullptr;
  ref.key_err = true;
  ref.key_parts = tmp_key_parts;
  table_ref = tmp_table_ref;

  if (cond->fix_fields(thd, &cond)) return true;

  assert(unit->is_prepared());

  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log.cc
Function: Log_to_csv_event_handler::log_general
bool Log_to_csv_event_handler::log_general(
    THD *thd, ulonglong event_utime, const char *user_host,
    size_t user_host_len, my_thread_id thread_id, const char *command_type,
    size_t command_type_len, const char *sql_text, size_t sql_text_len,
    const CHARSET_INFO *client_cs) {
  TABLE *table = nullptr;
  bool result = true;
  bool need_close = false;
  bool need_rnd_end = false;
  uint field_index;
  my_timeval tv;

  /*
    CSV uses TIME_to_timestamp() internally if table needs to be repaired
    which will set thd->time_zone_used
  */
  bool save_time_zone_used = thd->time_zone_used;

  ulonglong save_thd_options = thd->variables.option_bits;
  thd->variables.option_bits &= ~OPTION_BIN_LOG;

  Table_ref table_list(MYSQL_SCHEMA_NAME.str, MYSQL_SCHEMA_NAME.length,
                       GENERAL_LOG_NAME.str, GENERAL_LOG_NAME.length,
                       GENERAL_LOG_NAME.str, TL_WRITE_CONCURRENT_INSERT);

  /*
    1) open_log_table generates an error if the
    table can not be opened or is corrupted.
    2) "INSERT INTO general_log" can generate warning sometimes.

    Suppress these warnings and errors, they can't be dealt with
    properly anyway.

    QQ: this problem needs to be studied in more detail.
    Comment this 2 lines and run "cast.test" to see what's happening.
  */
  Silence_log_table_errors error_handler;
  thd->push_internal_handler(&error_handler);

  Open_tables_backup open_tables_backup;
  if (!(table = open_log_table(thd, &table_list, &open_tables_backup)))
    goto err;

  need_close = true;

  if (log_table_intact.check(thd, table_list.table, &general_log_table_def))
    goto err;

  if (table->file->ha_extra(HA_EXTRA_MARK_AS_LOG_TABLE) ||
      table->file->ha_rnd_init(false))
    goto err;

  need_rnd_end = true;

  /* Honor next number columns if present */
  table->next_number_field = table->found_next_number_field;

  /*
    NOTE: we do not call restore_record() here, as all fields are
    filled by the Logger (=> no need to load default ones).
  */

  /*
    We do not set a value for table->field[0], as it will use
    default value (which is CURRENT_TIMESTAMP).
  */

  assert(table->field[GLT_FIELD_EVENT_TIME]->type() == MYSQL_TYPE_TIMESTAMP);
  ull2timeval(event_utime, &tv);
  table->field[GLT_FIELD_EVENT_TIME]->store_timestamp(&tv);

  /* do a write */
  if (table->field[GLT_FIELD_USER_HOST]->store(user_host, user_host_len,
                                               client_cs) ||
      table->field[GLT_FIELD_THREAD_ID]->store((longlong)thread_id, true) ||
      table->field[GLT_FIELD_SERVER_ID]->store((longlong)server_id, true) ||
      table->field[GLT_FIELD_COMMAND_TYPE]->store(command_type,
                                                  command_type_len, client_cs))
    goto err;

  /*
    A positive return value in store() means truncation.
    Still logging a message in the log in this case.
  */
  if (table->field[GLT_FIELD_ARGUMENT]->store(sql_text, sql_text_len,
                                              client_cs) < 0)
    goto err;

  /* mark all fields as not null */
  table->field[GLT_FIELD_USER_HOST]->set_notnull();
  table->field[GLT_FIELD_THREAD_ID]->set_notnull();
  table->field[GLT_FIELD_SERVER_ID]->set_notnull();
  table->field[GLT_FIELD_COMMAND_TYPE]->set_notnull();
  table->field[GLT_FIELD_ARGUMENT]->set_notnull();

  /* Set any extra columns to their default values */
  for (field_index = GLT_FIELD_COUNT; field_index < table->s->fields;
       field_index++) {
    table->field[field_index]->set_default();
  }

  /* log table entries are not replicated */
  if (table->file->ha_write_row(table->record[0])) goto err;

  result = false;

err:
  thd->pop_internal_handler();

  if (result && !thd->killed) {
    LogErr(ERROR_LEVEL, ER_LOG_CANNOT_WRITE, "mysql.general_log",
           error_handler.message());
  }

  if (need_rnd_end) {
    table->file->ha_rnd_end();
    table->file->ha_release_auto_increment();
  }

  if (need_close) close_log_table(thd, &open_tables_backup);

  thd->variables.option_bits = save_thd_options;
  thd->time_zone_used = save_time_zone_used;
  return result;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/log.cc
Function: log_command
static bool log_command(THD *thd, enum_server_command command) {
  if (what_to_log & (1L << (uint)command)) {
    Security_context *sctx = thd->security_context();
    if ((thd->variables.option_bits & OPTION_LOG_OFF) &&
        (sctx->check_access(SUPER_ACL) ||
         sctx->has_global_grant(STRING_WITH_LEN("CONNECTION_ADMIN")).first)) {
      /* No logging */
      return false;
    }
    return true;
  }
  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/range_optimizer/range_analysis.cc
Function: warn_index_not_applicable not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/range_optimizer/range_analysis.cc
Function: warn_index_not_applicable not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/range_optimizer/range_analysis.cc
Function: warn_index_not_applicable not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/range_optimizer/range_analysis.cc
Function: warn_index_not_applicable not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_write_set_handler.cc
Function: add_pke
bool add_pke(TABLE *table, THD *thd, const uchar *record) {
  DBUG_TRACE;
  assert(record == table->record[0] || record == table->record[1]);
  /*
    The next section extracts the primary key equivalent of the rows that are
    changing during the current transaction.

    1. The primary key field is always stored in the key_part[0] so we can
    simply read the value from the table->s->keys.

    2. Along with primary key we also need to extract the unique key values to
       look for the places where we are breaking the unique key constraints.

    These keys (primary/unique) are prefixed with their index names.

    In MySQL, the name of a PRIMARY KEY is PRIMARY. For other indexes, if
    you do not assign a name, the index is assigned the same name as the
    first indexed column, with an optional suffix (_2, _3, ...) to make it
    unique.

    example :
       CREATE TABLE db1.t1 (i INT NOT NULL PRIMARY KEY, j INT UNIQUE KEY, k INT
                            UNIQUE KEY);

       INSERT INTO db1.t1 VALUES(1, 2, 3);

       Here the write set string will have three values and the prepared value
    before hash function is used will be :

       i -> PRIMARYdb13t1211 => PRIMARY is the index name (for primary key)

       j -> jdb13t1221       => 'j' is the index name (for first unique key)
       k -> kdb13t1231       => 'k' is the index name (for second unique key)

    Finally these value are hashed using the murmur hash function to prevent
    sending more for certification algorithm.
  */
  Rpl_transaction_write_set_ctx *ws_ctx =
      thd->get_transaction()->get_transaction_write_set_ctx();
  bool writeset_hashes_added = false;

  if (table->key_info && (table->s->primary_key < MAX_KEY)) {
    const ptrdiff_t ptrdiff = record - table->record[0];
    std::string pke_schema_table;
    pke_schema_table.reserve(NAME_LEN * 3);
    pke_schema_table.append(HASH_STRING_SEPARATOR);
    pke_schema_table.append(table->s->db.str, table->s->db.length);
    pke_schema_table.append(HASH_STRING_SEPARATOR);
    pke_schema_table.append(std::to_string(table->s->db.length));
    pke_schema_table.append(table->s->table_name.str,
                            table->s->table_name.length);
    pke_schema_table.append(HASH_STRING_SEPARATOR);
    pke_schema_table.append(std::to_string(table->s->table_name.length));

    std::string pke;
    pke.reserve(NAME_LEN * 5);

#ifndef NDEBUG
    std::vector<std::string> write_sets;
    std::vector<uint64> hash_list;
#endif
    for (uint key_number = 0; key_number < table->s->keys; key_number++) {
      // Skip non unique.
      if (!((table->key_info[key_number].flags & (HA_NOSAME)) == HA_NOSAME))
        continue;

      enum pke_mode_e { STANDARD_PKE = 1, NO_PARTIAL_KEYS_PKE = 2, END = 3 };
      bool old_pke_needed = false;
      uint pke_mode = pke_mode_e::STANDARD_PKE;
      DBUG_EXECUTE_IF("do_not_add_pke_key_part",
                      { pke_mode = pke_mode_e::NO_PARTIAL_KEYS_PKE; });

      while (pke_mode != pke_mode_e::END) {
        pke.clear();
        pke.append(table->key_info[key_number].name);
        pke.append(pke_schema_table);

        uint i = 0;
        // Whether the key has mv keypart which have to be handled separately
        Field *mv_field = nullptr;
        for (/*empty*/; i < table->key_info[key_number].user_defined_key_parts;
             i++) {
          /* Get the primary key field index. */
          int index = table->key_info[key_number].key_part[i].fieldnr;
          Field *field = table->field[index - 1];

          /* Ignore if the value is NULL. */
          if (field->is_null(ptrdiff)) break;
          if (field->is_array()) {
            // There can be only one multi-valued key part per key
            assert(!mv_field);
            mv_field = field;
            // Skip it for now
            continue;
          }

          /*
            Update the field offset as we may be working on table->record[0]
            or table->record[1], depending on the "record" parameter.
          */
          field->move_field_offset(ptrdiff);

          const CHARSET_INFO *cs = field->charset();
          size_t key_length = table->key_info[key_number].key_part[i].length;
          size_t max_length = cs->coll->strnxfrmlen(cs, key_length);
          if (pke_mode == pke_mode_e::STANDARD_PKE) {
            std::unique_ptr<uchar[]> pk_value(new uchar[max_length + 1]());
            /*
              convert to normalized string and store so that it can be
              sorted using binary comparison functions like memcmp.
            */
            size_t length = field->make_sort_key(pk_value.get(), max_length,
                                                 key_length / cs->mbmaxlen);
            pk_value[length] = 0;

            pke.append(pointer_cast<char *>(pk_value.get()), length);
            pke.append(HASH_STRING_SEPARATOR);
            pke.append(std::to_string(length));
          }

          /*
            When we upgrade a group, old members might be using the old PKEs and
            so they identify a row A with key OLD_PKE. This is the value that is
            in the certification table. When all members are upgrade and are now
            in the latest version, all members now identify row A with key
            NEW_PKE. How do you detect conflicts in row A if the transactions in
            the certification database have the old PKE?

            So the decision taken was to always send the old PKE and the new PKE
            when keys have only a partial value of a column. In 9.0 we remove
            this code for the old PKE.
          */
          size_t pack_length = cs->coll->strnxfrmlen(cs, field->pack_length());
          if (pke_mode == pke_mode_e::NO_PARTIAL_KEYS_PKE) {
            std::unique_ptr<uchar[]> pk_value(new uchar[pack_length + 1]());
            /*
              convert to normalized string and store so that it can be
              sorted using binary comparison functions like memcmp.
            */
            size_t length = field->make_sort_key(pk_value.get(), pack_length);
            pk_value[length] = 0;

            pke.append(pointer_cast<char *>(pk_value.get()), length);
            pke.append(HASH_STRING_SEPARATOR);
            pke.append(std::to_string(length));
          }

          if (pke_mode == pke_mode_e::STANDARD_PKE &&
              max_length != pack_length) {
            old_pke_needed = true;
          }

          field->move_field_offset(-ptrdiff);
        }
        /*
          If any part of the key is NULL, ignore adding it to hash keys.
          NULL cannot conflict with any value.
          Eg: create table t1(i int primary key not null, j int, k int,
                                                  unique key (j, k));
              insert into t1 values (1, 2, NULL);
              insert into t1 values (2, 2, NULL); => this is allowed.
        */
        if (i == table->key_info[key_number].user_defined_key_parts) {
          if (mv_field) {
            mv_field->move_field_offset(ptrdiff);
            if (generate_mv_hash_pke(pke, thd, mv_field
#ifndef NDEBUG
                                     ,
                                     write_sets, hash_list
#endif
                                     ))
              return true;
            mv_field->move_field_offset(-ptrdiff);
          } else {
            if (generate_hash_pke(pke, thd
#ifndef NDEBUG
                                  ,
                                  write_sets, hash_list
#endif
                                  ))
              return true;
          }
          writeset_hashes_added = true;
        } else {
          /* This is impossible to happen in case of primary keys */
          assert(key_number != 0);
        }
        if (pke_mode == pke_mode_e::STANDARD_PKE && old_pke_needed == true) {
          pke_mode = pke_mode_e::NO_PARTIAL_KEYS_PKE;
        } else {
          pke_mode = pke_mode_e::END;
        }
      }
    }
    /*
      Foreign keys handling.

      OPTION_NO_FOREIGN_KEY_CHECKS bit in options_bits is set at two places

      1) If the user executed 'SET foreign_key_checks= 0' on the local session
      before executing the query.
      or
      2) We are applying a RBR event (i.e., the event is from a remote server)
      and logic in Rows_log_event::do_apply_event found out that the event is
      generated from a remote server session that disabled foreign_key_checks
      (using 'SET foreign_key_checks=0').

      In either of the above cases (i.e., the foreign key check is disabled for
      the current query/current event), we should ignore generating
      the foreign key information as they should not participate
      in the conflicts detecting algorithm.
    */
    if (!(thd->variables.option_bits & OPTION_NO_FOREIGN_KEY_CHECKS) &&
        table->s->foreign_keys > 0) {
      TABLE_SHARE_FOREIGN_KEY_INFO *fk = table->s->foreign_key;
      for (uint fk_number = 0; fk_number < table->s->foreign_keys;
           fk_number++) {
        /*
          There are two situations on which there is no
          unique_constraint_name, which means that the foreign key
          must be skipped.

          1) The referenced table was dropped using
             foreign_key_checks= 0, on that case we cannot check
             foreign key and need to skip it.

          2) The foreign key does reference a non unique key, thence
             it must be skipped since it cannot be used to check
             conflicts/dependencies.

             Example:
               CREATE TABLE t1 (c1 INT PRIMARY KEY, c2 INT, KEY(c2));
               CREATE TABLE t2 (x1 INT PRIMARY KEY, x2 INT,
                                FOREIGN KEY (x2) REFERENCES t1(c2));

               DELETE FROM t1 WHERE c1=1;
                 does generate the PKEs:
                   PRIMARYtest4t1211

               INSERT INTO t2 VALUES (1,1);
                 does generate the PKEs:
                   PRIMARYtest4t2211

               which does not contain PKE for the non unique key c2.
        */
        if (0 == fk[fk_number].unique_constraint_name.length) continue;

        const std::string referenced_schema_name_length =
            std::to_string(fk[fk_number].referenced_table_db.length);
        const std::string referenced_table_name_length =
            std::to_string(fk[fk_number].referenced_table_name.length);

        /*
          Prefix the hash keys with the referenced index name.
        */
        pke.clear();
        pke.append(fk[fk_number].unique_constraint_name.str,
                   fk[fk_number].unique_constraint_name.length);
        pke.append(HASH_STRING_SEPARATOR);
        pke.append(fk[fk_number].referenced_table_db.str,
                   fk[fk_number].referenced_table_db.length);
        pke.append(HASH_STRING_SEPARATOR);
        pke.append(referenced_schema_name_length);
        pke.append(fk[fk_number].referenced_table_name.str,
                   fk[fk_number].referenced_table_name.length);
        pke.append(HASH_STRING_SEPARATOR);
        pke.append(referenced_table_name_length);

        /*
          Foreign key must not have a empty column list.
        */
        assert(fk[fk_number].columns > 0);
        for (uint c = 0; c < fk[fk_number].columns; c++) {
          for (uint field_number = 0; field_number < table->s->fields;
               field_number++) {
            Field *field = table->field[field_number];
            if (field->is_null(ptrdiff)) continue;

            if (!my_strcasecmp(system_charset_info, field->field_name,
                               fk[fk_number].column_name[c].str)) {
              /*
                Update the field offset, since we may be operating on
                table->record[0] or table->record[1] and both have
                different offsets.
              */
              field->move_field_offset(ptrdiff);

              const CHARSET_INFO *cs = field->charset();
              size_t max_length =
                  cs->coll->strnxfrmlen(cs, field->pack_length());
              std::unique_ptr<uchar[]> pk_value(new uchar[max_length + 1]());

              /*
                convert to normalized string and store so that it can be
                sorted using binary comparison functions like memcmp.
              */
              size_t length = field->make_sort_key(pk_value.get(), max_length);
              pk_value[length] = 0;

              pke.append(pointer_cast<char *>(pk_value.get()), length);
              pke.append(HASH_STRING_SEPARATOR);
              pke.append(std::to_string(length));

              /* revert the field object record offset back */
              field->move_field_offset(-ptrdiff);
            }
          }
        }

        if (generate_hash_pke(pke, thd
#ifndef NDEBUG
                              ,
                              write_sets, hash_list
#endif
                              ))
          return true;
        writeset_hashes_added = true;
      }
    }

    if (table->s->foreign_key_parents > 0)
      ws_ctx->set_has_related_foreign_keys();

#ifndef NDEBUG
    debug_check_for_write_sets(write_sets, hash_list);
#endif
  }

  if (!writeset_hashes_added) ws_ctx->set_has_missing_keys();
  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_cmd_ddl_table.cc
Function: Sql_cmd_create_table::execute
bool Sql_cmd_create_table::execute(THD *thd) {
  LEX *const lex = thd->lex;
  Query_block *const query_block = lex->query_block;
  Query_expression *const query_expression = lex->unit;
  Table_ref *const create_table = lex->query_tables;
  partition_info *part_info = lex->part_info;

  /*
    Code below (especially in mysql_create_table() and Query_result_create
    methods) may modify HA_CREATE_INFO structure in LEX, so we have to
    use a copy of this structure to make execution prepared statement-
    safe. A shallow copy is enough as this code won't modify any memory
    referenced from this structure.
  */
  HA_CREATE_INFO create_info(*lex->create_info);
  /*
    We need to copy alter_info for the same reasons of re-execution
    safety, only in case of Alter_info we have to do (almost) a deep
    copy.
  */
  Alter_info alter_info(*m_alter_info, thd->mem_root);

  if (thd->is_error()) {
    /* If out of memory when creating a copy of alter_info. */
    return true;
  }

  if (((lex->create_info->used_fields & HA_CREATE_USED_DATADIR) != 0 ||
       (lex->create_info->used_fields & HA_CREATE_USED_INDEXDIR) != 0) &&
      check_access(thd, FILE_ACL, any_db, nullptr, nullptr, false, false)) {
    my_error(ER_SPECIFIC_ACCESS_DENIED_ERROR, MYF(0), "FILE");
    return true;
  }

  if (!thd->is_plugin_fake_ddl()) {
    if (create_table_precheck(thd, query_expression_tables, create_table))
      return true;
  }

  /* Might have been updated in create_table_precheck */
  create_info.alias = create_table->alias;

  /*
    If no engine type was given, work out the default now
    rather than at parse-time.
  */
  if (!(create_info.used_fields & HA_CREATE_USED_ENGINE))
    create_info.db_type = create_info.options & HA_LEX_CREATE_TMP_TABLE
                              ? ha_default_temp_handlerton(thd)
                              : ha_default_handlerton(thd);

  assert(create_info.db_type != nullptr);
  if ((m_alter_info->flags & Alter_info::ANY_ENGINE_ATTRIBUTE) != 0 &&
      ((create_info.db_type->flags & HTON_SUPPORTS_ENGINE_ATTRIBUTE) == 0 &&
       DBUG_EVALUATE_IF("simulate_engine_attribute_support", false, true))) {
    my_error(ER_ENGINE_ATTRIBUTE_NOT_SUPPORTED, MYF(0),
             ha_resolve_storage_engine_name(create_info.db_type));
    return true;
  }

  /*
    Assign target tablespace name to enable locking in lock_table_names().
    Reject invalid names.
  */
  if (create_info.tablespace) {
    if (validate_tablespace_name_length(create_info.tablespace) ||
        validate_tablespace_name(TS_CMD_NOT_DEFINED, create_info.tablespace,
                                 create_info.db_type))
      return true;

    if (lex_string_strmake(thd->mem_root, &create_table->target_tablespace_name,
                           create_info.tablespace,
                           strlen(create_info.tablespace)))
      return true;
  }

  // Reject invalid tablespace names specified for partitions.
  if (validate_partition_tablespace_name_lengths(part_info) ||
      validate_partition_tablespace_names(part_info, create_info.db_type))
    return true;

  /* Fix names if symlinked or relocated tables */
  if (prepare_index_and_data_dir_path(thd, &create_info.data_file_name,
                                      &create_info.index_file_name,
                                      create_table->table_name))
    return true;

  {
    partition_info *part = thd->lex->part_info;
    if (part != nullptr && has_external_data_or_index_dir(*part) &&
        check_access(thd, FILE_ACL, any_db, nullptr, nullptr, false, false)) {
      return true;
    }
    if (part && !(part = thd->lex->part_info->get_clone(thd, true)))
      return true;
    thd->work_part_info = part;
  }

  if (part_info != nullptr && part_info->part_expr &&
      part_info->part_expr->fixed) {  // @todo Code may be redundant
    part_info->fixed = true;
  }
  bool res = false;

  if (!query_block->field_list_is_empty())  // With select
  {
    /*
      CREATE TABLE...IGNORE/REPLACE SELECT... can be unsafe, unless
      ORDER BY PRIMARY KEY clause is used in SELECT statement. We therefore
      use row based logging if mixed or row based logging is available.
      TODO: Check if the order of the output of the select statement is
      deterministic. Waiting for BUG#42415
    */
    if (lex->is_ignore())
      lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_CREATE_IGNORE_SELECT);

    if (lex->duplicates == DUP_REPLACE)
      lex->set_stmt_unsafe(LEX::BINLOG_STMT_UNSAFE_CREATE_REPLACE_SELECT);

    /**
      Disallow creation of foreign keys if,

      - SE supports atomic DDL's.
      - The binlogging is enabled.
      - The binlog format is ROW.

      This is done to avoid complications involved in locking,
      updating and invalidation (in case of rollback) of DD cache
      for parent table.
    */
    if ((alter_info.flags & Alter_info::ADD_FOREIGN_KEY) &&
        (create_info.db_type->flags & HTON_SUPPORTS_ATOMIC_DDL) &&
        mysql_bin_log.is_open() &&
        (thd->variables.option_bits & OPTION_BIN_LOG) &&
        thd->variables.binlog_format == BINLOG_FORMAT_ROW) {
      my_error(ER_FOREIGN_KEY_WITH_ATOMIC_CREATE_SELECT, MYF(0));
      return true;
    }

    // Reject request to CREATE TABLE AS SELECT with START TRANSACTION.
    if (create_info.m_transactional_ddl) {
      my_error(ER_NOT_ALLOWED_WITH_START_TRANSACTION, MYF(0),
               "with CREATE TABLE ... AS SELECT statement.");
      return true;
    }

    /*
      If:
      a) we inside an SP and there was NAME_CONST substitution,
      b) binlogging is on (STMT mode),
      c) we log the SP as separate statements
      raise a warning, as it may cause problems
      (see 'NAME_CONST issues' in 'Binary Logging of Stored Programs')
     */
    if (thd->query_name_consts && mysql_bin_log.is_open() &&
        thd->variables.binlog_format == BINLOG_FORMAT_STMT &&
        !mysql_bin_log.is_query_in_union(thd, thd->query_id)) {
      uint splocal_refs = 0;
      /* Count SP local vars in the top-level SELECT list */
      for (Item *item : query_block->visible_fields()) {
        if (item->is_splocal()) splocal_refs++;
      }
      /*
        If it differs from number of NAME_CONST substitution applied,
        we may have a SOME_FUNC(NAME_CONST()) in the SELECT list,
        that may cause a problem with binary log (see BUG#35383),
        raise a warning.
      */
      if (splocal_refs != thd->query_name_consts)
        push_warning(
            thd, Sql_condition::SL_WARNING, ER_UNKNOWN_ERROR,
            "Invoked routine ran a statement that may cause problems with "
            "binary log, see 'NAME_CONST issues' in 'Binary Logging of Stored "
            "Programs' "
            "section of the manual.");
    }

    /*
      Disable non-empty MERGE tables with CREATE...SELECT. Too
      complicated. See Bug #26379. Empty MERGE tables are read-only
      and don't allow CREATE...SELECT anyway.
    */
    if (create_info.used_fields & HA_CREATE_USED_UNION) {
      my_error(ER_WRONG_OBJECT, MYF(0), create_table->db,
               create_table->table_name, "BASE TABLE");
      return true;
    }

    if (query_expression->is_prepared()) {
      cleanup(thd);
    }
    auto cleanup_se_guard = create_scope_guard(
        [lex] { lex->set_secondary_engine_execution_context(nullptr); });
    if (open_tables_for_query(thd, lex->query_tables, false)) return true;

    /* The table already exists */
    if (create_table->table || create_table->is_view()) {
      if (create_info.options & HA_LEX_CREATE_IF_NOT_EXISTS) {
        push_warning_printf(thd, Sql_condition::SL_NOTE, ER_TABLE_EXISTS_ERROR,
                            ER_THD(thd, ER_TABLE_EXISTS_ERROR),
                            create_info.alias);
        my_ok(thd);
        return false;
      } else {
        my_error(ER_TABLE_EXISTS_ERROR, MYF(0), create_info.alias);
        return false;
      }
    }

    /*
      Remove target table from main select and name resolution
      context. This can't be done earlier as it will break view merging in
      statements like "CREATE TABLE IF NOT EXISTS existing_view SELECT".
    */
    bool link_to_local;
    lex->unlink_first_table(&link_to_local);

    /* Updating any other table is prohibited in CTS statement */
    for (Table_ref *table = lex->query_tables; table;
         table = table->next_global) {
      if (table->lock_descriptor().type >= TL_WRITE_ALLOW_WRITE) {
        lex->link_first_table_back(create_table, link_to_local);

        my_error(ER_CANT_UPDATE_TABLE_IN_CREATE_TABLE_SELECT, MYF(0),
                 table->table_name, create_info.alias);
        return true;
      }
    }

    Query_result_create *result;
    if (!query_expression->is_prepared()) {
      const Prepare_error_tracker tracker(thd);
      Prepared_stmt_arena_holder ps_arena_holder(thd);
      result = new (thd->mem_root)
          Query_result_create(create_table, &query_block->fields,
                              lex->duplicates, query_expression_tables);
      if (result == nullptr) {
        lex->link_first_table_back(create_table, link_to_local);
        return true;
      }

      // Use the hypergraph optimizer for the SELECT statement, if enabled.
      lex->set_using_hypergraph_optimizer(
          thd->optimizer_switch_flag(OPTIMIZER_SWITCH_HYPERGRAPH_OPTIMIZER));

      if (query_expression->prepare(thd, result, nullptr, SELECT_NO_UNLOCK,
                                    0)) {
        lex->link_first_table_back(create_table, link_to_local);
        return true;
      }
      if (!thd->stmt_arena->is_regular() && lex->save_cmd_properties(thd)) {
        lex->link_first_table_back(create_table, link_to_local);
        return true;
      }
    } else {
      result = down_cast<Query_result_create *>(
          query_expression->query_result() != nullptr
              ? query_expression->query_result()
              : query_block->query_result());
      // Restore prepared statement properties, bind table and field information
      lex->restore_cmd_properties();
      bind_fields(thd->stmt_arena->item_list());
    }
    if (validate_use_secondary_engine(lex)) return true;

    result->set_two_fields(&create_info, &alter_info);

    // For objects acquired during table creation.
    dd::cache::Dictionary_client::Auto_releaser releaser(thd->dd_client());

    Ignore_error_handler ignore_handler;
    Strict_error_handler strict_handler;
    if (lex->is_ignore())
      thd->push_internal_handler(&ignore_handler);
    else if (thd->is_strict_mode())
      thd->push_internal_handler(&strict_handler);

    res = populate_table(thd, lex);

    // Count the number of statements offloaded to a secondary storage engine.
    if (using_secondary_storage_engine() && lex->unit->is_executed())
      ++thd->status_var.secondary_engine_execution_count;

    if (lex->is_ignore() || thd->is_strict_mode()) thd->pop_internal_handler();
    lex->cleanup(false);
    thd->clear_current_query_costs();
    lex->clear_values_map();

    // Abort the result set if execution ended in error
    if (res) result->abort_result_set(thd);

    result->cleanup();

    lex->link_first_table_back(create_table, link_to_local);
    THD_STAGE_INFO(thd, stage_end);
  } else {
    Strict_error_handler strict_handler;
    /* Push Strict_error_handler */
    if (!lex->is_ignore() && thd->is_strict_mode())
      thd->push_internal_handler(&strict_handler);
    /* regular create */
    if (create_info.options & HA_LEX_CREATE_TABLE_LIKE) {
      /* CREATE TABLE ... LIKE ... */
      res = mysql_create_like_table(thd, create_table, query_expression_tables,
                                    &create_info);
    } else {
      /* Regular CREATE TABLE */
      res = mysql_create_table(thd, create_table, &create_info, &alter_info);
    }
    /* Pop Strict_error_handler */
    if (!lex->is_ignore() && thd->is_strict_mode()) thd->pop_internal_handler();
    if (!res) {
      /* in case of create temp tables if @@session_track_state_change is
         ON then send session state notification in OK packet */
      if (create_info.options & HA_LEX_CREATE_TMP_TABLE &&
          thd->session_tracker.get_tracker(SESSION_STATE_CHANGE_TRACKER)
              ->is_enabled())
        thd->session_tracker.get_tracker(SESSION_STATE_CHANGE_TRACKER)
            ->mark_as_changed(thd, {});
      my_ok(thd);
    }
  }
  // The following code is required to make CREATE TABLE re-execution safe.
  // @todo Consider refactoring this code.
  if (part_info != nullptr) {
    if (part_info->part_expr != nullptr &&
        part_info->part_expr->type() == Item::FIELD_ITEM)
      down_cast<Item_field *>(part_info->part_expr)->reset_field();

    if (part_info->subpart_expr != nullptr &&
        part_info->subpart_expr->type() == Item::FIELD_ITEM)
      down_cast<Item_field *>(part_info->subpart_expr)->reset_field();
  }
  return res;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_delete.cc
Function: CheckSqlSafeUpdate
bool CheckSqlSafeUpdate(THD *thd, const JOIN *join) {
  if (!Overlaps(thd->variables.option_bits, OPTION_SAFE_UPDATES)) {
    return false;
  }

  if (join->query_block->has_limit()) {
    return false;
  }

  bool full_scan = false;
  WalkAccessPaths(
      join->root_access_path(), join, WalkAccessPathPolicy::ENTIRE_QUERY_BLOCK,
      [&full_scan](const AccessPath *path, const JOIN *) {
        if (path->type == AccessPath::TABLE_SCAN) {
          full_scan |= path->table_scan().table->pos_in_table_list->updating;
        } else if (path->type == AccessPath::INDEX_SCAN) {
          full_scan |= path->index_scan().table->pos_in_table_list->updating;
        }
        return full_scan;
      });

  if (full_scan) {
    // Append the first warning (if any) to the error message. The warning may
    // give the user a hint as to why index access couldn't be chosen.
    my_error(ER_UPDATE_WITHOUT_KEY_IN_SAFE_MODE, MYF(0),
             thd->get_stmt_da()->get_first_condition_message());
    return true;
  }

  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_delete.cc
Function: Sql_cmd_delete::delete_from_single_table
bool Sql_cmd_delete::delete_from_single_table(THD *thd) {
  DBUG_TRACE;

  myf error_flags = MYF(0); /**< Flag for fatal errors */
  bool will_batch;
  /*
    Most recent handler error
    =  1: Some non-handler error
    =  0: Success
    = -1: No more rows to process, or reached limit
  */
  int error = 0;
  ha_rows deleted_rows = 0;
  bool reverse = false;
  /// read_removal is only used by NDB storage engine
  bool read_removal = false;
  bool need_sort = false;

  uint usable_index = MAX_KEY;
  Query_block *const query_block = lex->query_block;
  Query_expression *const unit = query_block->master_query_expression();
  ORDER *order = query_block->order_list.first;
  Table_ref *const table_list = query_block->get_table_list();
  THD::killed_state killed_status = THD::NOT_KILLED;
  THD::enum_binlog_query_type query_type = THD::ROW_QUERY_TYPE;

  const bool safe_update = thd->variables.option_bits & OPTION_SAFE_UPDATES;

  Table_ref *const delete_table_ref = table_list->updatable_base_table();
  TABLE *const table = delete_table_ref->table;

  const bool transactional_table = table->file->has_transactions();

  const bool has_delete_triggers =
      table->triggers && table->triggers->has_delete_triggers();

  const bool has_before_triggers =
      has_delete_triggers &&
      table->triggers->has_triggers(TRG_EVENT_DELETE, TRG_ACTION_BEFORE);
  const bool has_after_triggers =
      has_delete_triggers &&
      table->triggers->has_triggers(TRG_EVENT_DELETE, TRG_ACTION_AFTER);
  unit->set_limit(thd, query_block);

  AccessPath *range_scan = nullptr;
  join_type type = JT_UNKNOWN;

  auto cleanup = create_scope_guard([&range_scan, table] {
    destroy(range_scan);
    table->set_keyread(false);
    table->file->ha_index_or_rnd_end();
    free_io_cache(table);
    filesort_free_buffers(table, true);
  });

  ha_rows limit = unit->select_limit_cnt;
  const bool using_limit = limit != HA_POS_ERROR;

  if (limit == 0 && thd->lex->is_explain()) {
    Modification_plan plan(thd, MT_DELETE, table, "LIMIT is zero", true, 0);
    bool err = explain_single_table_modification(thd, thd, &plan, query_block);
    return err;
  }

  assert(!(table->all_partitions_pruned_away || m_empty_query));

  // Used to track whether there are no rows that need to be read
  bool no_rows =
      limit == 0 || is_empty_query() || table->all_partitions_pruned_away;

  Item *conds = nullptr;
  if (!no_rows && query_block->get_optimizable_conditions(thd, &conds, nullptr))
    return true; /* purecov: inspected */

  /*
    See if we can substitute expressions with equivalent generated
    columns in the WHERE and ORDER BY clauses of the DELETE statement.
    It is unclear if this is best to do before or after the other
    substitutions performed by substitute_for_best_equal_field(). Do
    it here for now, to keep it consistent with how multi-table
    deletes are optimized in JOIN::optimize().
  */
  if (conds || order)
    static_cast<void>(substitute_gc(thd, query_block, conds, nullptr, order));

  const bool const_cond = conds == nullptr || conds->const_item();
  const bool const_cond_result = const_cond && (!conds || conds->val_int());
  if (thd->is_error())  // Error during val_int()
    return true;        /* purecov: inspected */
  /*
    We are passing HA_EXTRA_IGNORE_DUP_KEY flag here to recreate query with
    IGNORE keyword within federated storage engine. If federated engine is
    removed in the future, use of HA_EXTRA_IGNORE_DUP_KEY and
    HA_EXTRA_NO_IGNORE_DUP_KEY flag should be removed from
    delete_from_single_table(), DeleteRowsIterator::Init() and
    handler::ha_reset().
  */
  if (lex->is_ignore()) table->file->ha_extra(HA_EXTRA_IGNORE_DUP_KEY);

  /*
    Test if the user wants to delete all rows and deletion doesn't have
    any side-effects (because of triggers), so we can use optimized
    handler::delete_all_rows() method.

    We can use delete_all_rows() if and only if:
    - There is no limit clause
    - The condition is constant
    - The row set is not empty
    - We allow new functions (not using option --skip-new)
    - If there is a condition, then it it produces a non-zero value
    - If the current command is DELETE FROM with no where clause, then:
      - We will not be binlogging this statement in row-based, and
      - there should be no delete triggers associated with the table.
  */
  if (!using_limit && const_cond_result && !no_rows &&
      !(specialflag & SPECIAL_NO_NEW_FUNC) &&
      ((!thd->is_current_stmt_binlog_format_row() ||  // not ROW binlog-format
        thd->is_current_stmt_binlog_disabled()) &&    // no binlog for this
                                                      // command
       !has_delete_triggers)) {
    /* Update the table->file->stats.records number */
    table->file->info(HA_STATUS_VARIABLE | HA_STATUS_NO_LOCK);
    ha_rows const maybe_deleted = table->file->stats.records;

    Modification_plan plan(thd, MT_DELETE, table, "Deleting all rows", false,
                           maybe_deleted);
    if (lex->is_explain()) {
      bool err =
          explain_single_table_modification(thd, thd, &plan, query_block);
      return err;
    }

    /* Do not allow deletion of all records if safe_update is set. */
    if (safe_update) {
      my_error(ER_UPDATE_WITHOUT_KEY_IN_SAFE_MODE, MYF(0),
               thd->get_stmt_da()->get_first_condition_message());
      return true;
    }

    DBUG_PRINT("debug", ("Trying to use delete_all_rows()"));
    if (!(error = table->file->ha_delete_all_rows())) {
      /*
        As delete_all_rows() was used, we have to log it in statement format.
      */
      query_type = THD::STMT_QUERY_TYPE;
      error = -1;
      deleted_rows = maybe_deleted;
      goto cleanup;
    }
    if (error != HA_ERR_WRONG_COMMAND) {
      if (table->file->is_fatal_error(error)) error_flags |= ME_FATALERROR;

      table->file->print_error(error, error_flags);
      goto cleanup;
    }
    /* Handler didn't support fast delete; Delete rows one by one */
  }

  if (conds != nullptr) {
    COND_EQUAL *cond_equal = nullptr;
    Item::cond_result result;

    if (optimize_cond(thd, &conds, &cond_equal,
                      query_block->m_current_table_nest, &result))
      return true;
    if (result == Item::COND_FALSE)  // Impossible where
    {
      no_rows = true;

      if (lex->is_explain()) {
        Modification_plan plan(thd, MT_DELETE, table, "Impossible WHERE", true,
                               0);
        bool err =
            explain_single_table_modification(thd, thd, &plan, query_block);
        return err;
      }
    }
    if (conds) {
      conds = substitute_for_best_equal_field(thd, conds, cond_equal, nullptr);
      if (conds == nullptr) return true;

      conds->update_used_tables();
    }
  }

  /* Prune a second time to be able to prune on subqueries in WHERE clause. */
  if (table->part_info && !no_rows) {
    if (prune_partitions(thd, table, query_block, conds)) return true;
    if (table->all_partitions_pruned_away) {
      no_rows = true;
      if (lex->is_explain()) {
        Modification_plan plan(thd, MT_DELETE, table,
                               "No matching rows after partition pruning", true,
                               0);
        bool err =
            explain_single_table_modification(thd, thd, &plan, query_block);
        return err;
      }
      my_ok(thd, 0);
      return false;
    }
  }

  // Initialize the cost model that will be used for this table
  table->init_cost_model(thd->cost_model());

  /* Update the table->file->stats.records number */
  table->file->info(HA_STATUS_VARIABLE | HA_STATUS_NO_LOCK);

  table->covering_keys.clear_all();

  if (conds &&
      thd->optimizer_switch_flag(OPTIMIZER_SWITCH_ENGINE_CONDITION_PUSHDOWN)) {
    table->file->cond_push(conds);
  }

  {  // Enter scope for optimizer trace wrapper
    Opt_trace_object wrapper(&thd->opt_trace);
    wrapper.add_utf8_table(delete_table_ref);

    if (!no_rows && conds != nullptr) {
      Key_map keys_to_use(Key_map::ALL_BITS), needed_reg_dummy;
      MEM_ROOT temp_mem_root(key_memory_test_quick_select_exec,
                             thd->variables.range_alloc_block_size);
      no_rows = test_quick_select(
                    thd, thd->mem_root, &temp_mem_root, keys_to_use, 0, 0,
                    limit, safe_update, ORDER_NOT_RELEVANT, table,
                    /*skip_records_in_range=*/false, conds, &needed_reg_dummy,
                    table->force_index, query_block, &range_scan) < 0;
    }
    if (thd->is_error())  // test_quick_select() has improper error propagation
      return true;

    if (no_rows) {
      if (lex->is_explain()) {
        Modification_plan plan(thd, MT_DELETE, table, "Impossible WHERE", true,
                               0);
        bool err =
            explain_single_table_modification(thd, thd, &plan, query_block);
        return err;
      }

      my_ok(thd, 0);
      return false;  // Nothing to delete
    }
  }  // Ends scope for optimizer trace wrapper

  /* If running in safe sql mode, don't allow updates without keys */
  if (table->quick_keys.is_clear_all()) {
    thd->server_status |= SERVER_QUERY_NO_INDEX_USED;

    /*
      Safe update error isn't returned if:
      1) It is  an EXPLAIN statement OR
      2) LIMIT is present.

      Append the first warning (if any) to the error message. This allows the
      user to understand why index access couldn't be chosen.
    */
    if (!thd->lex->is_explain() && safe_update && !using_limit) {
      my_error(ER_UPDATE_WITHOUT_KEY_IN_SAFE_MODE, MYF(0),
               thd->get_stmt_da()->get_first_condition_message());
      return true;
    }
  }

  if (order) {
    if (conds != nullptr) table->update_const_key_parts(conds);
    order = simple_remove_const(order, conds);
    ORDER_with_src order_src(order, ESC_ORDER_BY, /*const_optimized=*/true);
    usable_index = get_index_for_order(&order_src, table, limit, range_scan,
                                       &need_sort, &reverse);
    if (range_scan != nullptr) {
      // May have been changed by get_index_for_order().
      type = calc_join_type(range_scan);
    }
  }

  // Reaching here only when table must be accessed
  assert(!no_rows);

  {
    ha_rows rows;
    if (range_scan)
      rows = range_scan->num_output_rows();
    else if (!conds && !need_sort && limit != HA_POS_ERROR)
      rows = limit;
    else {
      delete_table_ref->fetch_number_of_rows();
      rows = table->file->stats.records;
    }
    Modification_plan plan(thd, MT_DELETE, table, type, range_scan, conds,
                           usable_index, limit, false, need_sort, false, rows);
    DEBUG_SYNC(thd, "planned_single_delete");

    if (lex->is_explain()) {
      bool err =
          explain_single_table_modification(thd, thd, &plan, query_block);
      return err;
    }

    if (query_block->active_options() & OPTION_QUICK)
      (void)table->file->ha_extra(HA_EXTRA_QUICK);

    unique_ptr_destroy_only<Filesort> fsort;
    JOIN join(thd, query_block);  // Only for holding examined_rows.
    AccessPath *path;
    if (usable_index == MAX_KEY || range_scan) {
      path =
          create_table_access_path(thd, table, range_scan,
                                   /*table_ref=*/nullptr, /*position=*/nullptr,
                                   /*count_examined_rows=*/true);
    } else {
      empty_record(table);
      path = NewIndexScanAccessPath(thd, table, usable_index,
                                    /*use_order=*/true, reverse,
                                    /*count_examined_rows=*/false);
    }

    unique_ptr_destroy_only<RowIterator> iterator;
    if (need_sort) {
      assert(usable_index == MAX_KEY);

      if (conds != nullptr) {
        path = NewFilterAccessPath(thd, path, conds);
      }

      fsort.reset(new (thd->mem_root) Filesort(
          thd, {table}, /*keep_buffers=*/false, order, HA_POS_ERROR,
          /*remove_duplicates=*/false,
          /*force_sort_rowids=*/true, /*unwrap_rollup=*/false));
      path = NewSortAccessPath(thd, path, fsort.get(), order,
                               /*count_examined_rows=*/false);
      iterator = CreateIteratorFromAccessPath(thd, path, &join,
                                              /*eligible_for_batch_mode=*/true);
      // Prevent cleanup in JOIN::destroy() and in the cleanup condition guard,
      // to avoid double-destroy of the SortingIterator.
      table->sorting_iterator = nullptr;
      if (iterator == nullptr || iterator->Init()) return true;
      thd->inc_examined_row_count(join.examined_rows);

      /*
        Filesort has already found and selected the rows we want to delete,
        so we don't need the where clause
      */
      conds = nullptr;
    } else {
      iterator = CreateIteratorFromAccessPath(thd, path, &join,
                                              /*eligible_for_batch_mode=*/true);
      // Prevent cleanup in JOIN::destroy() and in the cleanup condition guard,
      // to avoid double-destroy of the SortingIterator.
      table->sorting_iterator = nullptr;
      if (iterator->Init()) return true;
    }

    if (query_block->has_ft_funcs() && init_ftfuncs(thd, query_block))
      return true; /* purecov: inspected */

    THD_STAGE_INFO(thd, stage_updating);

    if (has_after_triggers) {
      /*
        The table has AFTER DELETE triggers that might access to subject table
        and therefore might need delete to be done immediately. So we turn-off
        the batching.
      */
      (void)table->file->ha_extra(HA_EXTRA_DELETE_CANNOT_BATCH);
      will_batch = false;
    } else {
      // No after delete triggers, attempt to start bulk delete
      will_batch = !table->file->start_bulk_delete();
    }
    table->mark_columns_needed_for_delete(thd);
    if (thd->is_error()) return true;

    if ((table->file->ha_table_flags() & HA_READ_BEFORE_WRITE_REMOVAL) &&
        !using_limit && !has_delete_triggers && range_scan &&
        used_index(range_scan) != MAX_KEY)
      read_removal = table->check_read_removal(used_index(range_scan));

    assert(limit > 0);

    // The loop that reads rows and delete those that qualify

    while (!(error = iterator->Read()) && !thd->killed) {
      assert(!thd->is_error());
      thd->inc_examined_row_count(1);

      if (conds != nullptr) {
        const bool skip_record = conds->val_int() == 0;
        if (thd->is_error()) {
          error = 1;
          break;
        }
        if (skip_record) {
          // Row failed condition check, release lock
          table->file->unlock_row();
          continue;
        }
      }

      assert(!thd->is_error());

      if (DeleteCurrentRowAndProcessTriggers(thd, table, has_before_triggers,
                                             has_after_triggers,
                                             &deleted_rows)) {
        error = 1;
        break;
      }

      if (!--limit && using_limit) {
        error = -1;
        break;
      }
    }

    killed_status = thd->killed;
    if (killed_status != THD::NOT_KILLED || thd->is_error())
      error = 1;  // Aborted
    int loc_error;
    if (will_batch && (loc_error = table->file->end_bulk_delete())) {
      /* purecov: begin inspected */
      if (error != 1) {
        if (table->file->is_fatal_error(loc_error))
          error_flags |= ME_FATALERROR;

        table->file->print_error(loc_error, error_flags);
      }
      error = 1;
      /* purecov: end */
    }
    if (read_removal) {
      /* Only handler knows how many records were really written */
      deleted_rows = table->file->end_read_removal();
    }
    if (query_block->active_options() & OPTION_QUICK)
      (void)table->file->ha_extra(HA_EXTRA_NORMAL);
  }  // End of scope for Modification_plan

cleanup:
  assert(!lex->is_explain());

  if (!transactional_table && deleted_rows > 0)
    thd->get_transaction()->mark_modified_non_trans_table(
        Transaction_ctx::STMT);

  /* See similar binlogging code in sql_update.cc, for comments */
  if ((error < 0) ||
      thd->get_transaction()->cannot_safely_rollback(Transaction_ctx::STMT)) {
    if (mysql_bin_log.is_open()) {
      int errcode = 0;
      if (error < 0)
        thd->clear_error();
      else
        errcode = query_error_code(thd, killed_status == THD::NOT_KILLED);

      /*
        [binlog]: As we don't allow the use of 'handler:delete_all_rows()' when
        binlog_format == ROW, if 'handler::delete_all_rows()' was called
        we replicate statement-based; otherwise, 'ha_delete_row()' was used to
        delete specific rows which we might log row-based.
      */
      int log_result =
          thd->binlog_query(query_type, thd->query().str, thd->query().length,
                            transactional_table, false, false, errcode);

      if (log_result) {
        error = 1;
      }
    }
  }
  assert(transactional_table || deleted_rows == 0 ||
         thd->get_transaction()->cannot_safely_rollback(Transaction_ctx::STMT));
  if (error < 0) {
    my_ok(thd, deleted_rows);
    DBUG_PRINT("info", ("%ld records deleted", (long)deleted_rows));
  }
  return error > 0;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_insert.cc
Function: Sql_cmd_insert_values::execute_inner
bool Sql_cmd_insert_values::execute_inner(THD *thd) {
  DBUG_TRACE;

  assert(thd->lex->sql_command == SQLCOM_REPLACE ||
         thd->lex->sql_command == SQLCOM_INSERT);

  /*
    We have three alternative syntax rules for the INSERT statement:
    1) "INSERT (columns) VALUES ...", so non-listed columns need a default
    2) "INSERT VALUES (), ..." so all columns need a default;
    note that "VALUES (),(expr_1, ..., expr_n)" is not allowed, so checking
    emptiness of the first row is enough
    3) "INSERT VALUES (expr_1, ...), ..." so no defaults are needed; even if
    expr_i is "DEFAULT" (in which case the column is set by
    Item_default_value::save_in_field_inner()).
  */
  const bool manage_defaults = column_count > 0 ||  // 1)
                               value_count == 0;    // 2)
  COPY_INFO info(COPY_INFO::INSERT_OPERATION, &insert_field_list,
                 manage_defaults, duplicates);
  COPY_INFO update(COPY_INFO::UPDATE_OPERATION, &update_field_list,
                   &update_value_list);

  Query_block *const query_block = lex->query_block;

  Table_ref *const table_list = lex->insert_table;
  TABLE *const insert_table = lex->insert_table_leaf->table;

  if (duplicates == DUP_UPDATE || duplicates == DUP_REPLACE)
    prepare_for_positional_update(insert_table, table_list);

  /* Must be done before can_prune_insert, due to internal initialization. */
  if (info.add_function_default_columns(insert_table, insert_table->write_set))
    return true; /* purecov: inspected */
  if (duplicates == DUP_UPDATE && update.add_function_default_columns(
                                      insert_table, insert_table->write_set))
    return true; /* purecov: inspected */

  // Current error state inside and after the insert loop
  bool has_error = false;

  {  // Statement plan is available within these braces
    Modification_plan plan(
        thd, (lex->sql_command == SQLCOM_INSERT) ? MT_INSERT : MT_REPLACE,
        insert_table, nullptr, false, 0);
    DEBUG_SYNC(thd, "planned_single_insert");

    if (lex->is_explain()) {
      bool err =
          explain_single_table_modification(thd, thd, &plan, query_block);
      return err;
    }

    insert_table->next_number_field = insert_table->found_next_number_field;

    THD_STAGE_INFO(thd, stage_update);
    if (duplicates == DUP_REPLACE &&
        (!insert_table->triggers ||
         !insert_table->triggers->has_delete_triggers()))
      insert_table->file->ha_extra(HA_EXTRA_WRITE_CAN_REPLACE);
    if (duplicates == DUP_UPDATE)
      insert_table->file->ha_extra(HA_EXTRA_INSERT_WITH_UPDATE);
    /*
      let's *try* to start bulk inserts. It won't necessary
      start them as insert_many_values.elements should be greater than
      some - handler dependent - threshold.
      We should not start bulk inserts if this statement uses
      functions or invokes triggers since they may access
      to the same table and therefore should not see its
      inconsistent state created by this optimization.
      So we call start_bulk_insert to perform nesessary checks on
      insert_many_values.elements, and - if nothing else - to initialize
      the code to make the call of end_bulk_insert() below safe.
    */
    if (duplicates != DUP_ERROR || lex->is_ignore())
      insert_table->file->ha_extra(HA_EXTRA_IGNORE_DUP_KEY);
    /*
       This is a simple check for the case when the table has a trigger
       that reads from it, or when the statement invokes a stored function
       that reads from the table being inserted to.
       Engines can't handle a bulk insert in parallel with a read form the
       same table in the same connection.
    */
    if (thd->locked_tables_mode <= LTM_LOCK_TABLES)
      insert_table->file->ha_start_bulk_insert(insert_many_values.size());

    prepare_triggers_for_insert_stmt(thd, insert_table);

    /*
      Count warnings for all inserts. For single row insert, generate an error
      if trying to set a NOT NULL field to NULL.
      Notice that policy must be reset before leaving this function.
    */
    thd->check_for_truncated_fields =
        ((insert_many_values.size() == 1 && !lex->is_ignore())
             ? CHECK_FIELD_ERROR_FOR_NULL
             : CHECK_FIELD_WARN);
    thd->num_truncated_fields = 0L;

    for (Field **next_field = insert_table->field; *next_field; ++next_field) {
      (*next_field)->reset_warnings();
    }

    for (const List_item *values : insert_many_values) {
      Autoinc_field_has_explicit_non_null_value_reset_guard after_each_row(
          insert_table);

      restore_record(insert_table, s->default_values);  // Get empty record
      /*
        Check whether default values of the insert_field_list not specified in
        column list are correct or not.
      */
      if (validate_default_values_of_unset_fields(thd, insert_table)) {
        has_error = true;
        break;
      }
      if (fill_record_n_invoke_before_triggers(
              thd, &info, insert_field_list, *values, insert_table,
              TRG_EVENT_INSERT, insert_table->s->fields, true, nullptr)) {
        assert(thd->is_error());
        /*
          TODO: Convert warnings to errors if values_list.elements == 1
          and check that all items return warning in case of problem with
          storing field.
        */
        has_error = true;
        break;
      }

      if (check_that_all_fields_are_given_values(thd, insert_table,
                                                 table_list)) {
        assert(thd->is_error());
        has_error = true;
        break;
      }

      const int check_result = table_list->view_check_option(thd);
      if (check_result == VIEW_CHECK_SKIP)
        continue;
      else if (check_result == VIEW_CHECK_ERROR) {
        has_error = true;
        break;
      }

      if (invoke_table_check_constraints(thd, insert_table)) {
        if (thd->is_error()) {
          has_error = true;
          break;
        }
        // continue when IGNORE clause is used.
        continue;
      }

      if (write_record(thd, insert_table, &info, &update)) {
        has_error = true;
        break;
      }
      thd->get_stmt_da()->inc_current_row_for_condition();
    }
  }  // Statement plan is available within these braces

  assert(has_error == thd->get_stmt_da()->is_error());

  /*
    Now all rows are inserted.  Time to update logs and sends response to
    user
  */
  {
    /* TODO: Only call this if insert_table->found_next_number_field.*/
    insert_table->file->ha_release_auto_increment();
    /*
      Make sure 'end_bulk_insert()' is called regardless of current error
    */
    int loc_error = 0;
    if (thd->locked_tables_mode <= LTM_LOCK_TABLES)
      loc_error = insert_table->file->ha_end_bulk_insert();
    /*
      Report error if 'end_bulk_insert()' failed, and set 'has_error'
    */
    if (loc_error && !has_error) {
      /* purecov: begin inspected */
      myf error_flags = MYF(0);
      if (insert_table->file->is_fatal_error(loc_error))
        error_flags |= ME_FATALERROR;

      insert_table->file->print_error(loc_error, error_flags);
      has_error = true;
      /* purecov: end */
    }

    const bool transactional_table = insert_table->file->has_transactions();

    const bool changed [[maybe_unused]] =
        info.stats.copied || info.stats.deleted || info.stats.updated;

    if (!has_error ||
        thd->get_transaction()->cannot_safely_rollback(Transaction_ctx::STMT)) {
      if (mysql_bin_log.is_open()) {
        int errcode = 0;
        if (!has_error) {
          /*
            [Guilhem wrote] Temporary errors may have filled
            thd->net.last_error/errno.  For example if there has
            been a disk full error when writing the row, and it was
            MyISAM, then thd->net.last_error/errno will be set to
            "disk full"... and the mysql_file_pwrite() will wait until free
            space appears, and so when it finishes then the
            write_row() was entirely successful
          */
          /* todo: consider removing */
          thd->clear_error();
        } else
          errcode = query_error_code(thd, thd->killed == THD::NOT_KILLED);

        /* bug#22725:

        A query which per-row-loop can not be interrupted with
        KILLED, like INSERT, and that does not invoke stored
        routines can be binlogged with neglecting the KILLED error.

        If there was no error (has_error == false) until after the end of
        inserting loop the KILLED flag that appeared later can be
        disregarded since previously possible invocation of stored
        routines did not result in any error due to the KILLED.  In
        such case the flag is ignored for constructing binlog event.
        */
        if (thd->binlog_query(THD::ROW_QUERY_TYPE, thd->query().str,
                              thd->query().length, transactional_table, false,
                              false, errcode))
          has_error = true;
      }
    }
    assert(
        transactional_table || !changed ||
        thd->get_transaction()->cannot_safely_rollback(Transaction_ctx::STMT));
  }
  /*
    We'll report to the client this id:
    - if the table contains an autoincrement column and we successfully
    inserted an autogenerated value, the autogenerated value.
    - if the table contains no autoincrement column and LAST_INSERT_ID(X) was
    called, X.
    - if the table contains an autoincrement column, and some rows were
    inserted, the id of the last "inserted" row (if IGNORE, that value may not
    have been really inserted but ignored).
  */
  ulonglong id =
      (thd->first_successful_insert_id_in_cur_stmt > 0)
          ? thd->first_successful_insert_id_in_cur_stmt
          : (thd->arg_of_last_insert_id_function
                 ? thd->first_successful_insert_id_in_prev_stmt
                 : ((insert_table->next_number_field && info.stats.copied)
                        ? insert_table->next_number_field->val_int()
                        : 0));
  insert_table->next_number_field = nullptr;

  // Remember to restore warning handling before leaving
  thd->check_for_truncated_fields = CHECK_FIELD_IGNORE;

  assert(has_error == thd->get_stmt_da()->is_error());
  if (has_error) return true;

  if (insert_many_values.size() == 1 &&
      (!(thd->variables.option_bits & OPTION_WARNINGS) ||
       !thd->num_truncated_fields)) {
    my_ok(thd,
          info.stats.copied + info.stats.deleted +
              (thd->get_protocol()->has_client_capability(CLIENT_FOUND_ROWS)
                   ? info.stats.touched
                   : info.stats.updated),
          id);
  } else {
    char buff[160];
    ha_rows updated =
        thd->get_protocol()->has_client_capability(CLIENT_FOUND_ROWS)
            ? info.stats.touched
            : info.stats.updated;
    if (lex->is_ignore())
      snprintf(buff, sizeof(buff), ER_THD(thd, ER_INSERT_INFO),
               (long)info.stats.records,
               (long)(info.stats.records - info.stats.copied),
               (long)thd->get_stmt_da()->current_statement_cond_count());
    else
      snprintf(buff, sizeof(buff), ER_THD(thd, ER_INSERT_INFO),
               (long)info.stats.records, (long)(info.stats.deleted + updated),
               (long)thd->get_stmt_da()->current_statement_cond_count());
    my_ok(thd, info.stats.copied + info.stats.deleted + updated, id, buff);
  }

  /*
    If we have inserted into a VIEW, and the base table has
    AUTO_INCREMENT column, but this column is not accessible through
    a view, then we should restore LAST_INSERT_ID to the value it
    had before the statement.
  */
  if (table_list->is_view() && !table_list->contain_auto_increment)
    thd->first_successful_insert_id_in_cur_stmt =
        thd->first_successful_insert_id_in_prev_stmt;

  DBUG_EXECUTE_IF("after_mysql_insert", {
    const char act[] =
        "now "
        "wait_for signal.continue";
    assert(opt_debug_sync_timeout > 0);
    assert(!debug_sync_set_action(thd, STRING_WITH_LEN(act)));
  };);

  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_truncate.cc
Function: Sql_cmd_truncate_table::truncate_base
void Sql_cmd_truncate_table::truncate_base(THD *thd, Table_ref *table_ref) {
  DBUG_TRACE;
  assert(is_temporary_table(table_ref) == false);

  m_error = true;
  bool binlog_stmt = false;
  bool binlog_is_trans = false;
  handlerton *hton = nullptr;

  assert((!table_ref->table) || (table_ref->table && table_ref->table->s));
  assert(m_ticket_downgrade == nullptr);

  /*
    Truncate is allowed for performance schema tables in both read_only and
    super_read_only mode.
  */
  if (is_perfschema_db(table_ref->db)) thd->set_skip_readonly_check();

  dd::Schema_MDL_locker mdl_locker(thd);
  dd::cache::Dictionary_client::Auto_releaser releaser(thd->dd_client());

  // Actions needed to cleanup before leaving scope.
  auto cleanup_guard = create_scope_guard([&]() {
    end_transaction(thd, binlog_stmt, binlog_is_trans);
    cleanup_base(thd, hton);
  });
  if (mdl_locker.ensure_locked(table_ref->db)) return;

  if (lock_table(thd, table_ref)) return;

  Table_ddl_hton_notification_guard notification_guard{
      thd, &table_ref->mdl_request.key, ha_ddl_type::HA_TRUNCATE_DDL};

  if (notification_guard.notify()) return;

  dd::Table *table_def = nullptr;
  if (thd->dd_client()->acquire_for_modification(
          table_ref->db, table_ref->table_name, &table_def)) {
    return;
  }
  if (table_def == nullptr ||
      table_def->hidden() == dd::Abstract_table::HT_HIDDEN_SE) {
    my_error(ER_NO_SUCH_TABLE, MYF(0), table_ref->db, table_ref->table_name);
    return;
  }
  assert(table_def != nullptr);

  if (table_def->options().exists("secondary_engine")) {
    LEX_CSTRING secondary_engine;
    table_def->options().get("secondary_engine", &secondary_engine,
                             thd->mem_root);

    DBUG_EXECUTE_IF("simulate_error_in_truncate_ddl", {
      my_error(ER_SECONDARY_ENGINE, MYF(0), "Simulated truncate ddl error");
      return;
    });
    if (!ha_secondary_engine_supports_ddl(thd, secondary_engine)) {
      my_error(ER_SECONDARY_ENGINE_DDL, MYF(0));
      return;
    }
  }

  if (dd::table_storage_engine(thd, table_def, &hton)) {
    return;
  }
  assert(hton != nullptr);

  /*
    Check if table can't be truncated because there is a foreign key
    on some other table which references it.
  */
  if (!(thd->variables.option_bits & OPTION_NO_FOREIGN_KEY_CHECKS)) {
    if (fk_truncate_illegal_if_parent(thd, table_ref, table_def)) {
      return;
    }
  }

  if (hton->flags & HTON_CAN_RECREATE) {
    // Set this before any potential error returns
    binlog_is_trans = (hton->flags & HTON_SUPPORTS_ATOMIC_DDL);

    if (mysql_audit_table_access_notify(thd, table_ref) != 0) {
      return;
    }

    /*
      The storage engine can truncate the table by creating an
      empty table with the same structure.
    */
    HA_CREATE_INFO create_info;

    // Create a path to the table, but without a extension
    char path[FN_REFLEN + 1];
    build_table_filename(path, sizeof(path) - 1, table_ref->db,
                         table_ref->table_name, "", 0);

    // Attempt to reconstruct the table
    if (ha_create_table(thd, path, table_ref->db, table_ref->table_name,
                        &create_info, true, false, table_def) != 0) {
      return;
    }

    // Binlog only if truncate-by-recreate succeeds.
    m_error = false;
    binlog_stmt = true;
    return;
  }  // hton->flags & HTON_CAN_RECREATE

  assert((hton->flags & HTON_CAN_RECREATE) == false);
  /*
    The engine does not support truncate-by-recreate.
    Attempt to use the handler truncate method.
    MYSQL_AUDIT_TABLE_ACCESS_READ audit event is generated when opening
    tables using open_tables function.
  */
  const Truncate_result tr = handler_truncate_base(thd, table_ref, table_def);
  switch (tr) {
      /*
        All effects of a TRUNCATE TABLE operation are committed even if
        truncation fails in the case of non transactional tables. Thus, the
        query must be written to the binary log for such tables.
        The exceptions are failure to open table or unimplemented truncate
        method.
      */
    case Truncate_result::OK:
      m_error = false;
      [[fallthrough]];
    case Truncate_result::FAILED_BUT_BINLOG:
      binlog_stmt = true;
      binlog_is_trans = table_ref->table->file->has_transactions();
      [[fallthrough]];
    case Truncate_result::FAILED_SKIP_BINLOG:
      /*
        Call to handler_truncate() might have updated table definition
        in the data-dictionary, let us remove TABLE_SHARE from the TDC.
        This needs to be done even in case of failure so InnoDB SE
        properly invalidates its internal cache.
      */
      close_all_tables_for_name(thd, table_ref->table->s, false, nullptr);
      break;

    case Truncate_result::FAILED_OPEN:
      // Nothing to do here
      break;

    default:
      assert(false);
  };

  assert(m_error || !thd->get_stmt_da()->is_set());
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/event_scheduler.cc
Function: pre_init_event_thread
    pre_init_event_thread()
      thd  The THD of the thread. Has to be allocated by the caller.

  NOTES
    1. The host of the thead is my_localhost
    2. thd->net is initted with NULL - no communication.
*/

void pre_init_event_thread(THD *thd) {
  DBUG_TRACE;
  thd->security_context()->set_master_access(0);
  thd->security_context()->cache_current_db_access(0);
  thd->security_context()->set_host_or_ip_ptr(my_localhost,
                                              strlen(my_localhost));
  thd->get_protocol_classic()->init_net(nullptr);
  thd->security_context()->set_user_ptr(STRING_WITH_LEN("event_scheduler"));
  thd->get_protocol_classic()->get_net()->read_timeout = replica_net_timeout;
  thd->slave_thread = false;
  thd->variables.option_bits |= OPTION_AUTO_IS_NULL;
  thd->get_protocol_classic()->set_client_capabilities(CLIENT_MULTI_RESULTS);

  thd->set_new_thread_id();

  /*
    Guarantees that we will see the thread in SHOW PROCESSLIST though its
    vio is NULL.
  */

  thd->set_proc_info("Initialized");
  thd->set_time();

  /* Do not use user-supplied timeout value for system threads. */
  thd->variables.lock_wait_timeout = LONG_TIMEOUT;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_rli.h
Function: Relay_log_info::is_in_trx_or_stmt
  bool is_in_trx_or_stmt() const {
    bool ret = is_in_stmt() || (info_thd->variables.option_bits & OPTION_BEGIN);
    DBUG_PRINT("info", ("is_in_trx_or_stmt()=%d", ret));
    return ret;
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_rli.h
Function: Relay_log_info::is_in_group
  bool is_in_group() const {
    bool ret = is_in_trx_or_stmt() || info_thd->owned_gtid.sidno != 0;
    DBUG_PRINT("info", ("is_in_group()=%d", ret));
    return ret;
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/libbinlogevents/src/statement_events.cpp
Function: binary_log::Query_event::Query_event
Query_event::Query_event(Log_event_type type_arg)
    : Binary_log_event(type_arg),
      query(nullptr),
      db(nullptr),
      user(nullptr),
      user_len(0),
      host(nullptr),
      host_len(0),
      db_len(0),
      q_len(0) {}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_gtid_persist.cc
Function: Gtid_table_access_context::init
bool Gtid_table_access_context::init(THD **thd, TABLE **table, bool is_write) {
  DBUG_TRACE;

  if (!(*thd)) *thd = m_drop_thd_object = this->create_thd();
  if (!(*thd)->is_cmd_skip_readonly()) {
    (*thd)->set_skip_readonly_check();
    this->m_skip_readonly_set = true;
  }
  m_is_write = is_write;
  if (m_is_write) {
    /* Disable binlog temporarily */
    m_tmp_disable_binlog__save_options = (*thd)->variables.option_bits;
    (*thd)->variables.option_bits &= ~OPTION_BIN_LOG;
  }

  if (!(*thd)->get_transaction()->xid_state()->has_state(XID_STATE::XA_NOTR)) {
    /*
      This type of caller of Attachable_trx_rw is deadlock-free with
      the main transaction thanks to rejection to update
      'mysql.gtid_executed' by XA main transaction.
    */
    assert(
        (*thd)->get_transaction()->xid_state()->has_state(XID_STATE::XA_IDLE) ||
        (*thd)->get_transaction()->xid_state()->has_state(
            XID_STATE::XA_PREPARED));

    (*thd)->begin_attachable_rw_transaction();
  }

  (*thd)->is_operating_gtid_table_implicitly = true;
  bool ret = this->open_table(
      *thd, DB_NAME, TABLE_NAME, Gtid_table_persistor::number_fields,
      m_is_write ? TL_WRITE : TL_READ, table, &m_backup);

  return ret;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_gtid_persist.cc
Function: Gtid_table_access_context::deinit
bool Gtid_table_access_context::deinit(THD *thd, TABLE *table, bool error,
                                       bool need_commit) {
  DBUG_TRACE;

  bool err;

  /*
    This fails on errors committing the info, or when
    replica_preserve_commit_order is enabled and a previous transaction
    has failed.  In both cases, the error is reported already.
  */
  err = this->close_table(thd, table, &m_backup, 0 != error, need_commit);

  /*
    If Gtid is inserted through Attachable_trx_rw its has been done
    in the above close_table() through ha_commit_trans().
    It does not have any side effect on the global transaction state
    as the only vulnerable part there relates to gtid (and is blocked
    from recursive invocation).
  */
  if (thd->is_attachable_rw_transaction_active())
    thd->end_attachable_transaction();

  thd->is_operating_gtid_table_implicitly = false;
  /* Re-enable binlog */
  if (m_is_write)
    thd->variables.option_bits = m_tmp_disable_binlog__save_options;
  if (this->m_skip_readonly_set) {
    thd->reset_skip_readonly_check();
    this->m_skip_readonly_set = false;
  }
  if (m_drop_thd_object) this->drop_thd(m_drop_thd_object);

  return err;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/sql_binlog.cc
Function: mysql_client_binlog_statement
void mysql_client_binlog_statement(THD *thd) {
  DBUG_TRACE;
  DBUG_PRINT("info", ("binlog base64: '%*s'",
                      (int)(thd->lex->binlog_stmt_arg.length < 2048
                                ? thd->lex->binlog_stmt_arg.length
                                : 2048),
                      thd->lex->binlog_stmt_arg.str));

  Security_context *sctx = thd->security_context();
  if (!(sctx->check_access(SUPER_ACL) ||
        sctx->has_global_grant(STRING_WITH_LEN("BINLOG_ADMIN")).first ||
        sctx->has_global_grant(STRING_WITH_LEN("REPLICATION_APPLIER")).first)) {
    my_error(ER_SPECIFIC_ACCESS_DENIED_ERROR, MYF(0),
             "SUPER, BINLOG_ADMIN or REPLICATION_APPLIER");
    return;
  }

  size_t coded_len = thd->lex->binlog_stmt_arg.length;
  if (!coded_len) {
    my_error(ER_SYNTAX_ERROR, MYF(0));
    return;
  }
  size_t decoded_len = base64_needed_decoded_length(coded_len);

  /*
    option_bits will be changed when applying the event. But we don't expect
    it be changed permanently after BINLOG statement, so backup it first.
    It will be restored at the end of this function.
  */
  ulonglong thd_options = thd->variables.option_bits;

  /*
    Allocation
  */
  int err = 0;
  Relay_log_info *rli = thd->rli_fake;
  if (!rli) {
    /*
      We create a Relay_log_info object with a INFO_REPOSITORY_DUMMY because
      to process a BINLOG command a real repository is not necessary. In the
      future, we need to improve the code around the BINLOG command as only a
      small part of the object is required to execute it. / Alfranio
    */

    /* when trying to create an rli from a client, there is no channel*/
    if ((rli = Rpl_info_factory::create_rli(INFO_REPOSITORY_DUMMY, false,
                                            (const char *)"", true))) {
      thd->rli_fake = rli;
      rli->info_thd = thd;
    }
  }

  const char *error = nullptr;
  char *buf = (char *)my_malloc(key_memory_binlog_statement_buffer, decoded_len,
                                MYF(MY_WME));
  Log_event *ev = nullptr;

  /*
    Out of memory check
  */
  if (!(rli && buf)) {
    my_error(ER_OUTOFMEMORY, MYF(ME_FATALERROR), 1); /* needed 1 bytes */
    goto end;
  }

  assert(rli->belongs_to_client());

  for (char const *strptr = thd->lex->binlog_stmt_arg.str;
       strptr <
       thd->lex->binlog_stmt_arg.str + thd->lex->binlog_stmt_arg.length;) {
    char const *endptr = nullptr;
    int64 bytes_decoded = base64_decode(strptr, coded_len, buf, &endptr,
                                        MY_BASE64_DECODE_ALLOW_MULTIPLE_CHUNKS);

    DBUG_PRINT("info",
               ("bytes_decoded: %" PRId64 "  strptr: %p  endptr: %p ('%c':%d)",
                bytes_decoded, strptr, endptr, *endptr, *endptr));

    if (bytes_decoded < 0) {
      my_error(ER_BASE64_DECODE_ERROR, MYF(0));
      goto end;
    } else if (bytes_decoded == 0)
      break;  // If no bytes where read, the string contained only whitespace

    assert(bytes_decoded > 0);
    assert(endptr > strptr);
    coded_len -= endptr - strptr;
    strptr = endptr;

    /*
      Now we have one or more events stored in the buffer. The size of
      the buffer is computed based on how much base64-encoded data
      there were, so there should be ample space for the data (maybe
      even too much, since a statement can consist of a considerable
      number of events).

      TODO: Switch to use a stream-based base64 encoder/decoder in
      order to be able to read exactly what is necessary.
    */

    DBUG_PRINT("info",
               ("binlog base64 decoded_len: %lu  bytes_decoded: %" PRId64,
                (ulong)decoded_len, bytes_decoded));

    /*
      Now we start to read events of the buffer, until there are no
      more.
    */
    for (char *bufptr = buf; bytes_decoded > 0;) {
      /*
        Checking that the first event in the buffer is not truncated.
      */
      ulong event_len;
      if (bytes_decoded < EVENT_LEN_OFFSET + 4 ||
          (event_len = uint4korr(bufptr + EVENT_LEN_OFFSET)) >
              (uint)bytes_decoded) {
        my_error(ER_SYNTAX_ERROR, MYF(0));
        goto end;
      }
      DBUG_PRINT("info", ("event_len=%lu, bytes_decoded=%" PRId64, event_len,
                          bytes_decoded));

      if (check_event_type(bufptr[EVENT_TYPE_OFFSET], rli)) goto end;

      Binlog_read_error binlog_read_error = binlog_event_deserialize(
          reinterpret_cast<unsigned char *>(bufptr), event_len,
          rli->get_rli_description_event(), false, &ev);
      if (binlog_read_error.has_error()) {
        DBUG_PRINT("info",
                   ("binlog base64 err=%s", binlog_read_error.get_str()));
        /*
          This could actually be an out-of-memory, but it is more likely
          caused by a bad statement
        */
        my_error(ER_SYNTAX_ERROR, MYF(0));
        goto end;
      }

      bytes_decoded -= event_len;
      bufptr += event_len;

      DBUG_PRINT("info", ("ev->common_header()=%d", ev->get_type_code()));
      ev->thd = thd;
      /*
        We go directly to the application phase, since we don't need
        to check if the event shall be skipped or not.

        Neither do we have to update the log positions, since that is
        not used at all: the rli_fake instance is used only for error
        reporting.
      */
      err = ev->apply_event(rli);
      /*
        Format_description_log_event should not be deleted because it
        will be used to read info about the relay log's format; it
        will be deleted when the SQL thread does not need it,
        i.e. when this thread terminates.
        ROWS_QUERY_LOG_EVENT if present in rli is deleted at the end
        of the event.
      */
      if (ev->get_type_code() != binary_log::FORMAT_DESCRIPTION_EVENT &&
          ev->get_type_code() != binary_log::ROWS_QUERY_LOG_EVENT) {
        delete ev;
        ev = nullptr;
      }
      if (err) {
        /*
          TODO: Maybe a better error message since the BINLOG statement
          now contains several events.
        */
        my_error(ER_UNKNOWN_ERROR, MYF(0));
        goto end;
      }
    }
  }

  DBUG_PRINT("info", ("binlog base64 execution finished successfully"));
  my_ok(thd);

end:
  if (rli) {
    if ((error || err) && rli->rows_query_ev) {
      delete rli->rows_query_ev;
      rli->rows_query_ev = nullptr;
    }
    rli->slave_close_thread_tables(thd);
  }
  thd->variables.option_bits = thd_options;
  my_free(buf);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_info_table.cc
Function: Rpl_info_table::do_flush_info
int Rpl_info_table::do_flush_info(const bool force) {
  int error = 1;
  enum enum_return_id res = FOUND_ID;
  TABLE *table = nullptr;
  sql_mode_t saved_mode;
  Open_tables_backup backup;

  DBUG_TRACE;

  if (!(force || (sync_period && ++(sync_counter) >= sync_period))) return 0;

  THD *thd = access->create_thd();

  sync_counter = 0;
  saved_mode = thd->variables.sql_mode;
  ulonglong saved_options = thd->variables.option_bits;
  thd->variables.option_bits &= ~OPTION_BIN_LOG;
  thd->is_operating_substatement_implicitly = true;

  /*
    Opens and locks the rpl_info table before accessing it.
  */
  if (access->open_table(thd, to_lex_cstring(str_schema),
                         to_lex_cstring(str_table), get_number_info(), TL_WRITE,
                         &table, &backup))
    goto end;

  /*
    Points the cursor at the row to be read according to the
    keys. If the row is not found an error is reported.
  */
  if ((res = access->find_info(field_values, table)) == NOT_FOUND_ID) {
    /*
      Prepares the information to be stored before calling ha_write_row.
    */
    empty_record(table);
    if (access->store_info_values(get_number_info(), table->field,
                                  field_values))
      goto end;

    /*
      Inserts a new row into rpl_info table.
    */
    if ((error = table->file->ha_write_row(table->record[0]))) {
      table->file->print_error(error, MYF(0));
      /*
        This makes sure that the error is 1 and not the status returned
        by the handler.
      */
      error = 1;
      goto end;
    }
    error = 0;
  } else if (res == FOUND_ID) {
    /*
      Prepares the information to be stored before calling ha_update_row.
    */
    store_record(table, record[1]);
    if (access->store_info_values(get_number_info(), table->field,
                                  field_values))
      goto end;

    /*
      Updates a row in the rpl_info table.
    */
    if ((error =
             table->file->ha_update_row(table->record[1], table->record[0])) &&
        error != HA_ERR_RECORD_IS_THE_SAME) {
      table->file->print_error(error, MYF(0));
      /*
        This makes sure that the error is 1 and not the status returned
        by the handler.
      */
      error = 1;
      goto end;
    }
    error = 0;
  }

end:
  DBUG_EXECUTE_IF("mta_debug_concurrent_access", {
    while (thd->system_thread == SYSTEM_THREAD_SLAVE_WORKER &&
           mta_debug_concurrent_access < 2 && mta_debug_concurrent_access > 0) {
      DBUG_PRINT("mts", ("Waiting while locks are acquired to show "
                         "concurrency in mts: %u %u\n",
                         mta_debug_concurrent_access, thd->thread_id()));
      my_sleep(6000000);
    }
  };);

  /*
    Unlocks and closes the rpl_info table.
  */
  error = access->close_table(thd, table, &backup, error) || error;
  thd->is_operating_substatement_implicitly = false;
  thd->variables.sql_mode = saved_mode;
  thd->variables.option_bits = saved_options;
  access->drop_thd(thd);
  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_info_table.cc
Function: Rpl_info_table::do_clean_info
int Rpl_info_table::do_clean_info() {
  int error = 1;
  enum enum_return_id res = FOUND_ID;
  TABLE *table = nullptr;
  sql_mode_t saved_mode;
  Open_tables_backup backup;

  DBUG_TRACE;

  THD *thd = access->create_thd();

  saved_mode = thd->variables.sql_mode;
  ulonglong saved_options = thd->variables.option_bits;
  thd->variables.option_bits &= ~OPTION_BIN_LOG;

  /*
    Opens and locks the rpl_info table before accessing it.
  */
  if (access->open_table(thd, to_lex_cstring(str_schema),
                         to_lex_cstring(str_table), get_number_info(), TL_WRITE,
                         &table, &backup))
    goto end;

  /*
    Points the cursor at the row to be deleted according to the
    keys. If the row is not found, the execution proceeds normally.
  */
  if ((res = access->find_info(field_values, table)) == FOUND_ID) {
    /*
      Deletes a row in the rpl_info table.
    */
    if ((error = table->file->ha_delete_row(table->record[0]))) {
      table->file->print_error(error, MYF(0));
      goto end;
    }
  }
  error = (res == ERROR_ID);
end:
  /*
    Unlocks and closes the rpl_info table.
  */
  error = access->close_table(thd, table, &backup, error) || error;
  thd->variables.sql_mode = saved_mode;
  thd->variables.option_bits = saved_options;
  access->drop_thd(thd);
  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_info_table.cc
Function: Rpl_info_table::do_update_is_transactional
bool Rpl_info_table::do_update_is_transactional() {
  bool error = true;
  sql_mode_t saved_mode;
  TABLE *table = nullptr;
  Open_tables_backup backup;

  DBUG_TRACE;

  THD *thd = access->create_thd();
  saved_mode = thd->variables.sql_mode;
  ulonglong saved_options = thd->variables.option_bits;
  thd->variables.option_bits &= ~OPTION_BIN_LOG;

  /*
    Opens and locks the rpl_info table before accessing it.
  */
  if (access->open_table(thd, to_lex_cstring(str_schema),
                         to_lex_cstring(str_table), get_number_info(), TL_READ,
                         &table, &backup))
    goto end;

  is_transactional = table->file->has_transactions();
  error = false;

end:
  error = access->close_table(thd, table, &backup, false) || error;
  thd->variables.sql_mode = saved_mode;
  thd->variables.option_bits = saved_options;
  access->drop_thd(thd);
  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_info_table.cc
Function: Rpl_info_table::do_init_info
int Rpl_info_table::do_init_info(uint instance) {
  return do_init_info(FIND_KEY, instance);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_info_table.cc
Function: Rpl_info_table::do_reset_info
int Rpl_info_table::do_reset_info(uint nparam, const char *param_schema,
                                  const char *param_table,
                                  const char *channel_name,
                                  MY_BITMAP const *nullable_bitmap) {
  int error = 0;
  TABLE *table = nullptr;
  sql_mode_t saved_mode;
  Open_tables_backup backup;
  Rpl_info_table *info = nullptr;
  THD *thd = nullptr;
  int handler_error = 0;

  DBUG_TRACE;

  if (!(info = new Rpl_info_table(nparam, param_schema, param_table, 0, nullptr,
                                  nullable_bitmap)))
    return 1;

  thd = info->access->create_thd();
  saved_mode = thd->variables.sql_mode;
  ulonglong saved_options = thd->variables.option_bits;
  thd->variables.option_bits &= ~OPTION_BIN_LOG;

  /*
    Opens and locks the rpl_info table before accessing it.
  */
  if (info->access->open_table(thd, to_lex_cstring(info->str_schema),
                               to_lex_cstring(info->str_table),
                               info->get_number_info(), TL_WRITE, &table,
                               &backup)) {
    error = 1;
    goto end;
  }

  if (!(handler_error = table->file->ha_index_init(0, true))) {
    KEY *key_info = table->key_info;

    /*
      Currently this method is used only for Worker info table
      resetting.
      todo: for another table in future, consider to make use of the
      passed parameter to locate the lookup key.
    */
    assert(strcmp(info->str_table.str, "slave_worker_info") == 0);

    if (info->verify_table_primary_key_fields(table)) {
      error = 1;
      table->file->ha_index_end();
      goto end;
    }

    uint fieldnr = key_info->key_part[0].fieldnr - 1;
    table->field[fieldnr]->store(channel_name, strlen(channel_name),
                                 &my_charset_bin);
    uint key_len = key_info->key_part[0].store_length;

    uchar key[MAX_KEY_LENGTH];
    key_copy(key, table->record[0], table->key_info,
             table->key_info->key_length);
    if (!(handler_error = table->file->ha_index_read_map(
              table->record[0], key, (key_part_map)1, HA_READ_KEY_EXACT))) {
      do {
        if ((handler_error = table->file->ha_delete_row(table->record[0])))
          break;
      } while (!(handler_error = table->file->ha_index_next_same(
                     table->record[0], key, key_len)));
      if (handler_error != HA_ERR_END_OF_FILE) error = 1;
    } else {
      /*
        Being reset table can be even empty, and that's benign.
      */
      if (handler_error != HA_ERR_KEY_NOT_FOUND) error = 1;
    }

    if (error) table->file->print_error(handler_error, MYF(0));
    table->file->ha_index_end();
  }
end:
  /*
    Unlocks and closes the rpl_info table.
  */
  error = info->access->close_table(thd, table, &backup, error) || error;
  thd->variables.sql_mode = saved_mode;
  thd->variables.option_bits = saved_options;
  info->access->drop_thd(thd);
  delete info;
  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_rli.cc
Function: Relay_log_info::cleanup_context
void Relay_log_info::cleanup_context(THD *thd, bool error) {
  DBUG_TRACE;

  assert(info_thd == thd);
  /*
    1) Instances of Table_map_log_event, if ::do_apply_event() was called on
    them, may have opened tables, which we cannot be sure have been closed
    (because maybe the Rows_log_event have not been found or will not be,
    because slave SQL thread is stopping, or relay log has a missing tail etc).
    So we close all thread's tables. And so the table mappings have to be
    cancelled. 2) Rows_log_event::do_apply_event() may even have started
    statements or transactions on them, which we need to rollback in case of
    error. 3) If finding a Format_description_log_event after a BEGIN, we also
    need to rollback before continuing with the next events. 4) so we need this
    "context cleanup" function.
  */
  if (error) {
    trans_rollback_stmt(thd);  // if a "statement transaction"
    trans_rollback(thd);       // if a "real transaction"
    thd->variables.original_commit_timestamp = UNDEFINED_COMMIT_TIMESTAMP;
  }
  if (rows_query_ev) {
    /*
      In order to avoid invalid memory access, THD::reset_query() should be
      called before deleting the rows_query event.
    */
    info_thd->reset_query();
    info_thd->reset_query_for_display();
    delete rows_query_ev;
    rows_query_ev = nullptr;
    DBUG_EXECUTE_IF("after_deleting_the_rows_query_ev", {
      const char action[] =
          "now SIGNAL deleted_rows_query_ev WAIT_FOR go_ahead";
      assert(!debug_sync_set_action(info_thd, STRING_WITH_LEN(action)));
    };);
  }
  m_table_map.clear_tables();
  slave_close_thread_tables(thd);
  if (error) {
    /*
      trans_rollback above does not rollback XA transactions.
      It could be done only after necessarily closing tables which dictates
      the following placement.
    */
    XID_STATE *xid_state = thd->get_transaction()->xid_state();
    if (!xid_state->has_state(XID_STATE::XA_NOTR)) {
      assert(DBUG_EVALUATE_IF("simulate_commit_failure", 1,
                              xid_state->has_state(XID_STATE::XA_ACTIVE) ||
                                  xid_state->has_state(XID_STATE::XA_IDLE)));

      xa_trans_force_rollback(thd);
      xid_state->reset();
      cleanup_trans_state(thd);
      if (thd->is_engine_ha_data_detached()) thd->rpl_reattach_engine_ha_data();
    }
    thd->mdl_context.release_transactional_locks();
  }
  clear_flag(IN_STMT);
  /*
    Cleanup for the flags that have been set at do_apply_event.
  */
  thd->variables.option_bits &= ~OPTION_NO_FOREIGN_KEY_CHECKS;
  thd->variables.option_bits &= ~OPTION_RELAXED_UNIQUE_CHECKS;

  /*
    Reset state related to long_find_row notes in the error log:
    - timestamp
    - flag that decides whether the slave prints or not
  */
  reset_row_stmt_start_timestamp();
  unset_long_find_row_note_printed();

  /*
    If the slave applier changed the current transaction isolation level,
    it need to be restored to the session default value once having the
    current transaction cleared.

    We should call "trans_reset_one_shot_chistics()" only if the "error"
    flag is "true", because "cleanup_context()" is called at the end of each
    set of Table_maps/Rows representing a statement (when the rows event
    is tagged with the STMT_END_F) with the "error" flag as "false".

    So, without the "if (error)" below, the isolation level might be reset
    in the middle of a pure row based transaction.
  */
  if (error) trans_reset_one_shot_chistics(thd);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_sys_table_access.cc
Function: Rpl_sys_table_access::open
bool Rpl_sys_table_access::open(enum thr_lock_type lock_type) {
  assert(nullptr == m_thd);
  m_lock_type = lock_type;
  m_current_thd = current_thd;
  m_error = false;

  THD *thd = nullptr;
  thd = new THD;
  thd->thread_stack = (char *)&thd;
  thd->store_globals();
  thd->security_context()->skip_grants();
  thd->system_thread = SYSTEM_THREAD_BACKGROUND;
  thd->set_new_thread_id();
  thd->variables.option_bits &= ~OPTION_BIN_LOG;
  thd->variables.option_bits &= ~OPTION_AUTOCOMMIT;
  thd->variables.option_bits |= OPTION_NOT_AUTOCOMMIT;
  thd->set_skip_readonly_check();
  m_thd = thd;

  // m_table_list[0] is m_schema_name.m_table_name
  // m_table_list[1] is m_schema_version_name.m_table_version_name
  m_table_list = new Table_ref[m_table_list_size];

  Table_ref *table_version = &m_table_list[m_table_version_index];
  *table_version =
      Table_ref(m_schema_version_name.c_str(), m_schema_version_name.length(),
                m_table_version_name.c_str(), m_table_version_name.length(),
                m_table_version_name.c_str(), m_lock_type);
  table_version->open_strategy = Table_ref::OPEN_IF_EXISTS;
  table_version->next_local = nullptr;
  table_version->next_global = nullptr;

  Table_ref *table_data = &m_table_list[m_table_data_index];
  *table_data = Table_ref(m_schema_name.c_str(), m_schema_name.length(),
                          m_table_name.c_str(), m_table_name.length(),
                          m_table_name.c_str(), m_lock_type);
  table_data->open_strategy = Table_ref::OPEN_IF_EXISTS;
  table_data->next_local = table_version;
  table_data->next_global = table_version;

  uint flags =
      (MYSQL_OPEN_IGNORE_GLOBAL_READ_LOCK | MYSQL_LOCK_IGNORE_GLOBAL_READ_ONLY |
       MYSQL_OPEN_IGNORE_FLUSH | MYSQL_LOCK_IGNORE_TIMEOUT);
  if (open_and_lock_tables(m_thd, m_table_list, flags)) {
    /* purecov: begin inspected */
    m_error = true;
    goto err;
    /* purecov: end */
  }

  if (table_data->table->s->fields < m_max_num_field) {
    /* purecov: begin inspected */
    m_error = true;
    goto err;
    /* purecov: end */
  }

  table_version->table->use_all_columns();
  table_data->table->use_all_columns();

err:
  if (m_error) {
    /* purecov: begin inspected */
    close(true);
    /* purecov: end */
  }

  return m_error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_mta_submode.cc
Function: Mts_submode_logical_clock::get_least_occupied_worker not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_mta_submode.cc
Function: Mts_submode_logical_clock::get_least_occupied_worker not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_mta_submode.cc
Function: Mts_submode_logical_clock::get_least_occupied_worker not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/rpl_mta_submode.cc
Function: Mts_submode_logical_clock::get_least_occupied_worker not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/dd/impl/transaction_impl.cc
Function: dd::Update_dictionary_tables_ctx::Update_dictionary_tables_ctx
Update_dictionary_tables_ctx::Update_dictionary_tables_ctx(THD *thd)
    : otx(thd, TL_WRITE),
      m_thd(thd),
      m_kill_immunizer(thd),
      m_query_tables_list_backup(new Query_tables_list()),
      m_saved_in_sub_stmt(thd->in_sub_stmt),
      m_saved_time_zone_used(thd->time_zone_used),
      m_saved_auto_increment_increment(
          thd->variables.auto_increment_increment) {
  m_saved_check_for_truncated_fields = m_thd->check_for_truncated_fields;

  m_saved_mode = m_thd->variables.sql_mode;
  m_thd->variables.sql_mode = 0;  // Reset during DD operations

  /*
    Backup and reset part of LEX which will be accessed while opening
    and closing data-dictionary tables.
  */
  m_thd->lex->reset_n_backup_query_tables_list(m_query_tables_list_backup);

  m_thd->reset_n_backup_open_tables_state(&m_open_tables_state_backup,
                                          Open_tables_state::SYSTEM_TABLES);

  if ((m_saved_binlog_row_based = m_thd->is_current_stmt_binlog_format_row()))
    m_thd->clear_current_stmt_binlog_format_row();

  // Disable bin logging
  m_saved_options = m_thd->variables.option_bits;
  m_thd->variables.option_bits &= ~OPTION_BIN_LOG;

  // Set bit to indicate that the thread is updating the data dictionary tables.
  m_thd->variables.option_bits |= OPTION_DD_UPDATE_CONTEXT;

  /*
    In @@autocommit=1 mode InnoDB automatically commits its transaction when
    all InnoDB tables in the statement are closed. Particularly, this can
    happen when ~Update_dictionary_tables_ctx() closes data-dictionary tables
    and there are no other InnoDB tables open by the statement.
    Since normally we decide whether we want to commit or rollback changes to
    data-dictionary sometime after this point we need to avoid this happening.
    So we disallow usage of Update_dictionary_tables_ctx in @@autocommit=1
    mode. This means that all DDL statements using Update_dictionary_tables_ctx
    to update data-dictionary need to turn off @@autocommit for its duration.
  */
  assert((m_thd->variables.option_bits & OPTION_NOT_AUTOCOMMIT) &&
         !(m_thd->variables.option_bits & OPTION_AUTOCOMMIT));

  // Store current intervals.
  m_thd->auto_inc_intervals_in_cur_stmt_for_binlog.swap(
      &m_auto_inc_intervals_in_cur_stmt_for_binlog_saved);

  // Store current interval.
  m_thd->auto_inc_intervals_forced.swap(&m_auto_inc_intervals_forced_saved);

  m_thd->variables.auto_increment_increment = 1;

  m_thd->in_sub_stmt = 0;

  m_thd->time_zone_used = false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/sql/dd/impl/transaction_impl.cc
Function: dd::Update_dictionary_tables_ctx::
  if (!m_tables[name])
    m_tables[name] = new (std::nothrow) Raw_table(m_lock_type, name);
}

bool Open_dictionary_tables_ctx::open_tables() {


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/ndb/plugin/ndb_local_connection.cc
Function: Ndb_local_connection::Ndb_local_connection
Ndb_local_connection::Ndb_local_connection(THD *thd_arg)
    : saved_thd_server_id(thd_arg->server_id),
      saved_thd_options(thd_arg->variables.option_bits),
      m_thd(thd_arg),
      impl(std::make_unique<Impl>(thd_arg)) {
  assert(thd_arg);
  /*
    System(or daemon) threads report error to log file
    all other threads use push_warning
  */
  m_push_warnings = (thd_arg->get_command() != COM_DAEMON);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/ndb/plugin/ndb_local_connection.cc
Function: Ndb_local_connection::
   Copyright (c) 2011, 2023, Oracle and/or its affiliates.

   This program is free software; you can redistribute it and/or modify
   it under the terms of the GNU General Public License, version 2.0,
   as published by the Free Software Foundation.

   This program is also distributed with certain software (including
   but not limited to OpenSSL) that is licensed under separate terms,
   as designated in a particular file or component or in included license
   documentation.  The authors of MySQL hereby grant you an additional
   permission to link the program and your derivative works with the
   separately licensed software that they have included with MySQL.

   This program is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   GNU General Public License, version 2.0, for more details.

   You should have received a copy of the GNU General Public License
   along with this program; if not, write to the Free Software
   Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301  USA
*/

#include "storage/ndb/plugin/ndb_local_connection.h"
#include "storage/ndb/plugin/ndb_anyvalue.h"

#include "sql/mysqld.h"  // next_query_id()
#include "sql/sql_class.h"
#include "sql/sql_prepare.h"
#include "storage/ndb/plugin/ndb_log.h"

class Ndb_local_connection::Impl {
 public:
  explicit Impl(THD *thd_arg) : connection(thd_arg) {}
  Ed_connection connection;
};


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/ndb/plugin/ndb_local_connection.cc
Function: Ndb_local_connection::set_binlog_options
void Ndb_local_connection::set_binlog_options(bool log_replica_updates,
                                              unsigned int op_anyvalue) {
  bool disable_binlog = false;

  if (ndbcluster_anyvalue_is_reserved(op_anyvalue)) {
    if (ndbcluster_anyvalue_is_nologging(op_anyvalue)) disable_binlog = true;
  } else {
    unsigned int req_server_id = ndbcluster_anyvalue_get_serverid(op_anyvalue);
    if (req_server_id != 0) {
      m_thd->server_id = req_server_id;
      if (!log_replica_updates) disable_binlog = true;
    }
  }

  if (disable_binlog) m_thd->variables.option_bits &= ~OPTION_BIN_LOG;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/ndb/plugin/ndb_local_connection.cc
Function: Ndb_local_connection::execute_query_iso
bool Ndb_local_connection::execute_query_iso(const std::string &sql_query,
                                             const uint *ignore_mysql_errors) {
  /* Don't allow queries to affect THD's status variables */
  struct System_status_var save_thd_status_var = m_thd->status_var;

  /* Check modified_non_trans_table is false(check if actually needed) */
  assert(!m_thd->get_transaction()->has_modified_non_trans_table(
      Transaction_ctx::STMT));

  /* Turn off binlogging */
  ulonglong save_thd_options = m_thd->variables.option_bits;
  static_assert(
      sizeof(save_thd_options) == sizeof(m_thd->variables.option_bits),
      "Mismatched type for variable used to save option_bits");
  m_thd->variables.option_bits &= ~OPTION_BIN_LOG;

  /*
    Increment query_id, the query_id is used when generating
    the xid for transaction and unless incremented will get
    the same xid in subsequent queries.
  */
  m_thd->set_query_id(next_query_id());

  bool result = execute_query(sql_query, ignore_mysql_errors);

  /* Restore THD settings */
  m_thd->variables.option_bits = save_thd_options;
  m_thd->status_var = save_thd_status_var;

  return result;
}


